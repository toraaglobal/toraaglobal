{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"I am Tajudeen Abdulazeez","text":"<p>Hey there! I\u2019m a professional data engineer and geospatial data scientist based in Sacramento, CA. </p> Tajudeen Abdulazeez is a versatile professional with a background in Geo-science and a Master's degree in Applied Data Science. Certified Google Professional Data Engineer with expertise in building end-to-end data science solutions. With a commitment to continuous learning, he bridge his analytical insights with data-driven acumen, embodying the synergy between evolving technology and diverse expertise. My Resume More about me My website <p>Welcome to our cutting-edge data blog, your go-to resource for all things related to the intricate world of data. From the foundational concepts of data science and data engineering to the complexities of databases, data pipelines, and data analytics, we're here to unravel the mysteries that data holds.</p> <p>Embark on a journey with us as we explore the ever-evolving landscape of data technologies, leveraging the power of serverless computing, Docker, Kubernetes, Airflow, and the vast capabilities of cloud platforms like AWS and GCP. Our blog is a gateway to understanding how these tools revolutionize the way data is managed, processed, and transformed into invaluable insights.</p> <p>Whether you're an industry expert seeking to stay ahead of the curve or a curious mind eager to grasp the potentials of data-driven innovation, our articles are tailored to cater to all levels of expertise. Join us in this exciting expedition where data transforms into knowledge, and where we unravel the true potential of data's limitless possibilities.</p>"},{"location":"aboutme/","title":"Aboutme","text":"<p>Meet Tajudeen Abdulazeez, a dynamic individual who seamlessly bridged the worlds of Geo-science and Data Science to emerge as a proficient and adaptable full stack Data Scientist. Driven by an unquenchable thirst for knowledge and a passion for staying on the cutting edge of emerging technologies, Tajudeen Abdulazeez has successfully navigated a transformative career path.</p> <p>With a solid foundation in Geo-science, Tajudeen Abdulazeez holds a bachelor's degree in Geology, which laid the groundwork for their deep understanding of the Earth's complex systems. But their journey didn't stop there. Seeking to explore the intersection of data and science further, Tajudeen Abdulazeez pursued a Master's degree in Applied Data Science at Syracuse University. This academic endeavor allowed them to not only refine their analytical skills but also understand the nuances of transforming raw data into actionable insights.</p> <p>Fuelled by an insatiable curiosity, Tajudeen Abdulazeez took their educational journey a step further by acquiring a certificate in GIS and Remote Sensing. This specialized expertise equipped them with the tools to extract valuable information from geographic data, facilitating informed decision-making in a variety of contexts.</p> <p>A true testament to their commitment to excellence, Tajudeen Abdulazeez proudly holds the title of Certified Google Professional Data Engineer. This certification reflects their proficiency in designing, building, and maintaining data processing systems\u2014demonstrating their competence in harnessing the power of data to drive strategic initiatives.</p> <p>Currently, Tajudeen Abdulazeez is making waves as a Senior Data Scientist Engineer at Bayer. Here, they bring their unique blend of skills to the forefront, seamlessly integrating their geological insights with their data-driven acumen. In this role, Tajudeen Abdulazeez excels at constructing end-to-end data science solutions, demonstrating a holistic understanding of the entire data pipeline.</p> <p>At the heart of their expertise lies the mastery of various tools and technologies. With proficiency in Airflow, Python, R, AWS, Docker, and Redshift, Tajudeen Abdulazeez crafts sophisticated data pipelines that streamline processes and enhance efficiency. Their ability to manipulate and manage data is second to none, allowing them to extract valuable insights that fuel informed decision-making.</p> <p>Beyond their technical prowess, Tajudeen Abdulazeez possesses a passion for continuous education. Recognizing that the realm of data science is in a constant state of evolution, they dedicate themselves to staying ahead of the curve. This commitment ensures that their skillset remains current and aligned with the rapidly changing technological landscape.</p> <p>In essence, Tajudeen Abdulazeez is a trailblazer who seamlessly merged their geological foundation with the world of data science, emerging as a multifaceted professional capable of tackling complex challenges. Their journey\u2014from a Geo-scientist to a full stack Data Scientist and Data Engineer\u2014serves as an inspiring example of the possibilities that arise when curiosity, dedication, and a hunger for knowledge converge.</p>"},{"location":"credentials/","title":"Credentials","text":""},{"location":"weblinks/","title":"Weblinks","text":"My website www.toraaglobal.com  Metals: Financial analytics   https://toraaglobal.shinyapps.io/metals/"},{"location":"blog/","title":"Blog Home","text":"<p>Blog </p>"},{"location":"blog/2023/09/03/analyzing-congressional-floor-debates-with-lda-topic-modeling/","title":"Analyzing Congressional Floor Debates with LDA Topic Modeling","text":"<p>Topic modeling is a powerful technique in natural language processing (NLP) that helps us discover the underlying themes or topics within a collection of texts. In this blog post, we will explore the application of Latent Dirichlet Allocation (LDA) topic modeling to analyze the floor debates of the 110th Congress, focusing exclusively on the House of Representatives. The dataset is divided into subfolders, with \"m\" representing male speakers, \"f\" for female speakers, \"d\" for Democrats, and \"r\" for Republicans. Let's dive into the process of topic modeling and uncover the main themes of these congressional debates.</p>"},{"location":"blog/2023/09/03/analyzing-congressional-floor-debates-with-lda-topic-modeling/#the-tools-and-libraries","title":"The Tools and Libraries","text":"<p>Before we delve into the topic modeling process, let's understand the tools and libraries we'll be using:</p> <ul> <li>Python: We'll be using Python as our programming language for this analysis.</li> <li>Gensim: Gensim is a popular Python library for topic modeling and document similarity analysis. We will use it to build our LDA model.</li> <li>NLTK: NLTK (Natural Language Toolkit) is a comprehensive library for working with human language data. We'll use it for text preprocessing tasks.</li> <li>PyLDAvis: PyLDAvis is a Python library that helps visualize the topics extracted by an LDA model.</li> <li>Pandas: Pandas is a data manipulation library in Python that will assist us in managing our data.</li> <li>Matplotlib: We'll use Matplotlib for data visualization.</li> </ul>"},{"location":"blog/2023/09/03/analyzing-congressional-floor-debates-with-lda-topic-modeling/#data-collection","title":"Data Collection","text":"<p>The data for this analysis is organized in subfolders, each representing a different category (male, female, Democrat, Republican) of congressional speakers. We will read all the text files from these subfolders and store them in a dataframe for further analysis.</p> <pre><code># Folder directory\nfolder = \"../../data/110\"\n\n# Read all the files in the folder and store them as a dataframe\nalltext = []\nfor sub in os.listdir(folder):\n    temp = folder + '/' + sub\n    for file in os.listdir(temp):\n        filedir = temp + '/' + file\n        try:\n            with open(filedir) as f:\n                text = f.read()\n                alltext.append(text)\n        except Exception as e:\n            print(str(e))\n            print(\"Error reading : {}\".format(filedir))\n\n# Create a dataframe\ndoc = pd.DataFrame(alltext).reset_index()\ndocuments = doc[[0]].values\n\n\n</code></pre>"},{"location":"blog/2023/09/03/analyzing-congressional-floor-debates-with-lda-topic-modeling/#data-preprocessing","title":"Data Preprocessing","text":"<p>Text data is usually messy and noisy, so we need to preprocess it before applying topic modeling techniques. Our preprocessing steps include:</p> <ul> <li>Tokenization: Splitting text into words or tokens.</li> <li>Removing Stopwords: Eliminating common words (e.g., \"and,\" \"the,\" \"is\") that don't provide much meaningful information.</li> <li>Lemmatization and Stemming: Reducing words to their base or root form to consolidate similar words.</li> </ul> <pre><code># Preprocessing functions\ndef lemmatize_stemming(text):\n    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n\ndef preprocess(text):\n    result = []\n    for token in gensim.utils.simple_preprocess(text):\n        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) &gt; 3:\n            result.append(lemmatize_stemming(token))\n    return result\n\n# Apply preprocessing to the documents\nprocessed_docs = doc[0].map(preprocess)\n\n\n</code></pre>"},{"location":"blog/2023/09/03/analyzing-congressional-floor-debates-with-lda-topic-modeling/#building-a-dictionary-and-corpus","title":"Building a Dictionary and Corpus","text":"<p>To perform LDA, we need to create a dictionary that maps words to unique IDs and a corpus that represents each document as a list of word frequency tuples.</p> <pre><code># Create a dictionary\ndictionary = gensim.corpora.Dictionary(processed_docs)\n\n# Create a Bag of Words (BoW) corpus\nbow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n\n</code></pre>"},{"location":"blog/2023/09/03/analyzing-congressional-floor-debates-with-lda-topic-modeling/#tf-idf-transformation","title":"TF-IDF Transformation","text":"<p>We can further enhance our LDA model by applying TF-IDF (Term Frequency-Inverse Document Frequency) transformation to the BoW corpus. TF-IDF assigns weights to words based on their importance in individual documents and across the entire corpus.</p> <pre><code># Create a TF-IDF model\ntfidf = models.TfidfModel(bow_corpus)\ncorpus_tfidf = tfidf[bow_corpus]\n\n</code></pre>"},{"location":"blog/2023/09/03/analyzing-congressional-floor-debates-with-lda-topic-modeling/#running-lda","title":"Running LDA","text":"<p>Now that we have prepared our data, it's time to run the LDA model. LDA aims to identify topics in the text data and assign words to these topics. We specify the number of topics as a parameter.</p> <pre><code># Run LDA with the Bag of Words corpus\nlda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=10, id2word=dictionary, passes=10)\n</code></pre>"},{"location":"blog/2023/09/03/analyzing-congressional-floor-debates-with-lda-topic-modeling/#interpreting-lda-results","title":"Interpreting LDA Results","text":"<p>LDA provides us with a set of topics, each represented by a list of keywords. These keywords help us understand the main themes in the data. Additionally, we can calculate perplexity to evaluate how well our model fits the data.</p> <pre><code># Print the topics and their keywords\npprint(lda_model.print_topics())\n\n# Compute Perplexity\nperplexity = lda_model.log_perplexity(bow_corpus)\nprint('Perplexity:', perplexity)\n\n\n</code></pre>"},{"location":"blog/2023/09/03/analyzing-congressional-floor-debates-with-lda-topic-modeling/#visualizing-lda-topics","title":"Visualizing LDA Topics","text":"<p>To gain a better understanding of the topics generated by LDA, we can use PyLDAvis to create an interactive visualization.</p> <pre><code># Visualize LDA topics\nvis = pyLDAvis.gensim_models.prepare(lda_model, bow_corpus, dictionary)\npyLDAvis.save_html(vis, '../../data/10_gensim_110.html')\n\n\n</code></pre>"},{"location":"blog/2023/09/03/analyzing-congressional-floor-debates-with-lda-topic-modeling/#conclusion","title":"Conclusion","text":"<p>In this blog post, we explored the use of LDA topic modeling to analyze the floor debates of the 110th Congress in the House of Representatives. By preprocessing the data, building a dictionary and corpus, and running LDA, we were able to identify and interpret topics within the congressional debates. This analysis provides valuable insights into the major themes discussed during this legislative session.</p> <p>Topic modeling is a versatile technique that can be applied to various text datasets to uncover hidden patterns and extract meaningful information. Whether in politics, academia, or business, topic modeling can help researchers and analysts make sense of large volumes of text data and draw meaningful conclusions.</p> <p>Click here to Visualize the  LDA Topics</p>"},{"location":"blog/2023/08/13/unveiling-the-power-of-landsat-atmospheric-correction-using-r/","title":"Unveiling the Power of Landsat Atmospheric Correction Using R","text":"<p>In the realm of remote sensing and geospatial analysis, Landsat imagery plays a pivotal role in understanding and monitoring Earth's surface. However, to extract accurate information from these images, it's crucial to apply proper atmospheric correction techniques. In this blog post, we'll dive into the process of atmospheric correction using the R programming language and the RStoolbox package. Best of all, this package is both free and open source, making it accessible to all.</p>"},{"location":"blog/2023/08/13/unveiling-the-power-of-landsat-atmospheric-correction-using-r/#getting-started-with-rstoolbox","title":"Getting Started with RStoolbox","text":"<p>RStoolbox is a R package providing a wide range of tools for your every-day remote sensing processing needs. The available toolset covers many aspects from data import, pre-processing, data analysis, image classification and graphical display. RStoolbox builds upon the raster package, which makes it suitable for processing large data-sets even on smaller workstations.</p> <p>To embark on this journey, we'll harness the capabilities of the RStoolbox package. This versatile tool is designed to facilitate the atmospheric correction of Landsat imagery, ensuring that the data we work with is both accurate and reliable.</p> <p>Let's delve into the step-by-step process of atmospheric correction using the RStoolbox package.</p>"},{"location":"blog/2023/08/13/unveiling-the-power-of-landsat-atmospheric-correction-using-r/#step-1-installing-rstoolbox","title":"Step 1: Installing RStoolbox","text":"<p>RStoolbox is now available from CRAN and can be installed as usual with</p> <pre><code>install.packages(\"RStoolbox\")\n</code></pre>"},{"location":"blog/2023/08/13/unveiling-the-power-of-landsat-atmospheric-correction-using-r/#step-2-reading-metadata","title":"Step 2: Reading Metadata","text":"<p>The first step involves reading the metadata associated with a Landsat image. The readMeta() function allows us to extract essential information from the metadata file. Let's take a peek at how this is done:</p> <pre><code># Read metadata for Landsat image\nmeta2011 = readMeta('LT05_L1TP_130045_20060424_20161122_01_T1_MTL.txt')\nsummary(meta2011)\n\n</code></pre>"},{"location":"blog/2023/08/13/unveiling-the-power-of-landsat-atmospheric-correction-using-r/#step-3-stacking-landsat-bands","title":"Step 3: Stacking Landsat Bands","text":"<p>After acquiring the metadata, it's time to stack individual Landsat bands together. This consolidated stack forms the foundation for subsequent calculations. Here's how it's done:</p> <pre><code># Stack individual Landsat bands\np22_2011 = stackMeta(meta2011)\ndn2_rad = meta2011$CALRAD # Extract offset gain data\n\n</code></pre>"},{"location":"blog/2023/08/13/unveiling-the-power-of-landsat-atmospheric-correction-using-r/#step-4-conversion-to-radiant-values","title":"Step 4: Conversion to Radiant Values","text":"<p>Now, we move on to converting the digital numbers (DN) to top-of-the-atmosphere radiance. This process is crucial for ensuring that the data accurately represents the radiance values received from the Earth's surface:</p> <pre><code># Convert DN to radiance\np22_2011_rad = radCor(p22_2011, metaData = meta2011, method = 'rad')\n\n</code></pre>"},{"location":"blog/2023/08/13/unveiling-the-power-of-landsat-atmospheric-correction-using-r/#step-5-top-of-atmosphere-reflectance","title":"Step 5: Top of Atmosphere Reflectance","text":"<p>To obtain top-of-atmosphere (TOA) reflectance values, we proceed with additional atmospheric correction:</p> <pre><code># Calculate TOA reflectance\np22_2011_ref = radCor(p22_2011, metaData = meta2011, method = 'apref')\n\n</code></pre>"},{"location":"blog/2023/08/13/unveiling-the-power-of-landsat-atmospheric-correction-using-r/#step-6-haze-correction","title":"Step 6: Haze Correction","text":"<p>Haze can significantly impact the accuracy of remote sensing data. With the RStoolbox package, we can estimate and correct for haze:</p> <pre><code># Estimate and correct for haze\nhaze = estimateHaze(p22_2011, darkProp = 0.01, hazeBands = c(\"B1_dn\", \"B2_dn\", \"B3_dn\", \"B4_dn\"))\n\n</code></pre>"},{"location":"blog/2023/08/13/unveiling-the-power-of-landsat-atmospheric-correction-using-r/#step-7-dark-object-extraction-dos","title":"Step 7: Dark Object Extraction (DOS)","text":"<p>The Dark Object Subtraction (DOS) technique helps remove atmospheric effects caused by dark objects in the scene:</p> <pre><code># Apply Dark Object Subtraction (DOS)\np22_2011_dos = radCor(p22_2011, metaData = meta2011, darkProp = 0.01, method = 'dos')\n\n</code></pre>"},{"location":"blog/2023/08/13/unveiling-the-power-of-landsat-atmospheric-correction-using-r/#step-8-calculate-ndvi","title":"Step 8: Calculate NDVI","text":"<p>Finally, we can calculate the Normalized Difference Vegetation Index (NDVI) \u2013 a crucial metric for vegetation analysis \u2013 using the spectral indices function:</p> <pre><code># Calculate NDVI\nndvi = spectralIndices(p22_2011, red = \"B3_dn\", nir = 'B4_dn', indices = 'NDVI')\n</code></pre>"},{"location":"blog/2023/08/13/unveiling-the-power-of-landsat-atmospheric-correction-using-r/#conclusion","title":"Conclusion","text":"<p>And there you have it! By employing the RStoolbox package, we've journeyed through the intricate process of atmospheric correction for Landsat imagery. Each step contributes to transforming raw data into meaningful and accurate information, paving the way for a wide range of geospatial analyses and applications. The power of open source tools like RStoolbox empowers us to explore, analyze, and interpret our world with precision.</p>"},{"location":"blog/2024/11/24/revolutionizing-content-creation-with-bloggenie-the-ai-powered-blog-post-generator/","title":"Revolutionizing Content Creation with BlogGenie: The AI-Powered Blog Post Generator","text":"<p>In the age of content, crafting high-quality, engaging blog posts can be time-consuming and daunting. Enter BlogGenie, an AI-powered application designed to transform the blogging experience. Built using Streamlit, LangChain, and OpenAI, BlogGenie empowers users to generate informative, professional blog posts in minutes.</p> <p>This blog post explores how BlogGenie works, its features, and how it leverages the latest advancements in generative AI.</p>"},{"location":"blog/2024/11/24/revolutionizing-content-creation-with-bloggenie-the-ai-powered-blog-post-generator/#the-problem-writers-block-and-time-constraints","title":"The Problem: Writer\u2019s Block and Time Constraints","text":"<p>Content creators often face challenges such as:</p> <ul> <li>Writer\u2019s block: Struggling to start or complete a blog post.</li> <li>Tedious research: Spending hours gathering information.</li> <li>High demand for content: Meeting deadlines while ensuring quality.</li> </ul> <p>BlogGenie addresses these issues by automating the writing process. Users simply input a topic, and the app generates a 400-word blog post complete with analytics, saving time and effort.</p>"},{"location":"blog/2024/11/24/revolutionizing-content-creation-with-bloggenie-the-ai-powered-blog-post-generator/#how-bloggenie-works","title":"How BlogGenie Works","text":"<p>BlogGenie integrates Streamlit for the user interface, LangChain for prompt management, and OpenAI to power the underlying language model. Here's a breakdown of its functionality:</p>"},{"location":"blog/2024/11/24/revolutionizing-content-creation-with-bloggenie-the-ai-powered-blog-post-generator/#interactive-user-interface","title":"Interactive User Interface","text":"<p>Streamlit provides an intuitive and responsive UI for seamless interaction. Users can input their topic of choice, click a button, and receive a complete blog post within seconds.</p> <pre><code>st.set_page_config(\n    page_title=\"BlogGenie\",\n    page_icon=\"\ud83e\uddca\",\n    layout=\"centered\",\n)\n\nst.header(\"Generate high-quality blog posts in minutes with BlogGenie!\")\n\n</code></pre>"},{"location":"blog/2024/11/24/revolutionizing-content-creation-with-bloggenie-the-ai-powered-blog-post-generator/#prompt-design-for-blog-generation","title":"Prompt Design for Blog Generation","text":"<p>The prompt template ensures that BlogGenie delivers concise and well-structured posts. Users receive:</p> <ul> <li>A full blog post based on the given topic.</li> <li>Word count analytics to evaluate post length.</li> </ul> <pre><code>template = \"\"\"\n    As experienced startup and generative AI Engineers,\n    generate a 400-word blog post about {topic}\n\n    Your response should be in this format:\n    First, print the blog post.\n    Then, sum the total number of words and print the result like this: This post has X words.\n\"\"\"\n\n</code></pre>"},{"location":"blog/2024/11/24/revolutionizing-content-creation-with-bloggenie-the-ai-powered-blog-post-generator/#powerful-ai-backend","title":"Powerful AI Backend","text":"<p>The app uses OpenAI\u2019s language model for generating high-quality content. By adjusting parameters like temperature and max tokens, BlogGenie ensures a balance between creativity and relevance.</p> <pre><code>def load_LLM(openai_api_key):\n    llm = OpenAI(temperature=0.7, openai_api_key=openai_api_key)\n    return llm\n\n</code></pre>"},{"location":"blog/2024/11/24/revolutionizing-content-creation-with-bloggenie-the-ai-powered-blog-post-generator/#key-features-of-bloggenie","title":"Key Features of BlogGenie","text":""},{"location":"blog/2024/11/24/revolutionizing-content-creation-with-bloggenie-the-ai-powered-blog-post-generator/#seamless-user-experience","title":"Seamless User Experience","text":"<p>With just a topic input, BlogGenie delivers complete blog posts. The sidebar allows users to securely input their OpenAI API key for personalized results.</p> <pre><code>openai_api_key = st.sidebar.text_input(\n    label=\"OpenAI API Key\", \n    placeholder=\"Ex: sk-2twmA8tfCb8un4...\", \n    type=\"password\"\n)\n\n</code></pre>"},{"location":"blog/2024/11/24/revolutionizing-content-creation-with-bloggenie-the-ai-powered-blog-post-generator/#tailored-content","title":"Tailored Content","text":"<p>Whether you need a post for a technical blog or a lifestyle piece, BlogGenie adapts to any topic. The app is versatile and customizable, catering to a variety of niches.</p>"},{"location":"blog/2024/11/24/revolutionizing-content-creation-with-bloggenie-the-ai-powered-blog-post-generator/#real-time-word-count","title":"Real-Time Word Count","text":"<p>Each post includes an automated word count summary, helping users meet specific content requirements.</p>"},{"location":"blog/2024/11/24/revolutionizing-content-creation-with-bloggenie-the-ai-powered-blog-post-generator/#why-choose-bloggenie","title":"Why Choose BlogGenie?","text":"<ul> <li>Saves Time: Generate content in seconds, reducing the need for extensive research and writing.</li> <li>Boosts Creativity: Eliminate writer\u2019s block with AI-powered suggestions.</li> <li>Scalable Solution: Ideal for content creators, businesses, and marketers who need consistent, high-quality output.</li> </ul>"},{"location":"blog/2024/11/24/revolutionizing-content-creation-with-bloggenie-the-ai-powered-blog-post-generator/#how-to-get-started","title":"How to Get Started","text":"<ul> <li>Access BlogGenie: Download or run the app locally using Streamlit.</li> <li>Enter API Key: Add your OpenAI API key in the sidebar.</li> <li>Provide a Topic: Input the subject of your blog post.</li> <li>Generate Content: Click \"Generate Blog\" and let the magic happen!</li> </ul> <pre><code>topic_text = st.text_input(\"Enter topic: \")\nif st.button(\"Generate Blog\"):\n    if openai_api_key.startswith(\"sk-\") and topic_text:\n        generate_response(topic_text)\n\n</code></pre> <p>Link to the complete code on Github</p>"},{"location":"blog/2024/11/24/revolutionizing-content-creation-with-bloggenie-the-ai-powered-blog-post-generator/#build-your-own-ai-powered-applications","title":"Build Your Own AI-Powered Applications","text":"<p>BlogGenie is a testament to the transformative power of generative AI in content creation. Whether you're a developer or a business owner, tools like this open the door to endless possibilities.</p> <p>If you\u2019re inspired by BlogGenie and want to create similar applications, GenAIExpertise is here to help. From ideation to deployment, we specialize in building bespoke AI solutions tailored to your needs.</p>"},{"location":"blog/2023/08/31/evidence-based-investment-using-monte-carlo-simulations/","title":"Evidence-Based Investment Using  Monte Carlo Simulations","text":"<p>In the dynamic world of finance, making informed investment decisions can be quite challenging. Fortunately, advancements in technology and mathematical modeling have given rise to powerful tools that enable investors to gain a deeper understanding of potential outcomes. One such tool is the Monte Carlo Simulation, a technique that harnesses the power of randomness to forecast various scenarios and make evidence-based investment choices. In this article, we'll delve into the realm of evidence-based investing using a Monte Carlo Simulation, building upon the insightful notebook developed by Matt Macarty.</p>"},{"location":"blog/2023/08/31/evidence-based-investment-using-monte-carlo-simulations/#installing-the-essentials","title":"Installing the Essentials","text":"<p>Before we embark on our journey into the world of evidence-based investment, let's ensure we have all the necessary tools at our disposal. We'll be using Python with popular libraries like NumPy, Pandas, and Matplotlib for data manipulation, analysis, and visualization. To begin, make sure you have these libraries installed in your Python environment.</p> <pre><code>import numpy as np\nfrom pandas import Series, DataFrame\nimport matplotlib.pyplot as plt\nfrom babel.numbers import format_currency\n\nplt.style.use('fivethirtyeight')\n\n</code></pre>"},{"location":"blog/2023/08/31/evidence-based-investment-using-monte-carlo-simulations/#calculating-growth-a-solid-foundation","title":"Calculating Growth: A Solid Foundation","text":"<p>At the heart of every investment is the growth of capital over time. Let's start by building a base investment and calculating its growth. We'll consider an initial principal value (PV) of $10,000, an annual interest rate (i) of 7%, and annual additions of $10,000. With these parameters in place, we can compute the investment's value over a 30-year time horizon.</p> <pre><code>pv = 10000\ntime_horizon = 30\ni = 0.07\nadditions = 10000\n\nfor year in range(time_horizon):\n    ending = pv * (1 + i) + additions\n    print(format_currency(ending, 'USD'))\n    pv = ending\n\n</code></pre>"},{"location":"blog/2023/08/31/evidence-based-investment-using-monte-carlo-simulations/#incorporating-market-variation","title":"Incorporating Market Variation","text":"<p>In reality, investment returns are subject to market fluctuations. Let's introduce random variation based on market history to simulate the uncertainty investors face. Assuming an expected annual return of 7.1% and a volatility of 10% (typical of the S&amp;P 500), we can explore how an investment of $10,000 would fare over a 30-year period.</p> <pre><code>pv = 10000\nexpected_return = 0.071\nvolatility = 0.10\ntime_horizon = 30\nannual_addition = 10000\n\nprint(\"\\tReturn\", \"\\t\\tEnding Value\".rjust(18))\nfor year in range(time_horizon):\n    market_return = np.random.normal(expected_return, volatility)\n    fv = pv * (1 + market_return) + annual_addition\n    print(\"\\t{}\".ljust(10).format(round(market_return, 4)), \"\\t{}\".rjust(10).format(format_currency(fv, 'USD')))\n    pv = fv\n\n</code></pre>"},{"location":"blog/2023/08/31/evidence-based-investment-using-monte-carlo-simulations/#simulating-multiple-outcomes","title":"Simulating Multiple Outcomes","text":"<p>Now, let's take a step further and simulate multiple investment outcomes using the Monte Carlo Simulation technique. By running the simulation multiple times, each with slight variations in market returns, we can gain insights into the range of potential investment scenarios.</p> <pre><code>sim = DataFrame()\niterations = 5000\n\nfor x in range(iterations):\n    expected_return = 0.071\n    volatility = 0.15\n    time_horizon = 30\n    pv = 10000\n    annual_investment = 10000\n    stream = []\n    for i in range(time_horizon):\n        end = round(pv * (1 + np.random.normal(expected_return, volatility)) + annual_investment, 2)\n        stream.append(end)\n        pv = end\n\n    sim[x] = stream\n\n</code></pre>"},{"location":"blog/2023/08/31/evidence-based-investment-using-monte-carlo-simulations/#exploring-simulated-portfolios","title":"Exploring Simulated Portfolios","text":"<p>Visualizing data is essential for understanding trends and patterns. Let's explore a sample of annual ending values from our simulated portfolios and visualize them using line plots.</p> <pre><code>first_five = list(range(5))\nsim[first_five]\n\nplt.plot(sim[first_five])\nplt.show()\n\n</code></pre>"},{"location":"blog/2023/08/31/evidence-based-investment-using-monte-carlo-simulations/#analyzing-and-interpreting-results","title":"Analyzing and Interpreting Results","text":"<p>With our simulations in place, it's time to dive into data analysis and interpretation. We'll calculate summary statistics to provide a comprehensive overview of the simulated investment outcomes.</p> <pre><code>ending_values = sim.loc[29]\n\nprint(\"Count:\", len(ending_values))\nprint(\"Mean: \", format_currency(np.mean(ending_values), 'USD'))\nprint(\"SD: \", format_currency(np.std(ending_values), 'USD'))\nprint(\"Max: \", format_currency(np.max(ending_values), 'USD'))\nprint(\"Min: \", format_currency(np.min(ending_values), 'USD'))\n\n</code></pre>"},{"location":"blog/2023/08/31/evidence-based-investment-using-monte-carlo-simulations/#probability-and-percentiles","title":"Probability and Percentiles","text":"<p>We can also explore the likelihood of achieving specific investment outcomes. For instance, what's the probability of ending with more than $1,000,000?</p> <pre><code>probability = len(ending_values[ending_values &gt; 1000000]) / len(ending_values)\nprint(\"Probability of ending with more than $1,000,000:\", round(probability, 4))\n\n</code></pre> <p>Additionally, calculating percentiles provides a clearer picture of the potential range of outcomes.</p> <pre><code>p_tiles = np.percentile(ending_values, [5, 10, 15, 25, 75, 85, 90, 95])\nfor p in range(len(p_tiles)):\n    l = [5, 10, 15, 25, 75, 85, 90, 95]\n    print(\"{}%-ile: \".format(l[p]).rjust(15), \"{}\".format(format_currency(p_tiles[p], 'USD')))\n\n</code></pre>"},{"location":"blog/2023/08/31/evidence-based-investment-using-monte-carlo-simulations/#empowering-investment-decisions","title":"Empowering Investment Decisions","text":"<p>Monte Carlo Simulations are a valuable tool for evidence-based investment decision-making. By simulating a wide range of scenarios and analyzing potential outcomes, investors can gain a better understanding of the risks and rewards associated with different investment strategies. Remember that the key to successful investing lies in staying informed, being adaptable, and leveraging data-driven insights to make the best decisions for your financial future.</p>"},{"location":"blog/2023/08/31/evidence-based-investment-using-monte-carlo-simulations/#colab","title":"Colab","text":"<p>Open Source Code In Colab </p>"},{"location":"blog/2023/09/10/building-scalable-time-series-models-with-facebook-prophet/","title":"Building Scalable Time Series Models with Facebook Prophet","text":"<p>In the ever-evolving world of data science and forecasting, having a reliable tool that can quickly generate high-quality forecasts at scale is crucial. One such tool that has gained popularity in recent years is Facebook Prophet. In this blog post, we'll explore how Prophet can be used to build time series models for forecasting and dive into the process of preparing and analyzing time series data. We'll also provide a link to a Colab notebook for hands-on experience.</p> <p>Installing Prophet</p> <p>Before we dive into the details, make sure you have Prophet installed. You can install it using pip:</p> <pre><code>pip install fbprophet\n</code></pre> <p>Once you have Prophet installed, you're ready to get started.</p>"},{"location":"blog/2023/09/10/building-scalable-time-series-models-with-facebook-prophet/#getting-the-data","title":"Getting the Data","text":"<p>To demonstrate the capabilities of Prophet, we'll use a sample time series dataset that represents weekly sales of beverages. You can obtain the dataset from the following URL:</p> <p>Dataset Link</p> <p>We'll use Pandas to load the data into a DataFrame and take a look at the first few rows:</p> <pre><code>import pandas as pd\n\n# Load the data\ndf = pd.read_csv('https://raw.githubusercontent.com/2SUBDA/On-Campus/master/Dept1.csv', sep=',', error_bad_lines=False, encoding=\"ISO-8859-1\")\n\n# Rename the 'Sales' column to 'BevSales' for clarity\ndf = df.rename(index=str, columns={\"Sales\": \"BevSales\"})\n\n# Rename columns for Prophet\ndf = df.rename(index=str, columns={\"BevSales\": \"y\", \"Date\": \"ds\"})\n\n# Display the first few rows\ndf.head()\n\n</code></pre>"},{"location":"blog/2023/09/10/building-scalable-time-series-models-with-facebook-prophet/#data-preparation","title":"Data Preparation","text":"<p>Prophet requires a specific naming convention for input columns, where the date column should be named 'ds,' and the value column should be named 'y.' As you can see from the code above, we've prepared our data accordingly.</p>"},{"location":"blog/2023/09/10/building-scalable-time-series-models-with-facebook-prophet/#visualizing-the-data","title":"Visualizing the Data","text":"<p>Before building our model, let's visualize the time series data to get a better understanding of its patterns. We'll use Matplotlib for this purpose:</p> <pre><code>import matplotlib.pyplot as plt\n\n# Set the date column as the index\nax = df.set_index('ds').plot(figsize=(12, 8))\nax.set_ylabel('Weekly Sales of Beverages')\nax.set_xlabel('Date')\n\nplt.show()\n\n</code></pre>"},{"location":"blog/2023/09/10/building-scalable-time-series-models-with-facebook-prophet/#building-the-model","title":"Building the Model","text":"<p>Now that we have our data ready, we can proceed with building the Prophet model. We'll set the uncertainty interval to 95% to create a more robust forecast:</p> <pre><code>from fbprophet import Prophet\n\n# Create the Prophet model\nbev_model = Prophet(interval_width=0.95)\n\n# Fit the model to the data\nbev_model.fit(df)\n\n</code></pre>"},{"location":"blog/2023/09/10/building-scalable-time-series-models-with-facebook-prophet/#generating-forecasts","title":"Generating Forecasts","text":"<p>To generate forecasts, we need to create a dataframe containing future dates. We'll use the make_future_dataframe function for this:</p> <pre><code># Create a dataframe with future dates\nfuture_dates = bev_model.make_future_dataframe(periods=13, freq='W')\n\n# Display the last few rows of the future dates dataframe\nfuture_dates.tail()\n\n</code></pre> <p>Now, let's use our trained model to make forecasts:</p> <pre><code># Generate forecasts\nforecast = bev_model.predict(future_dates)\n\n# Display the last few rows of the forecast data\nforecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()\n\n</code></pre>"},{"location":"blog/2023/09/10/building-scalable-time-series-models-with-facebook-prophet/#visualizing-the-forecast","title":"Visualizing the Forecast","text":"<p>We can visualize the forecasted values along with uncertainty intervals using the following code:</p> <pre><code># Visualize the forecast\nbev_model.plot(forecast, uncertainty=True)\n\n</code></pre>"},{"location":"blog/2023/09/10/building-scalable-time-series-models-with-facebook-prophet/#interpreting-the-results","title":"Interpreting the Results","text":"<p>Prophet also provides valuable insights into the components of the time series. You can visualize trends, seasonality, and holidays using the following code:</p> <pre><code># Visualize components of the forecast\nbev_model.plot_components(forecast)\n\n</code></pre>"},{"location":"blog/2023/09/10/building-scalable-time-series-models-with-facebook-prophet/#conclusion","title":"Conclusion","text":"<p>Facebook Prophet is a powerful tool for building time series models at scale. In this blog post, we've covered the basic steps of using Prophet to prepare and analyze time series data, build forecasts, and visualize the results. If you're interested in trying it out yourself, you can access the Colab notebook with the complete code and examples here:</p> <p>Colab Notebook Link</p> <p>With Prophet, you can efficiently tackle time series forecasting tasks and gain valuable insights from your data. Give it a try and see how it can enhance your forecasting capabilities. Happy forecasting!</p>"},{"location":"blog/2024/09/11/ai-large-language-models-llms-2024-a-comprehensive-report/","title":"AI Large Language Models (LLMs) 2024: A Comprehensive Report","text":""},{"location":"blog/2024/09/11/ai-large-language-models-llms-2024-a-comprehensive-report/#1-scaling-laws-and-efficiency","title":"1. Scaling Laws and Efficiency","text":"<p>In 2024, AI LLMs have continued to follow scaling laws, achieving higher performance through increased parameters and data. However, recent advancements have focused on improving efficiency with innovative model architectures that reduce computational costs while maintaining or even enhancing performance.</p>"},{"location":"blog/2024/09/11/ai-large-language-models-llms-2024-a-comprehensive-report/#improved-computational-efficiency","title":"Improved Computational Efficiency","text":"<ul> <li>Sparse Models: Researchers have developed more efficient sparse models that selectively activate only relevant parts of the network during inference. This innovation reduces the computational load and energy consumption without sacrificing performance significantly. For example, the Mixture of Experts (MoE) architecture has become more refined, allowing for larger models with fewer active parameters per inference.</li> <li>Quantization and Pruning: Techniques like quantization (reducing the precision of the model\u2019s weights) and pruning (removing less important neurons) have become more sophisticated. These methods have decreased the computational complexity and memory footprint of LLMs, making them more accessible for real-time applications and deployment on edge devices.</li> </ul>"},{"location":"blog/2024/09/11/ai-large-language-models-llms-2024-a-comprehensive-report/#data-efficiency","title":"Data Efficiency","text":"<ul> <li>Smarter Data Utilization: Scaling laws have highlighted the importance of not just more data, but cleaner and more relevant data. Advanced data curation techniques and synthetic data generation have improved the quality of training datasets, resulting in better model performance with less data.</li> <li>Active Learning: By leveraging active learning, models can now identify the most informative data points to learn from, reducing the need for vast amounts of labeled data and accelerating the training process.</li> </ul>"},{"location":"blog/2024/09/11/ai-large-language-models-llms-2024-a-comprehensive-report/#algorithmic-improvements","title":"Algorithmic Improvements","text":"<ul> <li>Adaptive Computation Time: New algorithms have been developed to dynamically adjust the computation time based on the complexity of the input. This has led to more efficient processing, where simpler inputs require less computational effort, thereby saving resources.</li> <li>Meta-Learning and Transfer Learning: Meta-learning approaches have improved, allowing models to learn how to learn more effectively from fewer examples. Transfer learning has also become more efficient, enabling the reuse of pre-trained models across different tasks with minimal fine-tuning.</li> </ul>"},{"location":"blog/2024/09/11/ai-large-language-models-llms-2024-a-comprehensive-report/#hardware-advancements","title":"Hardware Advancements","text":"<ul> <li>Specialized AI Hardware: The development of AI-specific hardware, such as Tensor Processing Units (TPUs) and neuromorphic chips, has paralleled the scaling laws. These hardware advancements provide the necessary computational power to train and deploy larger models efficiently.</li> <li>Energy-Efficient Chips: Innovations in chip design have focused on reducing energy consumption. Energy-efficient architectures, like those employing reduced precision arithmetic and optimized for parallel processing, have become mainstream.</li> </ul>"},{"location":"blog/2024/09/11/ai-large-language-models-llms-2024-a-comprehensive-report/#model-distillation","title":"Model Distillation","text":"<ul> <li>Knowledge Distillation: Techniques for transferring knowledge from larger models (teachers) to smaller, more efficient models (students) have advanced. This process, known as knowledge distillation, allows for maintaining high performance while significantly reducing model size and computational requirements.</li> </ul>"},{"location":"blog/2024/09/11/ai-large-language-models-llms-2024-a-comprehensive-report/#2-fine-tuning-techniques","title":"2. Fine-Tuning Techniques","text":"<p>There has been significant progress in fine-tuning LLMs using techniques like LoRA (Low-Rank Adaptation) and P-tuning. These methods allow for more efficient adaptation to specific tasks and domains without the need for massive computational resources.</p>"},{"location":"blog/2024/09/11/ai-large-language-models-llms-2024-a-comprehensive-report/#low-rank-adaptation-lora","title":"Low-Rank Adaptation (LoRA)","text":"<p>Concept: Low-Rank Adaptation (LoRA) is a fine-tuning technique that focuses on reducing the number of trainable parameters in large language models by approximating weight updates with low-rank matrices. This method leverages the insight that the changes required to adapt a pre-trained model to a new task often lie in a lower-dimensional subspace.</p> <p>Key Components: 1. Low-Rank Decomposition: LoRA decomposes the weight updates into low-rank matrices, significantly reducing the number of parameters that need to be fine-tuned. 2. Efficiency: By reducing the number of trainable parameters, LoRA decreases the computational resources and time required for fine-tuning, making it feasible to adapt very large models on smaller hardware. 3. Performance: Despite the reduction in parameters, LoRA maintains competitive performance with traditional fine-tuning techniques, often achieving comparable or even superior results on various downstream tasks.</p> <p>Recent Developments: 1. Integration with Transformer Models: Recent works have integrated LoRA into transformer architectures, demonstrating its effectiveness in fine-tuning models like GPT-3 and BERT on specific NLP tasks. 2. Hybrid Approaches: Combining LoRA with other techniques, such as knowledge distillation and pruning, has shown further improvements in both efficiency and performance. 3. Applications: LoRA has been successfully applied in areas like text classification, question answering, and machine translation, showing its versatility across different NLP applications.</p>"},{"location":"blog/2024/09/11/ai-large-language-models-llms-2024-a-comprehensive-report/#p-tuning","title":"P-tuning","text":"<p>Concept: P-tuning, or Prompt-based Tuning, is a fine-tuning technique that involves learning soft prompts (continuous embeddings) that guide the model's behavior during inference. Instead of modifying the model's weights directly, P-tuning optimizes these prompts to steer the model towards the desired output.</p> <p>Key Components: 1. Prompt Embeddings: P-tuning optimizes prompt embeddings that are prepended to the input text, influencing the model's predictions without altering its original parameters. 2. Flexibility: This technique allows for flexible adaptations to various tasks by simply adjusting the learned prompts, making it easier to switch between tasks. 3. Scalability: P-tuning is highly scalable, as it requires only the optimization of prompt embeddings, which is computationally inexpensive compared to full model fine-tuning.</p> <p>Recent Developments: 1. Enhanced Prompt Engineering: Advances in prompt engineering have led to the development of more effective prompt templates and initialization strategies, improving the performance of P-tuning. 2. Task-Specific Prompts: Research has shown that task-specific prompts can significantly enhance the performance of models on specialized tasks, such as sentiment analysis and named entity recognition. 3. Few-Shot Learning: P-tuning has been particularly effective in few-shot learning scenarios, where only a small amount of labeled data is available. By leveraging prompt embeddings, models can achieve high accuracy with minimal data.</p> <p>Comparative Analysis: - Parameter Efficiency: Both LoRA and P-tuning aim to reduce the number of trainable parameters, but LoRA does so by decomposing weight updates, while P-tuning uses prompt embeddings. - Flexibility: P-tuning offers greater flexibility for task switching due to its prompt-based approach, whereas LoRA requires re-optimization of low-rank matrices for each new task. - Performance: Both techniques have shown competitive performance across various tasks, with specific advantages depending on the application and data availability.</p>"},{"location":"blog/2024/09/11/ai-large-language-models-llms-2024-a-comprehensive-report/#3-contextual-understanding","title":"3. Contextual Understanding","text":"<p>LLMs have improved dramatically in their ability to understand and maintain context over longer conversations and documents. This has been achieved through enhanced memory mechanisms and better training datasets that include long-form texts.</p>"},{"location":"blog/2024/09/11/ai-large-language-models-llms-2024-a-comprehensive-report/#enhanced-memory-mechanisms","title":"Enhanced Memory Mechanisms","text":"<ul> <li>Transformers with Extended Context Windows: New transformer architectures have been developed that can handle longer context windows, allowing models to retain and reference information over extended passages of text.</li> <li>Memory-Augmented Models: Techniques such as memory networks and recurrent memory mechanisms have been integrated into LLMs, enabling them to store and retrieve information across longer sequences.</li> </ul>"},{"location":"blog/2024/09/11/ai-large-language-models-llms-2024-a-comprehensive-report/#improved-training-datasets","title":"Improved Training Datasets","text":"<ul> <li>Long-Form Texts: Training datasets now include more long-form texts, such as books, articles, and multi-turn conversations, which help models learn to maintain coherence and context over extended interactions.</li> <li>Diverse Sources: Data is sourced from a variety of domains, ensuring that models are exposed to diverse linguistic structures and content types, improving their contextual understanding.</li> </ul>"},{"location":"blog/2024/09/11/ai-large-language-models-llms-2024-a-comprehensive-report/#real-world-applications","title":"Real-World Applications","text":"<ul> <li>Customer Support: LLMs are now better at handling multi-turn customer support interactions, maintaining context across multiple exchanges and providing more accurate and relevant responses.</li> <li>Interactive Storytelling: Enhanced contextual understanding enables LLMs to create more coherent and engaging narratives in interactive storytelling applications.</li> </ul>"},{"location":"blog/2024/09/11/ai-large-language-models-llms-2024-a-comprehensive-report/#4-multimodal-capabilities","title":"4. Multimodal Capabilities","text":"<p>The integration of multimodal inputs (text, image, audio) into LLMs has become more sophisticated. Models like GPT-4 Vision, which can process and generate text based on images, are leading the way in creating more versatile AI systems.</p>"},{"location":"blog/2024/09/11/ai-large-language-models-llms-2024-a-comprehensive-report/#advanced-multimodal-models","title":"Advanced Multimodal Models","text":"<ul> <li>GPT-4 Vision: This model can understand and generate text based on visual inputs, enabling applications like image captioning, visual question answering, and content generation based on visual prompts.</li> <li>Audio-Text Models: Models that integrate audio inputs have been developed, allowing for tasks like speech recognition, transcription, and audio-based content generation.</li> </ul>"},{"location":"blog/2024/09/11/ai-large-language-models-llms-2024-a-comprehensive-report/#applications","title":"Applications","text":"<ul> <li>Enhanced Search Engines: Multimodal capabilities improve search engines by allowing users to query using text, images, and audio, providing more accurate and relevant results.</li> <li>Content Creation: Creators can use multimodal models to generate content that combines text, images, and audio, enhancing the richness and diversity of their output.</li> </ul>"},{"location":"blog/2024/09/11/ai-large-language-models-llms-2024-a-comprehensive-report/#5-ethical-ai-and-bias-mitigation","title":"5. Ethical AI and Bias Mitigation","text":"<p>Addressing ethical concerns and bias in LLMs has been a major focus. New techniques for bias detection and mitigation, including adversarial training and fairness-aware algorithms, have been implemented to create more equitable AI systems.</p>"},{"location":"blog/2024/09/11/ai-large-language-models-llms-2024-a-comprehensive-report/#bias-detection-and-mitigation-techniques","title":"Bias Detection and Mitigation Techniques","text":"<ul> <li>Adversarial Training: This technique involves training models with adversarial examples to make them more robust against biased inputs and to reduce the propagation of biases in their outputs.</li> <li>Fairness-Aware Algorithms: Algorithms designed to ensure fair treatment across different groups are being integrated into LLMs, helping to mitigate bias and promote ethical outcomes.</li> </ul>"},{"location":"blog/2024/09/11/ai-large-language-models-llms-2024-a-comprehensive-report/#policy-and-regulation","title":"Policy and Regulation","text":"<ul> <li>Ethical Guidelines: Organizations and governments are establishing ethical guidelines and best practices for the development and deployment of LLMs to ensure they are used responsibly.</li> <li>Transparency and Accountability: Efforts are being made to increase the transparency of AI systems and hold developers accountable for the ethical implications of their models.</li> </ul>"},{"location":"blog/2024/09/11/ai-large-language-models-llms-2024-a-comprehensive-report/#6-personalization-and-adaptability","title":"6. Personalization and Adaptability","text":"<p>Advances in personalization techniques allow LLMs to adapt to individual user preferences and styles. This has improved user experience in applications such as virtual assistants, customer service, and content creation.</p>"},{"location":"blog/2024/09/11/ai-large-language-models-llms-2024-a-comprehensive-report/#personalization-techniques","title":"Personalization Techniques","text":"<ul> <li>User Profiling: LLMs can create detailed user profiles based on interactions, preferences, and feedback, enabling them to tailor responses and recommendations to individual users.</li> <li>Adaptive Learning: Models can continuously learn from user interactions, adapting their behavior and responses over time to better meet user needs.</li> </ul>"},{"location":"blog/2024/09/11/ai-large-language-models-llms-2024-a-comprehensive-report/#applications_1","title":"Applications","text":"<ul> <li>Virtual Assistants: Personalized virtual assistants can provide more relevant and helpful responses, improving user satisfaction and engagement.</li> <li>Content Generation: Personalized content generation tools can create content that matches the style and preferences of individual users, enhancing creativity and productivity.</li> </ul>"},{"location":"blog/2024/09/11/ai-large-language-models-llms-2024-a-comprehensive-report/#7-open-source-and-collaboration","title":"7. Open-Source and Collaboration","text":"<p>The AI community has seen a surge in open-source contributions, with organizations like EleutherAI and Hugging Face releasing powerful LLMs and tools. These collaborative efforts are accelerating innovation and democratizing access to advanced AI technologies.</p>"},{"location":"blog/2024/09/11/ai-large-language-models-llms-2024-a-comprehensive-report/#open-source-contributions","title":"Open-Source Contributions","text":"<ul> <li>EleutherAI: This organization has released several open-source LLMs, providing researchers and developers with access to powerful models for experimentation and development.</li> <li>Hugging Face: Known for its Transformers library, Hugging Face has made significant contributions to the open-source AI community, offering tools and models that are widely used in NLP research and applications.</li> </ul>"},{"location":"blog/2024/09/11/ai-large-language-models-llms-2024-a-comprehensive-report/#impact-on-innovation","title":"Impact on Innovation","text":"<ul> <li>Accelerated Development: Open-source contributions enable faster innovation by allowing researchers to build on existing work, share insights, and collaborate on new projects.</li> <li>Democratization of AI: By making advanced AI technologies accessible to a broader audience, open-source initiatives are helping to democratize AI and ensure that its benefits are widely distributed.</li> </ul>"},{"location":"blog/2024/09/11/ai-large-language-models-llms-2024-a-comprehensive-report/#8-regulatory-and-policy-developments","title":"8. Regulatory and Policy Developments","text":"<p>Governments and international bodies are increasingly focusing on AI regulation. New policies aimed at ensuring the ethical use of LLMs while fostering innovation have been proposed and, in some cases, implemented.</p>"},{"location":"blog/2024/09/11/ai-large-language-models-llms-2024-a-comprehensive-report/#regulatory-frameworks","title":"Regulatory Frameworks","text":"<ul> <li>AI Ethics Guidelines: Governments and organizations are developing guidelines to ensure the ethical development and deployment of AI systems, addressing issues such as bias, transparency, and accountability.</li> <li>Data Privacy Regulations: New data privacy laws and regulations are being enacted to protect user data and ensure that AI systems are developed and used responsibly.</li> </ul>"},{"location":"blog/2024/09/11/ai-large-language-models-llms-2024-a-comprehensive-report/#impact-on-ai-development","title":"Impact on AI Development","text":"<ul> <li>Compliance Requirements: Developers and organizations must comply with new regulations, which may impact the design and deployment of AI systems.</li> <li>Innovation Incentives: Some policies include incentives for ethical AI research and development, encouraging the creation of technologies that benefit society while minimizing harm.</li> </ul>"},{"location":"blog/2024/09/11/ai-large-language-models-llms-2024-a-comprehensive-report/#9-real-time-applications","title":"9. Real-Time Applications","text":"<p>LLMs are being deployed in real-time applications, including real-time translation, interactive storytelling, and dynamic content generation. These applications are becoming more practical with improvements in latency and response time.</p>"},{"location":"blog/2024/09/11/ai-large-language-models-llms-2024-a-comprehensive-report/#real-time-translation","title":"Real-Time Translation","text":"<ul> <li>Instantaneous Translation: LLMs can provide real-time translation services, enabling seamless communication across language barriers in applications such as video conferencing and live events.</li> </ul>"},{"location":"blog/2024/09/11/ai-large-language-models-llms-2024-a-comprehensive-report/#interactive-storytelling","title":"Interactive Storytelling","text":"<ul> <li>Dynamic Narratives: Real-time interactive storytelling applications allow users to engage with AI-generated narratives that adapt and evolve based on user input, creating immersive and personalized experiences.</li> </ul>"},{"location":"blog/2024/09/11/ai-large-language-models-llms-2024-a-comprehensive-report/#dynamic-content-generation","title":"Dynamic Content Generation","text":"<ul> <li>Real-Time Content Creation: LLMs can generate content on-the-fly, enabling applications such as real-time news generation, personalized marketing content, and interactive educational tools.</li> </ul>"},{"location":"blog/2024/09/11/ai-large-language-models-llms-2024-a-comprehensive-report/#10-quantum-computing-synergy","title":"10. Quantum Computing Synergy","text":"<p>There is growing interest in the potential synergy between quantum computing and LLMs. Early research suggests that quantum computing could exponentially increase the efficiency of training and inference processes for large language models.</p>"},{"location":"blog/2024/09/11/ai-large-language-models-llms-2024-a-comprehensive-report/#quantum-computing-advancements","title":"Quantum Computing Advancements","text":"<ul> <li>Quantum Algorithms: Researchers are developing quantum algorithms that could accelerate the training of LLMs by leveraging the unique computational capabilities of quantum processors.</li> <li>Hybrid Quantum-Classical Models: Hybrid approaches that combine classical and quantum computing are being explored to enhance the performance and efficiency of LLMs.</li> </ul>"},{"location":"blog/2024/09/11/ai-large-language-models-llms-2024-a-comprehensive-report/#future-prospects","title":"Future Prospects","text":"<ul> <li>Exponential Speedup: Quantum computing has the potential to provide exponential speedup for certain computational tasks, which could revolutionize the training and deployment of large language models.</li> <li>New Research Directions: The intersection of quantum computing and LLMs is opening new research directions, with the potential to unlock unprecedented capabilities in AI.</li> </ul> <p>In conclusion, the advancements in AI LLMs in 2024 span a wide range of areas, from scaling laws and efficiency to ethical AI, personalization, and real-time applications. The integration of multimodal capabilities, open-source contributions, and regulatory developments are shaping the future of AI, while the potential synergy with quantum computing promises exciting new possibilities. These developments collectively contribute to the ongoing evolution and impact of AI LLMs in various fields and applications.</p>"},{"location":"blog/2023/08/30/embracing-monorepos-for-microservices-advantages-challenges-and-best-practices/","title":"Embracing Monorepos for Microservices: Advantages, Challenges, and Best Practices","text":"<p>In modern software development, the choice between monorepos and polyrepos (multiple repositories) has become a pivotal decision for teams, particularly those working with microservices. Monorepos, a single repository housing all application and microservice code, offer an array of benefits when combined with streamlined build and deploy pipelines.  In this article, we explore the advantages, misconceptions, challenges, and best practices of monorepos to help you determine whether this approach is the right fit for your team's development journey.</p>"},{"location":"blog/2023/08/30/embracing-monorepos-for-microservices-advantages-challenges-and-best-practices/#monorepo-unveiled","title":"Monorepo Unveiled","text":"<p>A monorepo consolidates diverse application components into a single source code repository, promoting unified development and deployment. The implementation of automated build and deployment pipelines within a monorepo can substantially mitigate common development hurdles, while concurrently enhancing teamwork and productivity.</p>"},{"location":"blog/2023/08/30/embracing-monorepos-for-microservices-advantages-challenges-and-best-practices/#advantages-of-monorepos","title":"Advantages of Monorepos","text":"<ul> <li> <p>Enhanced Visibility: When working on microservices that interact with others, a monorepo provides clear visibility, making it easier to understand and debug issues within your code or interconnected microservices.</p> </li> <li> <p>Efficient Code Sharing: Storing shared libraries, models, and utility code in a single repository fosters efficient code sharing across multiple microservices, eliminating code duplication and streamlining development.</p> </li> <li> <p>Seamless Collaboration: Silos between teams are eradicated in a monorepo environment, allowing for streamlined collaboration and maintenance of cohesive microservice sets.</p> </li> <li> <p>Standardization: Standardizing code and tools across teams becomes simpler with monorepos, enabling the enforcement of best practices, naming conventions, and code review policies.</p> </li> <li> <p>Enhanced Discoverability: The consolidated view of the entire codebase within a monorepo facilitates tracking status, changes, and branches, resulting in improved release management and refactoring.</p> </li> <li> <p>Streamlined Release Management: Monorepos retain comprehensive deployment knowledge, making automated build and deploy pipelines more effective than those found in polyrepos.</p> </li> <li> <p>Facilitated Refactoring: The direct accessibility to all microservices encourages efficient code refactoring, including code structure changes and movement between folders.</p> </li> </ul>"},{"location":"blog/2023/08/30/embracing-monorepos-for-microservices-advantages-challenges-and-best-practices/#monorepo-challenges","title":"Monorepo Challenges","text":"<p>While the advantages are clear, monorepos aren't devoid of challenges. Altering shared code might affect multiple application components, leading to intricate merging processes. Additionally, scaling the source control management system and refining the deployment process can be demanding tasks.</p>"},{"location":"blog/2023/08/30/embracing-monorepos-for-microservices-advantages-challenges-and-best-practices/#debunking-misconceptions","title":"Debunking Misconceptions","text":"<ul> <li> <p>Language and Tool Diversity: The belief that multiple languages and tools hinder a unified build process can be countered through containerization. Container images housing microservices enable uniform builds, allowing testing and deployment as individual units within the monorepo.</p> </li> <li> <p>Tight Coupling: While monorepos might seem to encourage tightly-coupled code, proper adherence to microservice principles and guidelines can prevent this. Independent, loosely-coupled units of code communicating through APIs maintain the microservices architecture pattern.</p> </li> <li> <p>Independent Updates: Contrary to the notion that monorepos inhibit independent updates, advanced deployment strategies such as blue-green or canary deployment can ensure smooth updates while minimizing disruptions.</p> </li> </ul>"},{"location":"blog/2023/08/30/embracing-monorepos-for-microservices-advantages-challenges-and-best-practices/#navigating-the-decision-monorepo-or-polyrepo","title":"Navigating the Decision: Monorepo or Polyrepo?","text":"<p>Making the choice between monorepos and polyrepos involves assessing your team's culture and discipline. A collaborative and disciplined team can leverage the advantages of a monorepo. Implementing branch policies and permission restrictions further reinforce the separation of microservices and maintain efficient deployments.</p>"},{"location":"blog/2023/08/30/embracing-monorepos-for-microservices-advantages-challenges-and-best-practices/#embrace-monorepos-with-confidence","title":"Embrace Monorepos with Confidence","text":"<p>If a monorepo aligns with your team's strengths and development culture, consider integrating a unified, automated CI/CD pipeline. This approach empowers seamless management of your monorepo while upholding your rapid deployment pace.</p> <p>In conclusion, monorepos present a compelling case for microservices development by enhancing visibility, collaboration, code sharing, and more. However, the decision to adopt a monorepo should be made with careful consideration of your team's dynamics. When embraced thoughtfully and supported by robust CI/CD pipelines, monorepos can be a valuable asset in your software development journey.</p>"},{"location":"blog/2024/07/22/product-lifecycle-the-power-of-llm-for-content-development/","title":"Product Lifecycle: The power of LLM for content development","text":"<p>In the ever-evolving world of business and product management, understanding the product lifecycle is crucial for success. This lifecycle encompasses the various stages a product goes through, from its initial development to its eventual decline. This blog post, generated using ChatGPT and visualized with the help of Markmap, offers a comprehensive and concise guide to the product lifecycle, logically organized in a tree structure.</p>"},{"location":"blog/2024/07/22/product-lifecycle-the-power-of-llm-for-content-development/#generate-contents-using-chatgpt-promt","title":"Generate contents using chatGPT promt","text":"<p>promt: <code>Create a list about the product lifecycle</code></p> <p>Response: </p> <pre><code># Product Lifecycle\n\n- Development\n  - Idea Generation\n  - Concept Development\n  - Market Research\n  - Prototyping\n  - Product Design\n  - Testing\n  - Final Product Preparation\n\n- Introduction\n  - Product Launch\n  - Market Entry\n  - Initial Sales\n  - Marketing Campaigns\n\n\n- Growth\n  - Increasing Sales\n  - Market Expansion\n  - Brand Recognition\n  - Product Improvements\n\n\n- Maturity\n  - Peak Sales\n  - Market Saturation\n  - Product Differentiation\n  - Cost Optimization\n\n- Decline\n  - Reduced Sales\n  - Cost Management\n  - Product Discontinuation\n</code></pre>"},{"location":"blog/2024/07/22/product-lifecycle-the-power-of-llm-for-content-development/#visualize-using-markmap","title":"Visualize using  markmap","text":"Markmap"},{"location":"blog/2024/11/24/crafting-expert-level-text-redaction-with-generative-ai-a-step-by-step-guide/","title":"Crafting Expert-Level Text Redaction with Generative AI: A Step-by-Step Guide","text":"<p>Generative AI continues to redefine how we handle text processing, making it possible to transform raw, unstructured drafts into polished, tone-appropriate, and dialect-specific outputs. Whether you need a formal British redaction for a professional email or an informal American rewrite for a casual blog post, AI-powered tools streamline this process with remarkable efficiency.</p> <p>In this blog post, we\u2019ll explore how to build a Text Redaction and Conversion Application using Streamlit, LangChain, and OpenAI. Let\u2019s dive into the nitty-gritty!</p>"},{"location":"blog/2024/11/24/crafting-expert-level-text-redaction-with-generative-ai-a-step-by-step-guide/#the-vision-behind-the-application","title":"The Vision Behind the Application","text":"<p>Imagine being able to input a rough draft and, with a few clicks, receive a perfectly rewritten text tailored to your preferred tone and dialect. This application is ideal for:</p> <ul> <li>Content creators refining their drafts.</li> <li>Business professionals preparing communication for international audiences.</li> <li>Writers and bloggers adapting their style for different audiences.</li> </ul> <p>Our app simplifies this task by:</p> <ul> <li>Redacting poorly worded drafts.</li> <li>Customizing the text\u2019s tone (formal or informal).</li> <li>Adapting the text to American or British English.</li> </ul>"},{"location":"blog/2024/11/24/crafting-expert-level-text-redaction-with-generative-ai-a-step-by-step-guide/#the-tech-stack","title":"The Tech Stack","text":"<p>To achieve this functionality, we\u2019ll use:</p> <ul> <li>Streamlit: A simple and intuitive framework for building web apps.</li> <li>LangChain: A framework to handle AI prompts and chain logic.</li> <li>OpenAI API: The engine powering the language model for text rewriting.</li> </ul>"},{"location":"blog/2024/11/24/crafting-expert-level-text-redaction-with-generative-ai-a-step-by-step-guide/#building-the-application","title":"Building the Application","text":""},{"location":"blog/2024/11/24/crafting-expert-level-text-redaction-with-generative-ai-a-step-by-step-guide/#setting-up-streamlit","title":"Setting Up Streamlit","text":"<p>Streamlit is the foundation of our app, offering an interactive interface for user input and output.</p> <pre><code>import streamlit as st\n\nst.set_page_config(\n    page_title=\"Re-write Text\",\n    page_icon=\"\ud83e\uddca\",\n    layout=\"centered\",\n    initial_sidebar_state=\"expanded\",\n    menu_items={\n        \"Get Help\": \"https://genaiexpertise.com/contact/\",\n        \"Report a bug\": \"https://github.com/genaiexpertise/RAGApps/issues\",\n        \"About\": \"https://genaiexpertise.com\",\n    },\n)\n\nst.header(\"Redact and Convert Text to a Specified Tone and Dialect\")\n\n</code></pre>"},{"location":"blog/2024/11/24/crafting-expert-level-text-redaction-with-generative-ai-a-step-by-step-guide/#creating-the-prompt-template","title":"Creating the Prompt Template","text":"<p>A prompt template defines how the text redaction process operates. It includes instructions for redacting, selecting tones, and adapting dialects.</p> <pre><code>from langchain import PromptTemplate\n\ntemplate = \"\"\"\n    Below is a draft text that may be poorly worded.\n    Your goal is to:\n    - Properly redact the draft text\n    - Convert the draft text to a specified tone\n    - Convert the draft text to a specified dialect\n\n    Here are some examples:\n\n    Tones:\n    - Formal: Greetings! OpenAI has announced Sam Altman is rejoining the company.\n    - Informal: Hey everyone, Sam Altman is back at OpenAI! \n\n    Dialects:\n    - American: apartment, garbage, cookie\n    - British: flat, rubbish, biscuit\n\n    Draft: {draft}\n    TONE: {tone}\n    DIALECT: {dialect}\n\n    YOUR {dialect} RESPONSE:\n\"\"\"\nprompt = PromptTemplate(\n    input_variables=[\"tone\", \"dialect\", \"draft\"],\n    template=template,\n)\n\n\n</code></pre>"},{"location":"blog/2024/11/24/crafting-expert-level-text-redaction-with-generative-ai-a-step-by-step-guide/#integrating-openai-for-text-redaction","title":"Integrating OpenAI for Text Redaction","text":"<p>To process user inputs, we integrate OpenAI\u2019s API with a function that loads the LLM.</p> <pre><code>from langchain_openai import OpenAI\n\ndef load_LLM(openai_api_key):\n    llm = OpenAI(temperature=0.7, openai_api_key=openai_api_key)\n    return llm\n\n</code></pre>"},{"location":"blog/2024/11/24/crafting-expert-level-text-redaction-with-generative-ai-a-step-by-step-guide/#user-inputs-for-tone-and-dialect","title":"User Inputs for Tone and Dialect","text":"<p>The app collects the draft, tone, and dialect preferences using Streamlit widgets.</p> <pre><code># Draft text input\ndraft_input = st.text_area(label=\"Enter your draft text\", placeholder=\"Your Text...\", key=\"draft_input\")\n\n# Tone and dialect selection\ncol1, col2 = st.columns(2)\nwith col1:\n    option_tone = st.selectbox('Select Tone', ['Formal', 'Informal'])\nwith col2:\n    option_dialect = st.selectbox('Select Dialect', ['American', 'British'])\n\n</code></pre>"},{"location":"blog/2024/11/24/crafting-expert-level-text-redaction-with-generative-ai-a-step-by-step-guide/#generating-rewritten-text","title":"Generating Rewritten Text","text":"<p>When the user clicks the \"Re-write\" button, the app processes the input using the prompt and displays the output.</p> <pre><code>if st.button(\"Re-write\"):\n    if draft_input:\n        openai_api_key = st.sidebar.text_input(\"Enter OpenAI API Key\", type=\"password\")\n        if not openai_api_key:\n            st.warning(\"Please provide your OpenAI API Key.\")\n            st.stop()\n\n        llm = load_LLM(openai_api_key=openai_api_key)\n        prompt_with_draft = prompt.format(\n            tone=option_tone,\n            dialect=option_dialect,\n            draft=draft_input\n        )\n        improved_redaction = llm(prompt_with_draft)\n        st.markdown(\"### Your Re-written Text:\")\n        st.write(improved_redaction)\n\n</code></pre>"},{"location":"blog/2024/11/24/crafting-expert-level-text-redaction-with-generative-ai-a-step-by-step-guide/#features-of-the-application","title":"Features of the Application","text":"<ol> <li> <p>Real-Time Interaction The app processes drafts instantly, providing real-time feedback and allowing users to iterate on their text quickly.</p> </li> <li> <p>Customization Options Users can choose between formal and informal tones and adapt the text for American or British audiences.</p> </li> <li> <p>Accessibility The user-friendly interface makes it simple for non-technical users to leverage advanced AI capabilities.</p> </li> </ol>"},{"location":"blog/2024/11/24/crafting-expert-level-text-redaction-with-generative-ai-a-step-by-step-guide/#why-this-matters","title":"Why This Matters","text":"<p>Generative AI is a game-changer for text editing and adaptation. Whether you're a professional writer or a casual user, this tool saves time and ensures your text is tailored to your audience\u2019s preferences.</p>"},{"location":"blog/2024/11/24/crafting-expert-level-text-redaction-with-generative-ai-a-step-by-step-guide/#build-your-own-generative-ai-solutions","title":"Build Your Own Generative AI Solutions","text":"<p>Ready to integrate generative AI into your projects? GenAIExpertise specializes in crafting bespoke AI solutions tailored to your needs. Let\u2019s bring your ideas to life!</p>"},{"location":"blog/2024/07/21/uncovering-school-performance-patterns-a-comprehensive-data-analysis/","title":"Uncovering School Performance Patterns: A Comprehensive Data Analysis","text":"<p>Exploring educational data can provide deep insights into student performance and school effectiveness. In this blog post, I will guide you through a detailed analysis of a school dataset, explaining each step and the insights we gain from the data. This comprehensive analysis will help in understanding the distribution of student performance across different schools and identifying key areas for improvement.</p>"},{"location":"blog/2024/07/21/uncovering-school-performance-patterns-a-comprehensive-data-analysis/#reading-and-exploring-the-dataset","title":"Reading and Exploring the Dataset","text":"<p>To begin, we read the dataset into a dataframe and examine the structure and initial rows:</p> <pre><code>Filename &lt;- '../data/data-storyteller.csv'\nschool_df &lt;- read.csv(Filename, na.strings = c(\"\"))\nhead(school_df, n=7)\nstr(school_df)\n\n</code></pre> <p>The dataset contains columns with different data types, such as integers and factors. Notably, the Section column is an integer but should be converted to a categorical (ordered factor) type. The rest of the columns have the correct data types.</p>"},{"location":"blog/2024/07/21/uncovering-school-performance-patterns-a-comprehensive-data-analysis/#data-preparation","title":"Data Preparation","text":"<p>We start by converting the Section column to an ordered factor:</p> <pre><code>school_df$Section &lt;- as.ordered(school_df$Section)\nstr(school_df$Section)\n\n</code></pre> <p>Next, we check for any missing values using a custom function:</p> <pre><code>checkMissingData &lt;- function(TestData){\n  for(colname in names(TestData)){\n    cat(\"\\n Looking at column...\", colname, \"\\n\")\n    NAcount &lt;- sum(is.na(TestData[colname]))\n    cat(\"\\nThe number of missing values in column \", colname, \"is \", NAcount)\n  }\n}\ncheckMissingData(school_df)\n\n\n</code></pre> <p>We find that there are no missing values in the dataset.</p>"},{"location":"blog/2024/07/21/uncovering-school-performance-patterns-a-comprehensive-data-analysis/#summarizing-the-data","title":"Summarizing the Data","text":"<p>We summarize the dataset to get an overview of its structure:</p> <pre><code>summary(school_df)\n\n</code></pre> <p>The summary reveals that schools D and E have only one record each, while school C has three, school B has twelve, and school A has thirteen. There are no students who are very ahead in any school.</p>"},{"location":"blog/2024/07/21/uncovering-school-performance-patterns-a-comprehensive-data-analysis/#renaming-columns","title":"Renaming Columns","text":"<p>For better readability, we rename the columns:</p> <pre><code>new_col_name &lt;- c('School', 'Section', 'Very_Ahead', 'Middling', 'Behind', 'More_Behind', 'Very_Behind', 'Completed')\ncolnames(school_df) &lt;- new_col_name\nhead(school_df, n=5)\n\n</code></pre>"},{"location":"blog/2024/07/21/uncovering-school-performance-patterns-a-comprehensive-data-analysis/#checking-for-duplicates","title":"Checking for Duplicates","text":"<p>We check for duplicate records in the dataset:</p> <pre><code>nrow(school_df) # total number of rows\nnrow(school_df[duplicated(school_df),]) # duplicate check\n\n</code></pre> <p>There are no duplicate records in the dataset.</p>"},{"location":"blog/2024/07/21/uncovering-school-performance-patterns-a-comprehensive-data-analysis/#analyzing-outliers","title":"Analyzing Outliers","text":"<p>We use boxplots to check for any incorrect records or outliers:</p> <pre><code>boxplot(school_df[,-c(1,2)])\n\n</code></pre> <p>We find that the Completed and More_Behind columns have outliers. A deeper dive into the Completed column shows an unusual record with 27 completions, which stands out compared to other schools. Similarly, school A has an abnormally high number of students who are more behind compared to other schools.</p>"},{"location":"blog/2024/07/21/uncovering-school-performance-patterns-a-comprehensive-data-analysis/#data-distribution","title":"Data Distribution","text":"<p>We visualize the data distribution for each numeric column using various plots. For instance, the distribution of sessions is shown below:</p> <pre><code>d &lt;- ggplot(school_df, aes(Section)) + geom_bar(color='green', fill='blue') + theme_classic() + ggtitle('Frequency Distribution of Sessions')\nd\n\n</code></pre> <p>We create similar plots for Middling, Behind, More_Behind, Very_Behind, and Completed using ggplot2.</p>"},{"location":"blog/2024/07/21/uncovering-school-performance-patterns-a-comprehensive-data-analysis/#school-and-section-analysis","title":"School and Section Analysis","text":"<p>We analyze the relationship between schools and sections using count plots:</p> <pre><code>p &lt;- ggplot(school_df, aes(School, Section)) + geom_count(color='red', fill='blue', size=7) + theme_classic()\np\n\n</code></pre>"},{"location":"blog/2024/07/21/uncovering-school-performance-patterns-a-comprehensive-data-analysis/#detailed-analysis-by-school","title":"Detailed Analysis by School","text":"<p>We create various plots to analyze each school\u2019s performance in different categories such as Middling, Behind, More_Behind, Very_Behind, and Completed.</p> <pre><code>plot_grid(m, n, o, p, nrow = 2, ncol = 2, labels = 'AUTO')\n\n</code></pre>"},{"location":"blog/2024/07/21/uncovering-school-performance-patterns-a-comprehensive-data-analysis/#correlation-analysis","title":"Correlation Analysis","text":"<p>We perform correlation tests between different variables to understand their relationships:</p> <pre><code>cor.test(school_df$Middling, school_df$Completed)\ncor.test(school_df$Behind, school_df$Very_Behind)\n\n</code></pre>"},{"location":"blog/2024/07/21/uncovering-school-performance-patterns-a-comprehensive-data-analysis/#aggregation-and-summary","title":"Aggregation and Summary","text":"<p>We aggregate the data by school to get a summary of total students and the percentage of students who have completed their studies:</p> <pre><code>df_agg &lt;- aggregate(df_new[,-c(1,2)], by = list(df_new[,1]), FUN = sum)\nper_completed &lt;- (df_agg[,7]/df_agg[,8]) * 100\ndf_new &lt;- data.frame(df_agg, per_completed)\ndf_new\n\n</code></pre>"},{"location":"blog/2024/07/21/uncovering-school-performance-patterns-a-comprehensive-data-analysis/#conclusion","title":"Conclusion","text":"<p>Through this detailed analysis, we have uncovered various insights into the school dataset. From identifying outliers to understanding the distribution and correlations within the data, we have highlighted key areas that could help improve educational strategies and student performance tracking.</p> <p>Stay tuned for more data-driven stories and insights!</p>"},{"location":"blog/2023/11/09/unveiling-strength-mapping-leveraging-role-preferences-for-team-success/","title":"Unveiling Strength Mapping: Leveraging Role Preferences for Team Success","text":"<p>In today's dynamic and collaborative work environment, understanding and harnessing the unique strengths within your team is essential for achieving success. Strength mapping, when coupled with a thorough understanding of role preferences, can be a powerful tool in optimizing team performance. In this blog post, we'll explore the concept of strength mapping within a team context and delve into the role preferences of team members to unlock their potential.</p>"},{"location":"blog/2023/11/09/unveiling-strength-mapping-leveraging-role-preferences-for-team-success/#whole-team-strengths-and-risks","title":"Whole Team Strengths and Risks","text":"<p>Before we delve into individual role preferences, it's crucial to assess the collective strengths and risks of your team as a whole. This holistic perspective provides a foundation for effective strength mapping:</p> <ul> <li> <p>Strengths of Our Team: Recognizing the strengths of your team as a whole allows you to understand the qualities that set your group apart. These strengths can include a diverse skill set, strong communication, adaptability, and a shared vision.</p> </li> <li> <p>Risks for Our Team: Identifying potential risks is equally important. Risks might include communication gaps, conflicts, lack of diversity in perspectives, or resource limitations. Recognizing these risks empowers your team to proactively address them.</p> </li> </ul>"},{"location":"blog/2023/11/09/unveiling-strength-mapping-leveraging-role-preferences-for-team-success/#preference-group-contributions","title":"Preference Group Contributions","text":"<p>Understanding role preferences within your team is vital for optimizing collaboration. Here, we explore the roles and contributions of various preference groups and highlight the precious aspects they bring to the team:</p> <ul> <li> <p>Networking: This group excels at making contacts and seeking resources outside the team. Their ability to connect with external partners can open doors to new opportunities. However, they should be aware of potential limitations, such as over-enthusiasm and a tendency to lose interest quickly.</p> </li> <li> <p>Creator: As potential sources of innovative ideas and solutions, creators can drive your team's success. However, they may need to work on being less sensitive to critical evaluation of their ideas.</p> </li> <li> <p>Reviewing - Completers: Completers ensure deadlines are met and focus on the details, making them valuable for task completion. However, they may seem overly anxious about sticking to the plan and can be less involved in generating new ideas.</p> </li> <li> <p>Reviewing - Evaluators: Evaluators bring objectivity to the group, preventing it from going off track. However, their quiet and analytical nature may frustrate others by remaining in the background until the last minute.</p> </li> <li> <p>Leading - Driver: Drivers lead from the front, shape tasks, and drive progress. Their competitive nature can be an asset, but they need to be cautious not to come across as aggressive and impatient.</p> </li> <li> <p>Leading - Organizer: Organizers harness the team's talents and coordinate work with the team's well-being in mind. However, they should be careful not to appear detached or disengaged from others.</p> </li> <li> <p>Operating - Teambuilder: Teambuilders promote a harmonious and cooperative atmosphere. Their ability to make the team feel good is valuable, but they should be aware of their tendency to avoid conflict and potential indecisiveness.</p> </li> <li> <p>Operating - Implementor: Implementors break down big ideas into actionable details and are focused on execution. However, they may resist changes and appear disinterested in anything other than the task at hand.</p> </li> </ul>"},{"location":"blog/2023/11/09/unveiling-strength-mapping-leveraging-role-preferences-for-team-success/#conclusion","title":"Conclusion","text":"<p>Understanding the role preferences and strengths within your team is the first step towards effective strength mapping. By recognizing the contributions and limitations of each group, you can leverage the collective potential of your team, leading to improved collaboration, innovation, and overall success. The combination of strength mapping and role preference awareness can be a game-changer for your team, helping you navigate challenges and maximize your potential.</p>"},{"location":"blog/2023/11/09/unveiling-strength-mapping-leveraging-role-preferences-for-team-success/#template","title":"Template","text":""},{"location":"blog/2023/09/04/adding-a-voice-to-your-projects-a-guide-to-creating-voiceovers-with-python/","title":"Adding a Voice to Your Projects: A Guide to Creating Voiceovers with Python","text":"<p>In today's digital age, adding a personal touch to your projects can make a significant difference in user engagement and accessibility. One creative way to achieve this is by incorporating voiceovers into your applications, websites, or multimedia presentations. In this blog post, we'll explore a Python script that utilizes the pyttsx3 library to generate voiceovers from text. We'll walk through the code and discuss how you can enhance your projects with voiceovers.</p>"},{"location":"blog/2023/09/04/adding-a-voice-to-your-projects-a-guide-to-creating-voiceovers-with-python/#the-power-of-voiceovers","title":"The Power of Voiceovers","text":"<p>Voiceovers can provide numerous benefits to your projects:</p> <ul> <li> <p>Accessibility: Voiceovers make your content accessible to individuals with visual impairments or those who prefer auditory learning.</p> </li> <li> <p>Engagement: Adding a human voice can create a more engaging and immersive experience for users.</p> </li> <li> <p>Personalization: You can tailor voiceovers to match the tone and style of your project, adding a unique touch.</p> </li> <li> <p>Multilingual Support: Easily provide content in multiple languages by generating voiceovers for each.</p> </li> </ul>"},{"location":"blog/2023/09/04/adding-a-voice-to-your-projects-a-guide-to-creating-voiceovers-with-python/#lets-dive-into-the-code","title":"Let's dive into the code:","text":"<pre><code>\nimport pyttsx3\n\nvoiceoverDir = \"Voiceovers\"\n\ndef create_voice_over(fileName, text):\n    filePath = f\"{voiceoverDir}/{fileName}.mp3\"\n    engine = pyttsx3.init()\n    engine.save_to_file(text, filePath)\n    engine.runAndWait()\n    return filePath\n\nif __name__=='__main__':\n    fileName = 'filename'\n    text = 'Hello world'\n    path = create_voice_over(fileName, text)\n    print(path)\n\n\n</code></pre>"},{"location":"blog/2023/09/04/adding-a-voice-to-your-projects-a-guide-to-creating-voiceovers-with-python/#how-the-code-works","title":"How the Code Works","text":"<p>Importing Libraries: We start by importing the pyttsx3 library, which allows us to work with text-to-speech conversion.</p> <ul> <li> <p>Setting Voiceover Directory: The voiceoverDir variable specifies the directory where the generated voiceovers will be stored. You can customize this directory as needed.</p> </li> <li> <p>create_voice_over Function: This function takes two arguments: fileName (the desired name of the output file) and text (the text you want to convert into a voiceover).</p> </li> <li> <p>File Path: The function constructs the file path by combining the voiceoverDir, fileName, and '.mp3' extension.</p> </li> <li> <p>Initializing the Engine: We initialize the text-to-speech engine using pyttsx3.init().</p> </li> <li> <p>Saving to File: The engine.save_to_file(text, filePath) method generates the voiceover from the input text and saves it to the specified file path.</p> </li> <li> <p>Running and Returning: engine.runAndWait() ensures that the voiceover generation process is completed before moving on. The function then returns the file path of the generated voiceover.</p> </li> <li> <p>Main Section: In the if name=='main': section, we define the fileName and text variables with the desired values. The create_voice_over function is called with these values to generate a voiceover.</p> </li> <li> <p>Print Path: Finally, we print the path of the generated voiceover file.</p> </li> </ul>"},{"location":"blog/2023/09/04/adding-a-voice-to-your-projects-a-guide-to-creating-voiceovers-with-python/#conclusion","title":"Conclusion","text":"<p>Incorporating voiceovers into your projects can elevate the user experience and accessibility of your content. With the help of Python and the pyttsx3 library, you can easily convert text into voiceovers and add a unique dimension to your applications, websites, or multimedia presentations. Experiment with different texts, voices, and languages to create voiceovers that resonate with your audience and enhance your projects.</p>"},{"location":"blog/2024/08/17/deploying-a-wine-prediction-model-using-fastapi-on-railway/","title":"Deploying a Wine Prediction Model Using FastAPI on Railway","text":"<p>In the world of data science, creating a machine learning model is only half the battle. The real challenge lies in deploying that model so it can be accessed and utilized by end users. In this blog post, I'll walk you through how to deploy a wine prediction model using FastAPI and Railway, an efficient and modern web framework for Python that allows you to easily build APIs. We'll also reference the GitHub repository where the code for this project is hosted: Toraaglobal/deploy-model-using-fastapi.</p>"},{"location":"blog/2024/08/17/deploying-a-wine-prediction-model-using-fastapi-on-railway/#overview-of-the-wine-prediction-model","title":"Overview of the Wine Prediction Model","text":"<p>The wine prediction model is built using a classifier that predicts the class of a wine based on various chemical properties. The model is saved as a pickle file and loaded into a FastAPI application to serve predictions via a RESTful API.</p>"},{"location":"blog/2024/08/17/deploying-a-wine-prediction-model-using-fastapi-on-railway/#setting-up-the-fastapi-application","title":"Setting Up the FastAPI Application","text":"<p>First, let's dive into the code. Below is the FastAPI application that handles predictions:</p> <pre><code>import pickle\nimport numpy as np\nfrom typing import List\nfrom fastapi import FastAPI\nfrom pydantic import BaseModel, conlist\n\napp = FastAPI(title=\"Predicting Wine Class\")\n\n# Represents a particular wine (or datapoint)\nclass Wine(BaseModel):\n    alcohol: float\n    malic_acid: float\n    ash: float\n    alcalinity_of_ash: float\n    magnesium: float\n    total_phenols: float\n    flavanoids: float\n    nonflavanoid_phenols: float\n    proanthocyanins: float\n    color_intensity: float\n    hue: float\n    od280_od315_of_diluted_wines: float\n    proline: float\n\n# Represents a batch of wines\nclass WineBatch(BaseModel):\n    batches: List[conlist(item_type=float, min_length=13, max_length=13)]\n\n@app.on_event(\"startup\")\ndef load_clf():\n    # Load classifier from pickle file\n    with open(\"./models/wine.pkl\", \"rb\") as file:\n        global clf\n        clf = pickle.load(file)\n\n@app.get(\"/\")\ndef home():\n    return \"Congratulations! Your API is working as expected. Now head over /docs for the API docs\"\n\n@app.post(\"/predict\")\ndef predict(wine: Wine):\n    data_point = np.array(\n        [\n            [\n                wine.alcohol,\n                wine.malic_acid,\n                wine.ash,\n                wine.alcalinity_of_ash,\n                wine.magnesium,\n                wine.total_phenols,\n                wine.flavanoids,\n                wine.nonflavanoid_phenols,\n                wine.proanthocyanins,\n                wine.color_intensity,\n                wine.hue,\n                wine.od280_od315_of_diluted_wines,\n                wine.proline,\n            ]\n        ]\n    )\n\n    pred = clf.predict(data_point).tolist()\n    pred = pred[0]\n    print(pred)\n    return {\"Prediction\": pred}\n\n@app.post(\"/batch/predict\")\ndef predict(wine: WineBatch):\n    batches = wine.batches\n    np_batches = np.array(batches)\n    pred = clf.predict(np_batches).tolist()\n    return {\"Prediction\": pred}\n\n\n</code></pre>"},{"location":"blog/2024/08/17/deploying-a-wine-prediction-model-using-fastapi-on-railway/#code-explanation","title":"Code Explanation","text":""},{"location":"blog/2024/08/17/deploying-a-wine-prediction-model-using-fastapi-on-railway/#wine-and-winebatch-classes","title":"Wine and WineBatch Classes:","text":"<ul> <li>The Wine class represents a single wine instance with 13 attributes (e.g., alcohol, malic acid, etc.).</li> <li>The WineBatch class handles batches of wine instances. It ensures that each batch contains exactly 13 float values corresponding to the features.</li> </ul>"},{"location":"blog/2024/08/17/deploying-a-wine-prediction-model-using-fastapi-on-railway/#model-loading","title":"Model Loading:","text":"<ul> <li>The load_clf function is triggered during the startup of the FastAPI application. It loads the pre-trained wine classification model from a pickle file, making it available globally within the app.</li> </ul>"},{"location":"blog/2024/08/17/deploying-a-wine-prediction-model-using-fastapi-on-railway/#endpoints","title":"Endpoints:","text":"<ul> <li>Home (/): A simple GET endpoint to verify that the API is running.</li> <li>Predict (/predict): A POST endpoint that takes a single wine instance and returns the predicted class.</li> <li>Batch Predict (/batch/predict): A POST endpoint for predicting the classes of multiple wine instances in a single request.</li> </ul>"},{"location":"blog/2024/08/17/deploying-a-wine-prediction-model-using-fastapi-on-railway/#deployment-on-railway","title":"Deployment on Railway","text":"<p>Railway is a platform that allows you to deploy applications with ease. Follow these steps to deploy the Toraaglobal website on Railway:</p> <ul> <li> <p>Sign Up/Log In to Railway: If you don't already have an account, sign up at Railway.</p> </li> <li> <p>Create a New Project:</p> <ul> <li>After logging in, click on \"New Project\" from the dashboard.</li> <li>Select \"Deploy from GitHub repo\" and connect your GitHub account if you haven't done so already.</li> <li>Choose the repository from your list of repositories.</li> </ul> </li> <li> <p>Deploy the Project:</p> <ul> <li>Once everything is configured, click \"Deploy\" to start the deployment process.</li> <li>After deployment, you can access your site via the domain provided by Railway, or you can set up a custom domain (e.g., www.toraaglobal.com).</li> </ul> </li> <li> <p>Monitor and Manage: Railway provides logs and metrics to help you monitor the performance of your site. Use these tools to ensure everything is running smoothly.</p> </li> </ul>"},{"location":"blog/2024/08/17/deploying-a-wine-prediction-model-using-fastapi-on-railway/#conclusion","title":"Conclusion","text":"<p>By following this guide, you should now have a good understanding of how to deploy a machine learning model using FastAPI and Rail. This setup allows you to easily serve predictions through a RESTful API, making your model accessible to users or other systems. For the complete code and more details, visit the GitHub repository.</p> <p>Happy coding!</p>"},{"location":"blog/2024/11/24/content-summarization-with-generative-ai-a-step-by-step-guide-to-building-a-summarizer-with-streamlit-and-langchain/","title":"Content Summarization with Generative AI: A Step-By-Step Guide to Building a Summarizer with Streamlit and LangChain","text":"<p>Generative AI is transforming how we interact with content by automating complex tasks like summarizing videos and articles. Imagine distilling the key points of an hour-long YouTube lecture or a lengthy blog post into concise insights in seconds. This blog post walks you through the creation of a YouTube Video and Web Content Summarizer, leveraging tools like LangChain, Groq's Gemma-7b-It model, and Streamlit. Let's dive in!</p>"},{"location":"blog/2024/11/24/content-summarization-with-generative-ai-a-step-by-step-guide-to-building-a-summarizer-with-streamlit-and-langchain/#the-vision-behind-the-summarizer","title":"The Vision Behind the Summarizer","text":"<p>In today\u2019s fast-paced world, spending hours sifting through video content or lengthy articles isn\u2019t always practical. An AI-powered summarizer saves time by extracting key takeaways instantly, helping users stay informed and productive.</p> <p>Our app achieves this by:</p> <ul> <li>Extracting key points from YouTube videos.</li> <li>Summarizing long-form articles and blog posts in seconds.</li> <li>Empowering professionals, students, and content enthusiasts with actionable insights.</li> </ul>"},{"location":"blog/2024/11/24/content-summarization-with-generative-ai-a-step-by-step-guide-to-building-a-summarizer-with-streamlit-and-langchain/#the-tech-stack","title":"The Tech Stack","text":"<p>Here\u2019s the arsenal of tools we\u2019ll use:</p> <ul> <li>Streamlit: A powerful framework for building interactive web apps.</li> <li>LangChain: A framework for developing applications powered by language models.</li> <li>Groq's Gemma-7b-It Model: A high-performance LLM for natural language tasks.</li> <li>Custom Content Loaders: Tools for fetching and processing YouTube videos and website content.</li> </ul>"},{"location":"blog/2024/11/24/content-summarization-with-generative-ai-a-step-by-step-guide-to-building-a-summarizer-with-streamlit-and-langchain/#building-the-app-step-by-step","title":"Building the App: Step-by-Step","text":""},{"location":"blog/2024/11/24/content-summarization-with-generative-ai-a-step-by-step-guide-to-building-a-summarizer-with-streamlit-and-langchain/#setup-and-configuration","title":"Setup and Configuration","text":"<p>Start by configuring the Streamlit app with a sleek UI and instructions for users.</p> <pre><code>import streamlit as st\n\nst.set_page_config(page_title=\"YouTube Video and Web Content Summarizer\", page_icon=\"\ud83e\udd9c\")\nst.title(\"\ud83e\udd9cYouTube Video and Web Content Summarizer\")\n\nst.sidebar.markdown(\"\"\"\n- Extract key takeaways from YouTube videos\n- Summarize long-form articles and blog posts in seconds\n- Save time and increase productivity with our fast and accurate summarization engine\n\"\"\")\n\n</code></pre>"},{"location":"blog/2024/11/24/content-summarization-with-generative-ai-a-step-by-step-guide-to-building-a-summarizer-with-streamlit-and-langchain/#user-inputs-and-api-key-integration","title":"User Inputs and API Key Integration","text":"<p>The app requires an API key for Groq's LLM and a URL input for content to summarize.</p> <pre><code>groq_api_key = st.sidebar.text_input(\"Groq API Key\", value=\"\", type=\"password\")\ngeneric_url = st.text_input(\"URL\", label_visibility=\"collapsed\")\n\n</code></pre>"},{"location":"blog/2024/11/24/content-summarization-with-generative-ai-a-step-by-step-guide-to-building-a-summarizer-with-streamlit-and-langchain/#content-loading-and-validation","title":"Content Loading and Validation","text":"<p>he app supports both YouTube video URLs and generic website URLs. Validation ensures users provide valid inputs.</p> <pre><code>import validators\nfrom langchain_community.document_loaders import YoutubeLoader, UnstructuredURLLoader\n\nif st.button(\"Summarize the Content from YT or Website\"):\n    if not groq_api_key.strip() or not generic_url.strip():\n        st.error(\"Please provide the information to get started\")\n    elif not validators.url(generic_url):\n        st.error(\"Please enter a valid URL.\")\n    else:\n        try:\n            with st.spinner(\"Waiting...\"):\n                if \"youtube.com\" in generic_url:\n                    loader = YoutubeLoader.from_youtube_url(generic_url, add_video_info=True)\n                else:\n                    loader = UnstructuredURLLoader(urls=[generic_url], ssl_verify=False, headers={\"User-Agent\": \"Mozilla/5.0\"})\n                docs = loader.load()\n\n</code></pre>"},{"location":"blog/2024/11/24/content-summarization-with-generative-ai-a-step-by-step-guide-to-building-a-summarizer-with-streamlit-and-langchain/#summarization-chain","title":"Summarization Chain","text":"<p>The summarizer relies on LangChain's summarization chain to process content using a custom prompt.</p> <pre><code>from langchain.prompts import PromptTemplate\nfrom langchain.chains.summarize import load_summarize_chain\nfrom langchain_groq import ChatGroq\n\nllm = ChatGroq(model=\"Gemma-7b-It\", groq_api_key=groq_api_key)\n\nprompt_template = \"\"\"\nProvide a detailed summary of the following content:\nContent: {text}\n\"\"\"\nprompt = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\nchain = load_summarize_chain(llm, chain_type=\"stuff\", prompt=prompt)\n\noutput_summary = chain.run(docs)\nst.success(output_summary)\n\n</code></pre>"},{"location":"blog/2024/11/24/content-summarization-with-generative-ai-a-step-by-step-guide-to-building-a-summarizer-with-streamlit-and-langchain/#exception-handling","title":"Exception Handling","text":"<p>Robust exception handling ensures that the app gracefully manages errors.</p> <pre><code>except Exception as e:\n    st.exception(f\"Exception: {e}\")\n\n</code></pre>"},{"location":"blog/2024/11/24/content-summarization-with-generative-ai-a-step-by-step-guide-to-building-a-summarizer-with-streamlit-and-langchain/#the-final-product","title":"The Final Product","text":"<p>The app combines a clean, user-friendly interface with powerful backend processing to deliver fast, accurate summaries. It\u2019s an excellent tool for:</p> <ul> <li>Researchers looking to scan large amounts of content quickly.</li> <li>Educators summarizing teaching materials.</li> <li>Professionals staying updated without reading full articles.</li> </ul>"},{"location":"blog/2024/11/24/content-summarization-with-generative-ai-a-step-by-step-guide-to-building-a-summarizer-with-streamlit-and-langchain/#why-choose-generative-ai-for-summarization","title":"Why Choose Generative AI for Summarization?","text":"<p>Generative AI models like Groq's Gemma-7b-It excel at understanding and condensing information. They produce summaries that are not only concise but also contextually rich, saving time without sacrificing quality.</p>"},{"location":"blog/2024/11/24/content-summarization-with-generative-ai-a-step-by-step-guide-to-building-a-summarizer-with-streamlit-and-langchain/#bring-your-ai-projects-to-life","title":"Bring Your AI Projects to Life","text":"<p>Interested in creating AI-powered applications tailored to your business needs? Contact GenAIExpertise and let\u2019s build innovative solutions together.</p>"},{"location":"datascience_on_aws/ab_testing_auto_scaling/","title":"AB Testing and Auto Scaling","text":""},{"location":"datascience_on_aws/ab_testing_auto_scaling/#ab-testing-traffic-shifting-and-autoscaling","title":"A/B testing, traffic shifting and autoscaling","text":""},{"location":"datascience_on_aws/ab_testing_auto_scaling/#introduction","title":"Introduction","text":"<p>In this lab you will create an endpoint with multiple variants, splitting the traffic between them. Then after testing and reviewing the endpoint performance metrics, you will shift the traffic to one variant and configure it to autoscale.</p> <p>Let's install and import the required modules.</p> <pre><code># please ignore warning messages during the installation\n!pip install --disable-pip-version-check -q sagemaker==2.35.0\n!conda install -q -y pytorch==1.6.0 -c pytorch\n!pip install --disable-pip-version-check -q transformers==3.5.1\n</code></pre> <pre><code>\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting package metadata (current_repodata.json): ...working... done\nSolving environment: ...working... done\n\n# All requested packages already installed.\n\nRetrieving notices: ...working... done\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n</code></pre> <pre><code>import matplotlib.pyplot as plt\n%matplotlib inline\n%config InlineBackend.figure_format='retina'\n</code></pre> <pre><code>import boto3\nimport sagemaker\nimport pandas as pd\nimport botocore\n\nconfig = botocore.config.Config(user_agent_extra='dlai-pds/c3/w2')\n\n# low-level service client of the boto3 session\nsm = boto3.client(service_name='sagemaker', \n                  config=config)\n\nsm_runtime = boto3.client('sagemaker-runtime',\n                          config=config)\n\nsess = sagemaker.Session(sagemaker_client=sm,\n                         sagemaker_runtime_client=sm_runtime)\n\nbucket = sess.default_bucket()\nrole = sagemaker.get_execution_role()\nregion = sess.boto_region_name\n\ncw = boto3.client(service_name='cloudwatch', \n                  config=config)\n\nautoscale = boto3.client(service_name=\"application-autoscaling\", \n                         config=config)\n</code></pre>                         Clean data in minutes                     Automatically visualize data, and improve data quality in a few clicks. Learn more Import Data Wrangler widget Remind me later Don't show again <p></p>"},{"location":"datascience_on_aws/ab_testing_auto_scaling/#1-create-an-endpoint-with-multiple-variants","title":"1. Create an endpoint with multiple variants","text":"<p>Two models trained to analyze customer feedback and classify the messages into positive (1), neutral (0), and negative (-1) sentiments are saved in the following S3 bucket paths. These <code>tar.gz</code> files contain the model artifacts, which result from model training.</p> <pre><code>model_a_s3_uri = 's3://dlai-practical-data-science/models/ab/variant_a/model.tar.gz'\nmodel_b_s3_uri = 's3://dlai-practical-data-science/models/ab/variant_b/model.tar.gz'\n</code></pre> <p>Let's deploy an endpoint splitting the traffic between these two models 50/50 to perform A/B Testing. Instead of creating a PyTorch Model object and calling <code>model.deploy()</code> function, you will create an <code>Endpoint configuration</code> with multiple model variants. Here is the workflow you will follow to create an endpoint:</p> <p></p> <p></p>"},{"location":"datascience_on_aws/ab_testing_auto_scaling/#11-construct-docker-image-uri","title":"1.1. Construct Docker Image URI","text":"<p>You will need to create the models in Amazon SageMaker, which retrieves the URI for the pre-built SageMaker Docker image stored in Amazon Elastic Container Re gistry (ECR). Let's construct the ECR URI which you will pass into the <code>create_model</code> function later.</p> <p>Set the instance type. For the purposes of this lab, you will use a relatively small instance. Please refer to this link for additional instance types that may work for your use cases outside of this lab.</p> <pre><code>inference_instance_type = 'ml.m5.large'\n</code></pre> <p></p>"},{"location":"datascience_on_aws/ab_testing_auto_scaling/#exercise-1","title":"Exercise 1","text":"<p>Create an ECR URI using the <code>'PyTorch'</code> framework. Review other parameters of the image.</p> <pre><code>inference_image_uri = sagemaker.image_uris.retrieve(\n    ### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n    framework='pytorch', # Replace None\n    ### END SOLUTION - DO NOT delete this comment for grading purposes\n    version='1.6.0',\n    instance_type=inference_instance_type,\n    region=region,\n    py_version='py3',\n    image_scope='inference'\n)\nprint(inference_image_uri)\n</code></pre> <pre><code>763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-inference:1.6.0-cpu-py3\n</code></pre> <p></p>"},{"location":"datascience_on_aws/ab_testing_auto_scaling/#12-create-amazon-sagemaker-models","title":"1.2. Create Amazon SageMaker Models","text":"<p>Amazon SageMaker Model includes information such as the S3 location of the model, the container image that can be used for inference with that model, the execution role, and the model name. </p> <p>Let's construct the model names.</p> <pre><code>import time\nfrom pprint import pprint\n\ntimestamp = int(time.time())\n\nmodel_name_a = '{}-{}'.format('a', timestamp)\nmodel_name_b = '{}-{}'.format('b', timestamp)\n</code></pre> <p>You will use the following function to check if the model already exists in Amazon SageMaker.</p> <pre><code>def check_model_existence(model_name):\n    for model in sm.list_models()['Models']:\n        if model_name == model['ModelName']:\n            return True\n    return False\n</code></pre> <p></p>"},{"location":"datascience_on_aws/ab_testing_auto_scaling/#exercise-2","title":"Exercise 2","text":"<p>Create an Amazon SageMaker Model based on the <code>model_a_s3_uri</code> data.</p> <p>Instructions: Use <code>sm.create_model</code> function, which requires the model name, Amazon SageMaker execution role and a primary container description (<code>PrimaryContainer</code> dictionary). The <code>PrimaryContainer</code> includes the S3 bucket location of the model artifacts (<code>ModelDataUrl</code> key) and ECR URI (<code>Image</code> key).</p> <pre><code>if not check_model_existence(model_name_a):\n    model_a = sm.create_model(\n        ModelName=model_name_a,\n        ExecutionRoleArn=role,\n        PrimaryContainer={\n            ### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n            'ModelDataUrl': model_a_s3_uri, # Replace None\n            'Image': inference_image_uri # Replace None\n            ### END SOLUTION - DO NOT delete this comment for grading purposes\n        }\n    )\n    pprint(model_a)\nelse:\n    print(\"Model {} already exists\".format(model_name_a))\n</code></pre> <pre><code>{'ModelArn': 'arn:aws:sagemaker:us-east-1:514316801160:model/a-1686639191',\n 'ResponseMetadata': {'HTTPHeaders': {'content-length': '74',\n                                      'content-type': 'application/x-amz-json-1.1',\n                                      'date': 'Tue, 13 Jun 2023 06:57:08 GMT',\n                                      'x-amzn-requestid': '9879d633-a426-4cb7-ac5a-19463cc87568'},\n                      'HTTPStatusCode': 200,\n                      'RequestId': '9879d633-a426-4cb7-ac5a-19463cc87568',\n                      'RetryAttempts': 0}}\n</code></pre> <p></p>"},{"location":"datascience_on_aws/ab_testing_auto_scaling/#exercise-3","title":"Exercise 3","text":"<p>Create an Amazon SageMaker Model based on the <code>model_b_s3_uri</code> data.</p> <p>Instructions: Use the example in the cell above.</p> <pre><code>if not check_model_existence(model_name_b):\n    model_b = sm.create_model(\n        ### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n        ModelName=model_name_b, # Replace all None\n        ExecutionRoleArn=role, # Replace all None\n        ### END SOLUTION - DO NOT delete this comment for grading purposes\n        PrimaryContainer={\n            'ModelDataUrl': model_b_s3_uri, \n            'Image': inference_image_uri\n        }\n    )\n    pprint(model_b)\nelse:\n    print(\"Model {} already exists\".format(model_name_b))\n</code></pre> <pre><code>{'ModelArn': 'arn:aws:sagemaker:us-east-1:514316801160:model/b-1686639191',\n 'ResponseMetadata': {'HTTPHeaders': {'content-length': '74',\n                                      'content-type': 'application/x-amz-json-1.1',\n                                      'date': 'Tue, 13 Jun 2023 06:58:13 GMT',\n                                      'x-amzn-requestid': '75585fe2-573d-432f-91de-6f3439c3ba52'},\n                      'HTTPStatusCode': 200,\n                      'RequestId': '75585fe2-573d-432f-91de-6f3439c3ba52',\n                      'RetryAttempts': 0}}\n</code></pre> <p></p>"},{"location":"datascience_on_aws/ab_testing_auto_scaling/#13-set-up-amazon-sagemaker-production-variants","title":"1.3. Set up Amazon SageMaker production variants","text":"<p>A production variant is a packaged SageMaker Model combined with the configuration related to how that model will be hosted. </p> <p>You have constructed the model in the section above. The hosting resources configuration includes information on how you want that model to be hosted: the number and type of instances, a pointer to the SageMaker package model, as well as a variant name and variant weight. A single SageMaker Endpoint can actually include multiple production variants.</p> <p></p>"},{"location":"datascience_on_aws/ab_testing_auto_scaling/#exercise-4","title":"Exercise 4","text":"<p>Create an Amazon SageMaker production variant for the SageMaker Model with the <code>model_name_a</code>.</p> <p>Instructions: Use the <code>production_variant</code> function passing the <code>model_name_a</code> and instance type defined above.</p> <pre><code>variantA = production_variant(\n    model_name=..., # SageMaker Model name\n    instance_type=..., # instance type\n    initial_weight=50, # traffic distribution weight\n    initial_instance_count=1, # instance count\n    variant_name='VariantA', # production variant name\n)\n</code></pre> <pre><code>from sagemaker.session import production_variant\n\nvariantA = production_variant(\n    ### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n    model_name=model_name_a, # Replace None\n    instance_type=inference_instance_type, # Replace None\n    ### END SOLUTION - DO NOT delete this comment for grading purposes\n    initial_weight=50,\n    initial_instance_count=1,\n    variant_name='VariantA',\n)\nprint(variantA)\n</code></pre> <pre><code>{'ModelName': 'a-1686639191', 'InstanceType': 'ml.m5.large', 'InitialInstanceCount': 1, 'VariantName': 'VariantA', 'InitialVariantWeight': 50}\n</code></pre> <p></p>"},{"location":"datascience_on_aws/ab_testing_auto_scaling/#exercise-5","title":"Exercise 5","text":"<p>Create an Amazon SageMaker production variant for the SageMaker Model with the <code>model_name_b</code>.</p> <p>Instructions: See the required arguments in the cell above.</p> <pre><code>variantB = production_variant(\n    ### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n    model_name=model_name_b, # Replace all None\n    instance_type=inference_instance_type, # Replace all None\n    initial_weight=50, # Replace all None\n    ### END SOLUTION - DO NOT delete this comment for grading purposes\n    initial_instance_count=1,\n    variant_name='VariantB'\n)\nprint(variantB)\n</code></pre> <pre><code>{'ModelName': 'b-1686639191', 'InstanceType': 'ml.m5.large', 'InitialInstanceCount': 1, 'VariantName': 'VariantB', 'InitialVariantWeight': 50}\n</code></pre> <p></p>"},{"location":"datascience_on_aws/ab_testing_auto_scaling/#14-configure-and-create-the-endpoint","title":"1.4. Configure and create the endpoint","text":"<p>You will use the following functions to check if the endpoint configuration and endpoint itself already exist in Amazon SageMaker.</p> <pre><code>def check_endpoint_config_existence(endpoint_config_name):\n    for endpoint_config in sm.list_endpoint_configs()['EndpointConfigs']:\n        if endpoint_config_name == endpoint_config['EndpointConfigName']:\n            return True\n    return False\n\ndef check_endpoint_existence(endpoint_name):\n    for endpoint in sm.list_endpoints()['Endpoints']:\n        if endpoint_name == endpoint['EndpointName']:\n            return True\n    return False\n</code></pre> <p>Create the endpoint configuration by specifying the name and pointing to the two production variants that you just configured that tell SageMaker how you want to host those models.</p> <pre><code>endpoint_config_name = '{}-{}'.format('ab', timestamp)\n\nif not check_endpoint_config_existence(endpoint_config_name):\n    endpoint_config = sm.create_endpoint_config(\n        EndpointConfigName=endpoint_config_name, \n        ProductionVariants=[variantA, variantB]\n    )\n    pprint(endpoint_config)\nelse:\n    print(\"Endpoint configuration {} already exists\".format(endpoint_config_name))\n</code></pre> <pre><code>{'EndpointConfigArn': 'arn:aws:sagemaker:us-east-1:514316801160:endpoint-config/ab-1686639191',\n 'ResponseMetadata': {'HTTPHeaders': {'content-length': '94',\n                                      'content-type': 'application/x-amz-json-1.1',\n                                      'date': 'Tue, 13 Jun 2023 07:05:12 GMT',\n                                      'x-amzn-requestid': '763196b4-7e3e-4038-8471-b10c026c85e6'},\n                      'HTTPStatusCode': 200,\n                      'RequestId': '763196b4-7e3e-4038-8471-b10c026c85e6',\n                      'RetryAttempts': 0}}\n</code></pre> <p></p> <p>Construct the endpoint name.</p> <pre><code>model_ab_endpoint_name = '{}-{}'.format('ab', timestamp)\nprint('Endpoint name: {}'.format(model_ab_endpoint_name))\n</code></pre> <pre><code>Endpoint name: ab-1686639191\n</code></pre> <p></p>"},{"location":"datascience_on_aws/ab_testing_auto_scaling/#exercise-6","title":"Exercise 6","text":"<p>Create an endpoint with the endpoint name and configuration defined above.</p> <pre><code>if not check_endpoint_existence(model_ab_endpoint_name):\n    endpoint_response = sm.create_endpoint(\n        ### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n        EndpointName=model_ab_endpoint_name, # Replace None\n        EndpointConfigName=endpoint_config_name # Replace None\n        ### END SOLUTION - DO NOT delete this comment for grading purposes\n    )\n    print('Creating endpoint {}'.format(model_ab_endpoint_name))\n    pprint(endpoint_response)\nelse:\n    print(\"Endpoint {} already exists\".format(model_ab_endpoint_name))\n</code></pre> <pre><code>Creating endpoint ab-1686639191\n{'EndpointArn': 'arn:aws:sagemaker:us-east-1:514316801160:endpoint/ab-1686639191',\n 'ResponseMetadata': {'HTTPHeaders': {'content-length': '81',\n                                      'content-type': 'application/x-amz-json-1.1',\n                                      'date': 'Tue, 13 Jun 2023 07:06:19 GMT',\n                                      'x-amzn-requestid': '0ee03135-1a7a-42be-8535-b03da2a5e63c'},\n                      'HTTPStatusCode': 200,\n                      'RequestId': '0ee03135-1a7a-42be-8535-b03da2a5e63c',\n                      'RetryAttempts': 0}}\n</code></pre> <p>Review the created endpoint configuration in the AWS console.</p> <p>Instructions:</p> <ul> <li>open the link</li> <li>notice that you are in the section Amazon SageMaker -&gt; Endpoint configuration</li> <li>check the name of the endpoint configuration, its Amazon Resource Name (ARN) and production variants</li> <li>click on the production variants and check their container information: image and model data location</li> </ul> <pre><code>from IPython.core.display import display, HTML\n\ndisplay(\n    HTML(\n        '&lt;b&gt;Review &lt;a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={}#/endpointConfig/{}\"&gt;REST Endpoint configuration&lt;/a&gt;&lt;/b&gt;'.format(\n            region, endpoint_config_name\n        )\n    )\n)\n</code></pre> <p>Review REST Endpoint configuration</p> <p>Review the created endpoint in the AWS console.</p> <p>Instructions:</p> <ul> <li>open the link</li> <li>notice that you are in the section Amazon SageMaker -&gt; Endpoints</li> <li>check the name of the endpoint, its ARN and status</li> <li>below you can review the monitoring metrics such as CPU, memory and disk utilization. Further down you can see the endpoint configuration settings with its production variants</li> </ul> <pre><code>from IPython.core.display import display, HTML\n\ndisplay(HTML('&lt;b&gt;Review &lt;a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={}#/endpoints/{}\"&gt;SageMaker REST endpoint&lt;/a&gt;&lt;/b&gt;'.format(region, model_ab_endpoint_name)))\n</code></pre> <p>Review SageMaker REST endpoint</p> <p>Wait for the endpoint to deploy.</p>"},{"location":"datascience_on_aws/ab_testing_auto_scaling/#this-cell-will-take-approximately-5-10-minutes-to-run","title":"This cell will take approximately 5-10 minutes to run.","text":"<pre><code>%%time\n\nwaiter = sm.get_waiter('endpoint_in_service')\nwaiter.wait(EndpointName=model_ab_endpoint_name)\n</code></pre> <pre><code>CPU times: user 59.3 ms, sys: 4.76 ms, total: 64.1 ms\nWall time: 4min 1s\n</code></pre> <p>Wait until the ^^ endpoint ^^ is deployed</p> <p></p>"},{"location":"datascience_on_aws/ab_testing_auto_scaling/#2-test-model","title":"2. Test model","text":""},{"location":"datascience_on_aws/ab_testing_auto_scaling/#21-test-the-model-on-a-few-sample-strings","title":"2.1. Test the model on a few sample strings","text":"<p>Here, you will pass sample strings of text to the endpoint in order to see the sentiment. You are given one example of each, however, feel free to play around and change the strings yourself!</p> <p></p>"},{"location":"datascience_on_aws/ab_testing_auto_scaling/#exercise-7","title":"Exercise 7","text":"<p>Create an Amazon SageMaker Predictor based on the deployed endpoint.</p> <p>Instructions: Use the <code>Predictor</code> object with the following parameters. Please pass JSON serializer and deserializer objects here, calling them with the functions <code>JSONLinesSerializer()</code> and <code>JSONLinesDeserializer()</code>, respectively. More information about the serializers can be found here.</p> <pre><code>predictor = Predictor(\n    endpoint_name=..., # endpoint name\n    serializer=..., # a serializer object, used to encode data for an inference endpoint\n    deserializer=..., # a deserializer object, used to decode data from an inference endpoint\n    sagemaker_session=sess\n)\n</code></pre> <pre><code>from sagemaker.predictor import Predictor\nfrom sagemaker.serializers import JSONLinesSerializer\nfrom sagemaker.deserializers import JSONLinesDeserializer\n\ninputs = [\n    {\"features\": [\"I love this product!\"]},\n    {\"features\": [\"OK, but not great.\"]},\n    {\"features\": [\"This is not the right product.\"]},\n]\n\npredictor = Predictor(\n    ### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n    endpoint_name=model_ab_endpoint_name, # Replace None\n    serializer=JSONLinesSerializer(), # Replace None\n    deserializer=JSONLinesDeserializer(), # Replace None\n    ### END SOLUTION - DO NOT delete this comment for grading purposes\n    sagemaker_session=sess\n)\n\npredicted_classes = predictor.predict(inputs)\n\nfor predicted_class in predicted_classes:\n    print(\"Predicted class {} with probability {}\".format(predicted_class['predicted_label'], predicted_class['probability']))\n</code></pre> <pre><code>Predicted class 1 with probability 0.9605445861816406\nPredicted class 0 with probability 0.5798221230506897\nPredicted class -1 with probability 0.7667604684829712\n</code></pre> <p></p>"},{"location":"datascience_on_aws/ab_testing_auto_scaling/#22-generate-traffic-and-review-the-endpoint-performance-metrics","title":"2.2. Generate traffic and review the endpoint performance metrics","text":"<p>Now you will generate traffic. To analyze the endpoint performance you will review some of the metrics that Amazon SageMaker emits in CloudWatch: CPU Utilization, Latency and Invocations. Full list of namespaces and metrics can be found here. CloudWatch <code>get_metric_statistics</code> documentation can be found here.</p> <p>But before that, let's create a function that will help to extract the results from CloudWatch and plot them.</p> <pre><code>def plot_endpoint_metrics_for_variants(endpoint_name, \n                                       namespace_name, \n                                       metric_name, \n                                       variant_names, \n                                       start_time, \n                                       end_time):\n\n    try:\n        joint_variant_metrics = None\n\n        for variant_name in variant_names:\n            metrics = cw.get_metric_statistics( # extracts the results in a dictionary format\n                Namespace=namespace_name, # the namespace of the metric, e.g. \"AWS/SageMaker\"\n                MetricName=metric_name, # the name of the metric, e.g. \"CPUUtilization\"\n                StartTime=start_time, # the time stamp that determines the first data point to return\n                EndTime=end_time, # the time stamp that determines the last data point to return\n                Period=60, # the granularity, in seconds, of the returned data points\n                Statistics=[\"Sum\"], # the metric statistics\n                Dimensions=[ # dimensions, as CloudWatch treats each unique combination of dimensions as a separate metric\n                    {\"Name\": \"EndpointName\", \"Value\": endpoint_name}, \n                    {\"Name\": \"VariantName\", \"Value\": variant_name}\n                ],\n            )\n\n            if metrics[\"Datapoints\"]: # access the results from the distionary using the key \"Datapoints\"\n                df_metrics = pd.DataFrame(metrics[\"Datapoints\"]) \\\n                    .sort_values(\"Timestamp\") \\\n                    .set_index(\"Timestamp\") \\\n                    .drop(\"Unit\", axis=1) \\\n                    .rename(columns={\"Sum\": variant_name}) # rename the column with the metric results as a variant_name\n\n                if joint_variant_metrics is None:\n                    joint_variant_metrics = df_metrics\n                else:\n                    joint_variant_metrics = joint_variant_metrics.join(df_metrics, how=\"outer\")\n\n        joint_variant_metrics.plot(title=metric_name)\n    except:\n        pass\n</code></pre> <p>Establish wide enough time bounds to show all the charts using the same timeframe:</p> <pre><code>from datetime import datetime, timedelta\n\nstart_time = datetime.now() - timedelta(minutes=30)\nend_time = datetime.now() + timedelta(minutes=30)\n\nprint('Start Time: {}'.format(start_time))\nprint('End Time: {}'.format(end_time))\n</code></pre> <pre><code>Start Time: 2023-06-13 06:44:42.255736\nEnd Time: 2023-06-13 07:44:42.255780\n</code></pre> <p>Set the list of the the variant names to analyze.</p> <pre><code>variant_names = [variantA[\"VariantName\"], variantB[\"VariantName\"]]\n\nprint(variant_names)\n</code></pre> <pre><code>['VariantA', 'VariantB']\n</code></pre> <p>Run some predictions and view the metrics for each variant.</p>"},{"location":"datascience_on_aws/ab_testing_auto_scaling/#this-cell-will-take-approximately-1-2-minutes-to-run","title":"This cell will take approximately 1-2 minutes to run.","text":"<pre><code>%%time\n\nfor i in range(0, 100):\n    predicted_classes = predictor.predict(inputs)\n</code></pre> <pre><code>CPU times: user 254 ms, sys: 12.4 ms, total: 266 ms\nWall time: 1min 31s\n</code></pre> <p>\u039cake sure the predictions ^^ above ^^ ran successfully</p> <p>Let\u2019s query CloudWatch to get a few metrics that are split across variants. If you see <code>Metrics not yet available</code>, please be patient as metrics may take a few mins to appear in CloudWatch.</p> <pre><code>time.sleep(30) # Sleep to accomodate a slight delay in metrics gathering\n</code></pre> <pre><code># CPUUtilization\n# The sum of each individual CPU core's utilization. \n# The CPU utilization of each core can range between 0 and 100. For example, if there are four CPUs, CPUUtilization can range from 0% to 400%.\nplot_endpoint_metrics_for_variants(\n    endpoint_name=model_ab_endpoint_name, \n    namespace_name=\"/aws/sagemaker/Endpoints\", \n    metric_name=\"CPUUtilization\",\n    variant_names=variant_names,\n    start_time=start_time,\n    end_time=end_time\n)\n</code></pre> <p></p> <pre><code># Invocations\n# The number of requests sent to a model endpoint.\nplot_endpoint_metrics_for_variants(\n    endpoint_name=model_ab_endpoint_name, \n    namespace_name=\"AWS/SageMaker\", \n    metric_name=\"Invocations\",\n    variant_names=variant_names,\n    start_time=start_time,\n    end_time=end_time    \n)\n</code></pre> <p></p> <pre><code># InvocationsPerInstance\n# The number of invocations sent to a model, normalized by InstanceCount in each production variant.\nplot_endpoint_metrics_for_variants(\n    endpoint_name=model_ab_endpoint_name, \n    namespace_name=\"AWS/SageMaker\", \n    metric_name=\"InvocationsPerInstance\",\n    variant_names=variant_names,\n    start_time=start_time,\n    end_time=end_time\n)\n</code></pre> <p></p> <pre><code># ModelLatency\n# The interval of time taken by a model to respond as viewed from SageMaker (in microseconds).\nplot_endpoint_metrics_for_variants(\n    endpoint_name=model_ab_endpoint_name, \n    namespace_name=\"AWS/SageMaker\", \n    metric_name=\"ModelLatency\",\n    variant_names=variant_names,\n    start_time=start_time,\n    end_time=end_time\n)\n</code></pre> <p></p> <p></p>"},{"location":"datascience_on_aws/ab_testing_auto_scaling/#3-shift-the-traffic-to-one-variant-and-review-the-endpoint-performance-metrics","title":"3. Shift the traffic to one variant and review the endpoint performance metrics","text":"<p>Generally, the winning model would need to be chosen. The decision would be made based on the endpoint performance metrics and some other business related evaluations. Here you can assume that the winning model is in the Variant B and shift all traffic to it. </p> <p>Construct a list with the updated endpoint weights.</p>"},{"location":"datascience_on_aws/ab_testing_auto_scaling/#no-downtime-occurs-during-this-traffic-shift-activity","title":"No downtime occurs during this traffic-shift activity.","text":""},{"location":"datascience_on_aws/ab_testing_auto_scaling/#this-may-take-a-few-minutes-please-be-patient","title":"This may take a few minutes. Please be patient.","text":"<pre><code>updated_endpoint_config = [\n    {\n        \"VariantName\": variantA[\"VariantName\"],\n        \"DesiredWeight\": 0,\n    },\n    {\n        \"VariantName\": variantB[\"VariantName\"],\n        \"DesiredWeight\": 100,\n    },\n]\n</code></pre>"},{"location":"datascience_on_aws/ab_testing_auto_scaling/#exercise-8","title":"Exercise 8","text":"<p>Update variant weights in the configuration of the existing endpoint.</p> <p>Instructions: Use the <code>sm.update_endpoint_weights_and_capacities</code> function, passing the endpoint name and list of updated weights for each of the variants that you defined above.</p> <pre><code>sm.update_endpoint_weights_and_capacities(\n    ### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n    EndpointName=model_ab_endpoint_name, # Replace None\n    DesiredWeightsAndCapacities=updated_endpoint_config # Replace None\n    ### END SOLUTION - DO NOT delete this comment for grading purposes\n)\n</code></pre> <pre><code>{'EndpointArn': 'arn:aws:sagemaker:us-east-1:514316801160:endpoint/ab-1686639191',\n 'ResponseMetadata': {'RequestId': '89c7ac03-ffca-4129-8868-324645c7226a',\n  'HTTPStatusCode': 200,\n  'HTTPHeaders': {'x-amzn-requestid': '89c7ac03-ffca-4129-8868-324645c7226a',\n   'content-type': 'application/x-amz-json-1.1',\n   'content-length': '81',\n   'date': 'Tue, 13 Jun 2023 07:20:27 GMT'},\n  'RetryAttempts': 0}}\n</code></pre> <p>Wait for the ^^ endpoint update ^^ to complete above</p> <p>This may take a few minutes.  Please be patient.</p>"},{"location":"datascience_on_aws/ab_testing_auto_scaling/#there-is-no-downtime-while-the-update-is-applying","title":"There is no downtime while the update is applying.","text":"<p>While waiting for the update (or afterwards) you can review the endpoint in the AWS console.</p> <p>Instructions:</p> <ul> <li>open the link</li> <li>notice that you are in the section Amazon SageMaker -&gt; Endpoints</li> <li>check the name of the endpoint, its ARN and status (<code>Updating</code> or <code>InService</code>)</li> <li>below you can see the endpoint runtime settings with the updated weights</li> </ul> <pre><code>from IPython.core.display import display, HTML\n\ndisplay(HTML('&lt;b&gt;Review &lt;a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={}#/endpoints/{}\"&gt;SageMaker REST endpoint&lt;/a&gt;&lt;/b&gt;'.format(region, model_ab_endpoint_name)))\n</code></pre> <p>Review SageMaker REST endpoint</p> <pre><code>waiter = sm.get_waiter(\"endpoint_in_service\")\nwaiter.wait(EndpointName=model_ab_endpoint_name)\n</code></pre> <p>Run some more predictions and view the metrics for each variant.</p>"},{"location":"datascience_on_aws/ab_testing_auto_scaling/#this-cell-will-take-approximately-1-2-minutes-to-run_1","title":"This cell will take approximately 1-2 minutes to run.","text":"<pre><code>%%time\n\nfor i in range(0, 100):\n    predicted_classes = predictor.predict(inputs)\n</code></pre> <pre><code>CPU times: user 260 ms, sys: 14.2 ms, total: 274 ms\nWall time: 1min 31s\n</code></pre> <p>\u039cake sure the predictions ^^ above ^^ ran successfully</p> <p>If you see <code>Metrics not yet available</code>, please be patient as metrics may take a few minutes to appear in CloudWatch. Compare the results with the plots above.</p> <pre><code># CPUUtilization\n# The sum of each individual CPU core's utilization. \n# The CPU utilization of each core can range between 0 and 100. For example, if there are four CPUs, CPUUtilization can range from 0% to 400%.\nplot_endpoint_metrics_for_variants(\n    endpoint_name=model_ab_endpoint_name, \n    namespace_name=\"/aws/sagemaker/Endpoints\",\n    metric_name=\"CPUUtilization\",\n    variant_names=variant_names,\n    start_time=start_time,\n    end_time=end_time\n)\n</code></pre> <p></p> <pre><code># Invocations\n# The number of requests sent to a model endpoint.\nplot_endpoint_metrics_for_variants(\n    endpoint_name=model_ab_endpoint_name, \n    namespace_name=\"AWS/SageMaker\", \n    metric_name=\"Invocations\",\n    variant_names=variant_names,\n    start_time=start_time,\n    end_time=end_time    \n)\n</code></pre> <p></p> <pre><code># InvocationsPerInstance\n# The number of invocations sent to a model, normalized by InstanceCount in each production variant.\nplot_endpoint_metrics_for_variants(\n    endpoint_name=model_ab_endpoint_name, \n    namespace_name=\"AWS/SageMaker\", \n    metric_name=\"InvocationsPerInstance\",\n    variant_names=variant_names,\n    start_time=start_time,\n    end_time=end_time    \n)\n</code></pre> <p></p> <pre><code># ModelLatency\n# The interval of time taken by a model to respond as viewed from SageMaker (in microseconds).\nplot_endpoint_metrics_for_variants(\n    endpoint_name=model_ab_endpoint_name, \n    namespace_name=\"AWS/SageMaker\", \n    metric_name=\"ModelLatency\",\n    variant_names=variant_names,\n    start_time=start_time,\n    end_time=end_time    \n)\n</code></pre> <p></p> <p></p>"},{"location":"datascience_on_aws/ab_testing_auto_scaling/#4-configure-one-variant-to-autoscale","title":"4. Configure one variant to autoscale","text":"<p>Let's configure Variant B to autoscale. You would not autoscale Variant A since no traffic is being passed to it at this time.</p> <p>First, you need to define a scalable target. It is an AWS resource and in this case you want to scale a <code>sagemaker</code> resource as indicated in the <code>ServiceNameSpace</code> parameter. Then the <code>ResourceId</code> is a SageMaker Endpoint. Because autoscaling is used by other AWS resources, you\u2019ll see a few parameters that will remain static for scaling SageMaker Endpoints. Thus the <code>ScalableDimension</code> is a set value for SageMaker Endpoint scaling.</p> <p>You also need to specify a few key parameters that control the min and max behavior for your Machine Learning instances. The <code>MinCapacity</code> indicates the minimum number of instances you plan to scale in to. The <code>MaxCapacity</code> is the maximum number of instances you want to scale out to. So in this case you always want to have at least 1 instance running and a maximum of 2 during peak periods. </p> <pre><code>autoscale.register_scalable_target(\n    ServiceNamespace=\"sagemaker\",\n    ResourceId=\"endpoint/\" + model_ab_endpoint_name + \"/variant/VariantB\",\n    ScalableDimension=\"sagemaker:variant:DesiredInstanceCount\",\n    MinCapacity=1,\n    MaxCapacity=2,\n    RoleARN=role,\n    SuspendedState={\n        \"DynamicScalingInSuspended\": False,\n        \"DynamicScalingOutSuspended\": False,\n        \"ScheduledScalingSuspended\": False,\n    },\n)\n</code></pre> <pre><code>{'ScalableTargetARN': 'arn:aws:application-autoscaling:us-east-1:514316801160:scalable-target/056m1a5e507dfa2847b5ae1acf2a1f2cca0c',\n 'ResponseMetadata': {'RequestId': '7a361e6a-6bb5-4ab2-b5e6-a5744418bee3',\n  'HTTPStatusCode': 200,\n  'HTTPHeaders': {'x-amzn-requestid': '7a361e6a-6bb5-4ab2-b5e6-a5744418bee3',\n   'content-type': 'application/x-amz-json-1.1',\n   'content-length': '131',\n   'date': 'Tue, 13 Jun 2023 07:26:01 GMT'},\n  'RetryAttempts': 0}}\n</code></pre> <pre><code>waiter = sm.get_waiter(\"endpoint_in_service\")\nwaiter.wait(EndpointName=model_ab_endpoint_name)\n</code></pre> <p>Check that the parameters from the function above are in the description of the scalable target:</p> <pre><code>autoscale.describe_scalable_targets(\n    ServiceNamespace=\"sagemaker\",\n    MaxResults=100,\n)\n</code></pre> <pre><code>{'ScalableTargets': [{'ServiceNamespace': 'sagemaker',\n   'ResourceId': 'endpoint/ab-1686639191/variant/VariantB',\n   'ScalableDimension': 'sagemaker:variant:DesiredInstanceCount',\n   'MinCapacity': 1,\n   'MaxCapacity': 2,\n   'RoleARN': 'arn:aws:iam::514316801160:role/aws-service-role/sagemaker.application-autoscaling.amazonaws.com/AWSServiceRoleForApplicationAutoScaling_SageMakerEndpoint',\n   'CreationTime': datetime.datetime(2023, 6, 13, 7, 26, 1, 195000, tzinfo=tzlocal()),\n   'SuspendedState': {'DynamicScalingInSuspended': False,\n    'DynamicScalingOutSuspended': False,\n    'ScheduledScalingSuspended': False},\n   'ScalableTargetARN': 'arn:aws:application-autoscaling:us-east-1:514316801160:scalable-target/056m1a5e507dfa2847b5ae1acf2a1f2cca0c'}],\n 'ResponseMetadata': {'RequestId': '3eca7d5f-e38c-48ed-9439-5bf0182cf64f',\n  'HTTPStatusCode': 200,\n  'HTTPHeaders': {'x-amzn-requestid': '3eca7d5f-e38c-48ed-9439-5bf0182cf64f',\n   'content-type': 'application/x-amz-json-1.1',\n   'content-length': '652',\n   'date': 'Tue, 13 Jun 2023 07:26:19 GMT'},\n  'RetryAttempts': 0}}\n</code></pre> <p>Define and apply scaling policy using the <code>put_scaling_policy</code> function. The scaling policy provides additional information about the scaling behavior for your instance. <code>TargetTrackingScaling</code> refers to a specific autoscaling type supported by SageMaker, that uses a scaling metric and a target value as the indicator to scale.</p> <p>In the scaling policy configuration, you have the predefined metric <code>PredefinedMetricSpecification</code> which is the number of invocations on your instance and the <code>TargetValue</code> which indicates the number of invocations per ML instance you want to allow before triggering your scaling policy. A scale out cooldown of 60 seconds means that after autoscaling successfully scales out it starts to calculate the cooldown time. The scaling policy won\u2019t increase the desired capacity again until the cooldown period ends.</p> <p>The scale in cooldown setting of 300 seconds means that SageMaker will not attempt to start another cooldown policy within 300 seconds of when the last one completed.</p> <pre><code>autoscale.put_scaling_policy(\n    PolicyName=\"bert-reviews-autoscale-policy\",\n    ServiceNamespace=\"sagemaker\",\n    ResourceId=\"endpoint/\" + model_ab_endpoint_name + \"/variant/VariantB\",\n    ScalableDimension=\"sagemaker:variant:DesiredInstanceCount\",\n    PolicyType=\"TargetTrackingScaling\",\n    TargetTrackingScalingPolicyConfiguration={\n        \"TargetValue\": 2.0, # the number of invocations per ML instance you want to allow before triggering your scaling policy\n        \"PredefinedMetricSpecification\": {\n            \"PredefinedMetricType\": \"SageMakerVariantInvocationsPerInstance\", # scaling metric\n        },\n        \"ScaleOutCooldown\": 60, # wait time, in seconds, before beginning another scale out activity after last one completes\n        \"ScaleInCooldown\": 300, # wait time, in seconds, before beginning another scale in activity after last one completes\n    },\n)\n</code></pre> <pre><code>{'PolicyARN': 'arn:aws:autoscaling:us-east-1:514316801160:scalingPolicy:1a5e507d-fa28-47b5-ae1a-cf2a1f2cca0c:resource/sagemaker/endpoint/ab-1686639191/variant/VariantB:policyName/bert-reviews-autoscale-policy',\n 'Alarms': [{'AlarmName': 'TargetTracking-endpoint/ab-1686639191/variant/VariantB-AlarmHigh-c3501f58-ec19-4ef2-9052-a68ef13ce449',\n   'AlarmARN': 'arn:aws:cloudwatch:us-east-1:514316801160:alarm:TargetTracking-endpoint/ab-1686639191/variant/VariantB-AlarmHigh-c3501f58-ec19-4ef2-9052-a68ef13ce449'},\n  {'AlarmName': 'TargetTracking-endpoint/ab-1686639191/variant/VariantB-AlarmLow-af42de01-ac7b-4ad9-805f-d7dc95d52a6c',\n   'AlarmARN': 'arn:aws:cloudwatch:us-east-1:514316801160:alarm:TargetTracking-endpoint/ab-1686639191/variant/VariantB-AlarmLow-af42de01-ac7b-4ad9-805f-d7dc95d52a6c'}],\n 'ResponseMetadata': {'RequestId': 'bbc4461e-fb9b-40ce-903b-851b8e61830a',\n  'HTTPStatusCode': 200,\n  'HTTPHeaders': {'x-amzn-requestid': 'bbc4461e-fb9b-40ce-903b-851b8e61830a',\n   'content-type': 'application/x-amz-json-1.1',\n   'content-length': '780',\n   'date': 'Tue, 13 Jun 2023 07:27:28 GMT'},\n  'RetryAttempts': 0}}\n</code></pre> <pre><code>waiter = sm.get_waiter(\"endpoint_in_service\")\nwaiter.wait(EndpointName=model_ab_endpoint_name)\n</code></pre> <p>Generate traffic again and review the endpoint in the AWS console.</p>"},{"location":"datascience_on_aws/ab_testing_auto_scaling/#this-cell-will-take-approximately-1-2-minutes-to-run_2","title":"This cell will take approximately 1-2 minutes to run.","text":"<pre><code>%%time\n\nfor i in range(0, 100):\n    predicted_classes = predictor.predict(inputs)\n</code></pre> <p>Review the autoscaling:</p> <ul> <li>open the link</li> <li>notice that you are in the section Amazon SageMaker -&gt; Endpoints</li> <li>below you can see the endpoint runtime settings with the instance counts. You can run the predictions multiple times to observe the increase of the instance count to 2</li> </ul> <pre><code>from IPython.core.display import display, HTML\n\ndisplay(HTML('&lt;b&gt;Review &lt;a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={}#/endpoints/{}\"&gt;SageMaker REST endpoint&lt;/a&gt;&lt;/b&gt;'.format(region, model_ab_endpoint_name)))\n\n</code></pre> <p>Upload the notebook into S3 bucket for grading purposes.</p> <p>Note: you may need to click on \"Save\" button before the upload.</p> <pre><code>!aws s3 cp ./C3_W2_Assignment.ipynb s3://$bucket/C3_W2_Assignment_Learner.ipynb\n</code></pre> <pre><code>\n</code></pre>"},{"location":"datascience_on_aws/automatic_model_tuning/","title":"Optimize models using Automatic Model Tuning","text":""},{"location":"datascience_on_aws/automatic_model_tuning/#optimize-models-using-automatic-model-tuning","title":"Optimize models using Automatic Model Tuning","text":""},{"location":"datascience_on_aws/automatic_model_tuning/#introduction","title":"Introduction","text":"<p>When training ML models, hyperparameter tuning is a step taken to find the best performing training model. In this lab you will apply a random algorithm of Automated Hyperparameter Tuning to train a BERT-based natural language processing (NLP) classifier. The model analyzes customer feedback and classifies the messages into positive (1), neutral (0), and negative (-1) sentiments.</p> <p>Amazon SageMaker supports Automated Hyperparameter Tuning. It runs multiple training jobs on the training dataset using the hyperparameter ranges specified by the user. Then it chooses the combination of hyperparameters that leads to the best model candidate. The choice is made based on the objective metrics, e.g. maximization of the validation accuracy. </p> <p>For the choice of hyperparameters combinations, SageMaker supports two different types of tuning strategies: random and Bayesian. This capability can be further extended by providing an implementation of a custom tuning strategy as a Docker container.</p> <p> </p> <p>In this lab you will perform the following three steps:</p> <p> </p> <p>First, let's install and import the required modules.</p> <pre><code># please ignore warning messages during the installation\n!pip install --disable-pip-version-check -q sagemaker==2.35.0\n!conda install -q -y pytorch==1.6.0 -c pytorch\n!pip install --disable-pip-version-check -q transformers==3.5.1\n</code></pre> <pre><code>\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting package metadata (current_repodata.json): ...working... done\nSolving environment: ...working... failed with initial frozen solve. Retrying with flexible solve.\nCollecting package metadata (repodata.json): ...working... done\nSolving environment: ...working... done\n\n## Package Plan ##\n\n  environment location: /opt/conda\n\n  added / updated specs:\n    - pytorch==1.6.0\n\n\nThe following packages will be downloaded:\n\n    package                    |            build\n    ---------------------------|-----------------\n    ca-certificates-2023.05.30 |       h06a4308_0         120 KB\n    certifi-2022.12.7          |   py37h06a4308_0         150 KB\n    cudatoolkit-10.2.89        |       hfd86e86_1       365.1 MB\n    ninja-1.10.2               |       h06a4308_5           8 KB\n    ninja-base-1.10.2          |       hd09550d_5         109 KB\n    pytorch-1.6.0              |py3.7_cuda10.2.89_cudnn7.6.5_0       537.7 MB  pytorch\n    ------------------------------------------------------------\n                                           Total:       903.1 MB\n\nThe following NEW packages will be INSTALLED:\n\n  cudatoolkit        pkgs/main/linux-64::cudatoolkit-10.2.89-hfd86e86_1 None\n  ninja              pkgs/main/linux-64::ninja-1.10.2-h06a4308_5 None\n  ninja-base         pkgs/main/linux-64::ninja-base-1.10.2-hd09550d_5 None\n  pytorch            pytorch/linux-64::pytorch-1.6.0-py3.7_cuda10.2.89_cudnn7.6.5_0 None\n\nThe following packages will be UPDATED:\n\n  ca-certificates    conda-forge::ca-certificates-2022.12.~ --&gt; pkgs/main::ca-certificates-2023.05.30-h06a4308_0 None\n\nThe following packages will be SUPERSEDED by a higher-priority channel:\n\n  certifi            conda-forge/noarch::certifi-2022.12.7~ --&gt; pkgs/main/linux-64::certifi-2022.12.7-py37h06a4308_0 None\n\n\nPreparing transaction: ...working... done\nVerifying transaction: ...working... done\nExecuting transaction: ...working... done\nRetrieving notices: ...working... done\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n</code></pre> <pre><code>import boto3\nimport sagemaker\nimport pandas as pd\nimport botocore\n\nconfig = botocore.config.Config(user_agent_extra='dlai-pds/c3/w1')\n\n# low-level service client of the boto3 session\nsm = boto3.client(service_name='sagemaker', \n                  config=config)\n\nsess = sagemaker.Session(sagemaker_client=sm)\n\nbucket = sess.default_bucket()\nrole = sagemaker.get_execution_role()\nregion = sess.boto_region_name\n</code></pre>                         Clean data in minutes                     Automatically visualize data, and improve data quality in a few clicks. Learn more Import Data Wrangler widget Remind me later Don't show again <p></p>"},{"location":"datascience_on_aws/automatic_model_tuning/#1-configure-dataset-and-hyperparameter-tuning-job-htp","title":"1. Configure dataset and Hyperparameter Tuning Job (HTP)","text":""},{"location":"datascience_on_aws/automatic_model_tuning/#11-configure-dataset","title":"1.1. Configure dataset","text":"<p>Let's set up the paths and copy the data to the S3 bucket:</p> <pre><code>processed_train_data_s3_uri = 's3://{}/transformed/data/sentiment-train/'.format(bucket)\nprocessed_validation_data_s3_uri = 's3://{}/transformed/data/sentiment-validation/'.format(bucket)\nprocessed_test_data_s3_uri = 's3://{}/transformed/data/sentiment-test/'.format(bucket)\n</code></pre> <p>Upload the data to the S3 bucket:</p> <pre><code>!aws s3 cp --recursive ./data/sentiment-train $processed_train_data_s3_uri\n!aws s3 cp --recursive ./data/sentiment-validation $processed_validation_data_s3_uri\n!aws s3 cp --recursive ./data/sentiment-test $processed_test_data_s3_uri\n</code></pre> <pre><code>upload: data/sentiment-train/part-algo-1-womens_clothing_ecommerce_reviews.tsv to s3://sagemaker-us-east-1-610140168408/transformed/data/sentiment-train/part-algo-1-womens_clothing_ecommerce_reviews.tsv\nupload: data/sentiment-validation/part-algo-1-womens_clothing_ecommerce_reviews.tsv to s3://sagemaker-us-east-1-610140168408/transformed/data/sentiment-validation/part-algo-1-womens_clothing_ecommerce_reviews.tsv\nupload: data/sentiment-test/part-algo-1-womens_clothing_ecommerce_reviews.tsv to s3://sagemaker-us-east-1-610140168408/transformed/data/sentiment-test/part-algo-1-womens_clothing_ecommerce_reviews.tsv\n</code></pre> <p>Check the existence of those files in the S3 bucket:</p> <pre><code>!aws s3 ls --recursive $processed_train_data_s3_uri\n</code></pre> <pre><code>2023-06-12 02:35:27    4894416 transformed/data/sentiment-train/part-algo-1-womens_clothing_ecommerce_reviews.tsv\n</code></pre> <pre><code>!aws s3 ls --recursive $processed_validation_data_s3_uri\n</code></pre> <pre><code>2023-06-12 02:35:28     276522 transformed/data/sentiment-validation/part-algo-1-womens_clothing_ecommerce_reviews.tsv\n</code></pre> <pre><code>!aws s3 ls --recursive $processed_test_data_s3_uri\n</code></pre> <pre><code>2023-06-12 02:35:29     273414 transformed/data/sentiment-test/part-algo-1-womens_clothing_ecommerce_reviews.tsv\n</code></pre> <p></p>"},{"location":"datascience_on_aws/automatic_model_tuning/#exercise-1","title":"Exercise 1","text":"<p>Set up a dictionary of the input training and validation data channels, wrapping the corresponding S3 locations in a <code>TrainingInput</code> object.</p> <p>Instructions: Pass the S3 input paths for training and validation data into the <code>TrainingInput</code> function</p> <pre><code>TrainingInput(s3_data=...)\n</code></pre> <p>to construct the Amazon SageMaker channels for S3 input data sources. Then put the corresponding channels into the dictionary.</p> <pre><code>from sagemaker.inputs import TrainingInput\n\ndata_channels = {\n    ### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n    'train': TrainingInput(s3_data=processed_train_data_s3_uri), # Replace None\n    'validation': TrainingInput(s3_data=processed_validation_data_s3_uri) # Replace None\n    ### END SOLUTION - DO NOT delete this comment for grading purposes\n}\n</code></pre> <p>There is no need to create a test data channel, as the test data is used later at the evaluation stage and does not need to be wrapped into the <code>sagemaker.inputs.TrainingInput</code> function.</p> <p></p>"},{"location":"datascience_on_aws/automatic_model_tuning/#12-configure-hyperparameter-tuning-job","title":"1.2. Configure Hyperparameter Tuning Job","text":"<p>Model hyperparameters need to be set prior to starting the model training as they control the process of learning. Some of the hyperparameters you will set up as static - they will not be explored during the tuning job. For the non-static hyperparameters you will set the range of possible values to be explored.</p> <p>First, configure static hyperparameters including the instance type, instance count, maximum sequence length, etc. For the purposes of this lab, you will use a relatively small instance type. Please refer to this link for additional instance types that may work for your use cases outside of this lab.</p> <pre><code>max_seq_length=128 # maximum number of input tokens passed to BERT model\nfreeze_bert_layer=False # specifies the depth of training within the network\nepochs=3\ntrain_steps_per_epoch=50\nvalidation_batch_size=64\nvalidation_steps_per_epoch=50\nseed=42\n\ntrain_instance_count=1\ntrain_instance_type='ml.c5.9xlarge'\ntrain_volume_size=256\ninput_mode='File'\nrun_validation=True\n</code></pre> <p>Some of these will be passed into the PyTorch estimator and tuner in the hyperparameters argument. Let's set up the dictionary for that:</p> <pre><code>hyperparameters_static={\n    'freeze_bert_layer': freeze_bert_layer,\n    'max_seq_length': max_seq_length,\n    'epochs': epochs,\n    'train_steps_per_epoch': train_steps_per_epoch,\n    'validation_batch_size': validation_batch_size,\n    'validation_steps_per_epoch': validation_steps_per_epoch,\n    'seed': seed,\n    'run_validation': run_validation\n}\n</code></pre> <p>Configure hyperparameter ranges to explore in the Tuning Job. The values of the ranges typically come from prior experience, research papers, or other models similar to the task you are trying to do.</p> <pre><code>from sagemaker.tuner import IntegerParameter\nfrom sagemaker.tuner import ContinuousParameter\nfrom sagemaker.tuner import CategoricalParameter\n\nhyperparameter_ranges = {\n    'learning_rate': ContinuousParameter(0.00001, 0.00005, scaling_type='Linear'), # specifying continuous variable type, the tuning job will explore the range of values\n    'train_batch_size': CategoricalParameter([128, 256]), # specifying categorical variable type, the tuning job will explore only listed values\n}\n</code></pre> <p></p>"},{"location":"datascience_on_aws/automatic_model_tuning/#13-set-up-evaluation-metrics","title":"1.3. Set up evaluation metrics","text":"<p>Choose loss and accuracy as the evaluation metrics. The regular expressions <code>Regex</code> will capture the values of metrics that the algorithm will emit.</p> <pre><code>metric_definitions = [\n     {'Name': 'validation:loss', 'Regex': 'val_loss: ([0-9.]+)'},\n     {'Name': 'validation:accuracy', 'Regex': 'val_acc: ([0-9.]+)'},\n]\n</code></pre> <p>For example, these sample log lines...</p> <pre><code>[step: 100] val_loss: 0.76 - val_acc: 70.92%\n</code></pre> <p>...will produce the following metrics in CloudWatch:</p> <p><code>validation:loss</code> =  0.76</p> <p><code>validation:accuracy</code> = 70.92</p> <p>In the Tuning Job, you will be maximizing validation accuracy as the objective metric.</p> <p></p>"},{"location":"datascience_on_aws/automatic_model_tuning/#2-run-tuning-job","title":"2. Run Tuning Job","text":""},{"location":"datascience_on_aws/automatic_model_tuning/#21-set-up-the-roberta-and-pytorch-script-to-run-on-sagemaker","title":"2.1. Set up the RoBERTa and PyTorch script to run on SageMaker","text":"<p>Prepare the PyTorch model to run as a SageMaker Training Job. The estimator takes into the entry point a separate Python file, which will be called during the training. You can open and review this file src/train.py.</p> <p>For more information on the <code>PyTorchEstimator</code>, see the documentation here: https://sagemaker.readthedocs.io/</p> <pre><code>from sagemaker.pytorch import PyTorch as PyTorchEstimator\n# Note: indeed, it is not compulsory to rename the PyTorch estimator,\n# but this is useful for code clarity, especially when a few modules of 'sagemaker.pytorch' are used\n\nestimator = PyTorchEstimator(\n    entry_point='train.py',\n    source_dir='src',\n    role=role,\n    instance_count=train_instance_count,\n    instance_type=train_instance_type,\n    volume_size=train_volume_size,\n    py_version='py3',\n    framework_version='1.6.0',\n    hyperparameters=hyperparameters_static,\n    metric_definitions=metric_definitions,\n    input_mode=input_mode,\n)\n</code></pre> <p></p>"},{"location":"datascience_on_aws/automatic_model_tuning/#22-launch-the-hyperparameter-tuning-job","title":"2.2. Launch the Hyperparameter Tuning Job","text":"<p>A hyperparameter tuning job runs a series of training jobs that each test a combination of hyperparameters for a given objective metric (i.e. <code>validation:accuracy</code>). In this lab, you will use a <code>Random</code> search strategy to determine the combinations of hyperparameters - within the specific ranges - to use for each training job within the tuning job.  For more information on hyperparameter tuning search strategies, please see the following documentation:  https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-how-it-works.html</p> <p>When the tuning job completes, you can select the hyperparameters used by the best-performing training job relative to the objective metric. </p> <p>The <code>max_jobs</code> parameter is a stop criteria that limits the number of overall training jobs (and therefore hyperparameter combinations) to run within the tuning job.</p> <p>The <code>max_parallel_jobs</code> parameter limits the number of training jobs (and therefore hyperparameter combinations) to run in parallel within the tuning job.  This parameter is often used in combination with the <code>Bayesian</code> search strategy when you want to test a smaller set of training jobs (less than the <code>max_jobs</code>), learn from the smaller set of training jobs, then apply Bayesian methods to determine the next set of hyperparameters used by the next set of training jobs. Bayesian methods can improve hyperparameter-tuning performance in some cases.</p> <p>The <code>early_stopping_type</code> parameter is used by SageMaker hyper-parameter tuning jobs to automatically stop a training job if the job is not improving the objective metrics (i.e. <code>validation:accuracy</code>) relative to previous training jobs within the tuning job.  For more information on early stopping, please see the following documentation:  https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-early-stopping.html.</p> <p></p>"},{"location":"datascience_on_aws/automatic_model_tuning/#exercise-2","title":"Exercise 2","text":"<p>Set up the Hyperparameter Tuner.</p> <p>Instructions: Use the function <code>HyperparameterTuner</code>, passing the variables defined above. Please use tuning strategy <code>'Random'</code>.</p> <pre><code>tuner = HyperparameterTuner(\n    estimator=..., # estimator\n    hyperparameter_ranges=..., # hyperparameter ranges\n    metric_definitions=..., # definition metric\n    strategy='...', # tuning strategy\n    objective_type='Maximize',\n    objective_metric_name='validation:accuracy',\n    max_jobs=2, # maximum number of jobs to run\n    max_parallel_jobs=2, # maximum number of jobs to run in parallel\n    early_stopping_type='Auto' # early stopping criteria\n)\n</code></pre> <pre><code>from sagemaker.tuner import HyperparameterTuner\n\ntuner = HyperparameterTuner(\n    ### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n    estimator=estimator, # Replace None\n    hyperparameter_ranges=hyperparameter_ranges, # Replace None\n    metric_definitions=metric_definitions, # Replace None\n    strategy='Random', # Replace None\n    ### END SOLUTION - DO NOT delete this comment for grading purposes\n    objective_type='Maximize',\n    objective_metric_name='validation:accuracy',\n    max_jobs=2, # maximum number of jobs to run\n    max_parallel_jobs=2, # maximum number of jobs to run in parallel\n    early_stopping_type='Auto' # early stopping criteria\n)\n</code></pre> <p></p>"},{"location":"datascience_on_aws/automatic_model_tuning/#exercise-3","title":"Exercise 3","text":"<p>Launch the SageMaker Hyper-Parameter Tuning (HPT) Job.</p> <p>Instructions: Use the <code>tuner.fit</code> function, passing the configured train and validation inputs (data channels).</p> <pre><code>tuner.fit(\n    inputs=..., # train and validation input\n    include_cls_metadata=False, # to be set as false if the algorithm cannot handle unknown hyperparameters\n    wait=False # do not wait for the job to complete before continuing\n)\n</code></pre> <pre><code>tuner.fit(\n    ### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n    inputs=data_channels, # Replace None\n    ### END SOLUTION - DO NOT delete this comment for grading purposes\n    include_cls_metadata=False,\n    wait=False\n)\n</code></pre> <p></p>"},{"location":"datascience_on_aws/automatic_model_tuning/#23-check-tuning-job-status","title":"2.3. Check Tuning Job status","text":"<p>You can see the Tuning Job status in the console. Let's get the Tuning Job name to construct the link.</p> <pre><code>tuning_job_name = tuner.latest_tuning_job.job_name\nprint(tuning_job_name)\n</code></pre> <pre><code>pytorch-training-230612-0238\n</code></pre> <p>Check the status of the Tuning Job.</p> <pre><code>from IPython.core.display import display, HTML\n\ndisplay(HTML('&lt;b&gt;Review &lt;a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={}#/hyper-tuning-jobs/{}\"&gt;Hyper-Parameter Tuning Job&lt;/a&gt;&lt;/b&gt;'.format(region, tuning_job_name)))\n</code></pre> <p>Review Hyper-Parameter Tuning Job</p> <p>Wait for the Tuning Job to complete.</p>"},{"location":"datascience_on_aws/automatic_model_tuning/#this-cell-will-take-approximately-20-30-minutes-to-run","title":"This cell will take approximately 20-30 minutes to run.","text":"<pre><code>%%time\n\ntuner.wait()\n</code></pre> <pre><code>.................................................................................................................................................................................................................................................................................................................................................!\nCPU times: user 1.55 s, sys: 160 ms, total: 1.71 s\nWall time: 28min 54s\n</code></pre> <p>Wait until the ^^ Tuning Job ^^ completes above</p> <p>The results of the SageMaker Hyperparameter Tuning Job are available on the <code>analytics</code> of the <code>tuner object</code>. The <code>dataframe</code> function converts the result directly into the dataframe. You can explore the results with the following lines of the code:</p> <pre><code>import time\n\ntime.sleep(10) # slight delay to allow the analytics to be calculated\n\ndf_results = tuner.analytics().dataframe()\ndf_results.shape\n</code></pre> <pre><code>(2, 8)\n</code></pre> <pre><code>df_results.sort_values('FinalObjectiveValue', ascending=0)\n</code></pre> learning_rate train_batch_size TrainingJobName TrainingJobStatus FinalObjectiveValue TrainingStartTime TrainingEndTime TrainingElapsedTimeSeconds 1 0.000022 \"128\" pytorch-training-230612-0238-001-e2bd7fda Completed 71.480003 2023-06-12 02:39:29+00:00 2023-06-12 03:03:36+00:00 1447.0 0 0.000025 \"256\" pytorch-training-230612-0238-002-0346b365 Completed 68.750000 2023-06-12 02:40:05+00:00 2023-06-12 03:04:11+00:00 1446.0 <p>When training and tuning at scale, it is important to continuously monitor and use the right compute resources. While you have the flexibility of choosing different compute options how do you choose the specific instance types and sizes to use? There is no standard answer for this. It comes down to understanding the workload and running empirical testing to determine the best compute resources to use for the training. </p> <p>SageMaker Training Jobs emit CloudWatch metrics for resource utilization. You can review them in the AWS console:</p> <ul> <li>open the link</li> <li>notice that you are in the section Amazon SageMaker -&gt; Hyperparameter tuning jobs</li> <li>have a look at the list of the Training jobs below and click on one of them</li> <li>scroll down to the Monitor section and review the available metrics</li> </ul> <pre><code>from IPython.core.display import display, HTML\n\ndisplay(HTML('&lt;b&gt;Review Training Jobs of the &lt;a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={}#/hyper-tuning-jobs/{}\"&gt;Hyper-Parameter Tuning Job&lt;/a&gt;&lt;/b&gt;'.format(region, tuning_job_name)))\n</code></pre> <p>Review Training Jobs of the Hyper-Parameter Tuning Job</p> <p></p>"},{"location":"datascience_on_aws/automatic_model_tuning/#3-evaluate-the-results","title":"3. Evaluate the results","text":"<p>An important part of developing a model is evaluating the model with a test data set - one that the model has never seen during its training process. The final metrics resulting from this evaluation can be used to compare competing machine learning models. The higher the value of these metrics, the better the model is able to generalize.</p> <p></p>"},{"location":"datascience_on_aws/automatic_model_tuning/#31-show-the-best-candidate","title":"3.1. Show the best candidate","text":""},{"location":"datascience_on_aws/automatic_model_tuning/#exercise-4","title":"Exercise 4","text":"<p>Show the best candidate - the one with the highest accuracy result.</p> <p>Instructions: Use the <code>sort_values</code> function to sort the results by accuracy, which is stored in the column <code>FinalObjectiveValue</code>. Put <code>ascending=0</code> and <code>head(1)</code> for the selection.</p> <pre><code>df_results.sort_values(\n    '...', # column name for sorting\n    ascending=0).head(1)\n</code></pre> <pre><code>df_results.sort_values(\n    ### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n    'FinalObjectiveValue', # Replace None\n    ### END SOLUTION - DO NOT delete this comment for grading purposes\n    ascending=0).head(1)\n</code></pre> learning_rate train_batch_size TrainingJobName TrainingJobStatus FinalObjectiveValue TrainingStartTime TrainingEndTime TrainingElapsedTimeSeconds 1 0.000022 \"128\" pytorch-training-230612-0238-001-e2bd7fda Completed 71.480003 2023-06-12 02:39:29+00:00 2023-06-12 03:03:36+00:00 1447.0 <p></p>"},{"location":"datascience_on_aws/automatic_model_tuning/#32-evaluate-the-best-candidate","title":"3.2. Evaluate the best candidate","text":"<p>Let's pull the information about the best candidate from the dataframe and then take the Training Job name from the column <code>TrainingJobName</code>.</p> <pre><code>best_candidate = df_results.sort_values('FinalObjectiveValue', ascending=0).iloc[0]\n\nbest_candidate_training_job_name = best_candidate['TrainingJobName']\nprint('Best candidate Training Job name: {}'.format(best_candidate_training_job_name))\n</code></pre> <pre><code>Best candidate Training Job name: pytorch-training-230612-0238-001-e2bd7fda\n</code></pre> <p></p>"},{"location":"datascience_on_aws/automatic_model_tuning/#exercise-5","title":"Exercise 5","text":"<p>Show accuracy result for the best candidate.</p> <p>Instructions: Use the example in the cell above.</p> <pre><code>### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\nbest_candidate_accuracy = best_candidate['FinalObjectiveValue'] # Replace all None\n### END SOLUTION - DO NOT delete this comment for grading purposes\n\nprint('Best candidate accuracy result: {}'.format(best_candidate_accuracy))\n</code></pre> <pre><code>Best candidate accuracy result: 71.4800033569336\n</code></pre> <p>You can use the function <code>describe_training_job</code> of the service client to get some more information about the best candidate. The result is in dictionary format. Let's check that it has the same Training Job name:</p> <pre><code>best_candidate_description = sm.describe_training_job(TrainingJobName=best_candidate_training_job_name)\n\nbest_candidate_training_job_name2 = best_candidate_description['TrainingJobName']\n\nprint('Training Job name: {}'.format(best_candidate_training_job_name2))\n</code></pre> <pre><code>Training Job name: pytorch-training-230612-0238-001-e2bd7fda\n</code></pre> <p></p>"},{"location":"datascience_on_aws/automatic_model_tuning/#exercise-6","title":"Exercise 6","text":"<p>Pull the Tuning Job and Training Job Amazon Resource Name (ARN) from the best candidate training job description.</p> <p>Instructions: Print the keys of the best candidate Training Job description dictionary, choose the ones related to the Tuning Job and Training Job ARN and print their values.</p> <pre><code>print(best_candidate_description.keys())\n</code></pre> <pre><code>dict_keys(['TrainingJobName', 'TrainingJobArn', 'TuningJobArn', 'ModelArtifacts', 'TrainingJobStatus', 'SecondaryStatus', 'HyperParameters', 'AlgorithmSpecification', 'RoleArn', 'InputDataConfig', 'OutputDataConfig', 'ResourceConfig', 'StoppingCondition', 'CreationTime', 'TrainingStartTime', 'TrainingEndTime', 'LastModifiedTime', 'SecondaryStatusTransitions', 'FinalMetricDataList', 'EnableNetworkIsolation', 'EnableInterContainerTrafficEncryption', 'EnableManagedSpotTraining', 'TrainingTimeInSeconds', 'BillableTimeInSeconds', 'ProfilingStatus', 'WarmPoolStatus', 'ResponseMetadata'])\n</code></pre> <pre><code>### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\nbest_candidate_tuning_job_arn = best_candidate_description['TuningJobArn'] # Replace None\nbest_candidate_training_job_arn = best_candidate_description['TrainingJobArn'] # Replace None\n### END SOLUTION - DO NOT delete this comment for grading purposes\nprint('Best candidate Tuning Job ARN: {}'.format(best_candidate_tuning_job_arn))\nprint('Best candidate Training Job ARN: {}'.format(best_candidate_training_job_arn))\n</code></pre> <pre><code>Best candidate Tuning Job ARN: arn:aws:sagemaker:us-east-1:610140168408:hyper-parameter-tuning-job/pytorch-training-230612-0238\nBest candidate Training Job ARN: arn:aws:sagemaker:us-east-1:610140168408:training-job/pytorch-training-230612-0238-001-e2bd7fda\n</code></pre> <p>Pull the path of the best candidate model in the S3 bucket. You will need it later to set up the Processing Job for the evaluation.</p> <pre><code>model_tar_s3_uri = sm.describe_training_job(TrainingJobName=best_candidate_training_job_name)['ModelArtifacts']['S3ModelArtifacts']\nprint(model_tar_s3_uri)\n</code></pre> <pre><code>s3://sagemaker-us-east-1-610140168408/pytorch-training-230612-0238-001-e2bd7fda/output/model.tar.gz\n</code></pre> <p>To perform model evaluation you will use a scikit-learn-based Processing Job. This is essentially a generic Python Processing Job with scikit-learn pre-installed. You can specify the version of scikit-learn you wish to use. Also pass the SageMaker execution role, processing instance type and instance count. </p> <pre><code>from sagemaker.sklearn.processing import SKLearnProcessor\n\nprocessing_instance_type = \"ml.c5.2xlarge\"\nprocessing_instance_count = 1\n\nprocessor = SKLearnProcessor(\n    framework_version=\"0.23-1\",\n    role=role,\n    instance_type=processing_instance_type,\n    instance_count=processing_instance_count,\n    max_runtime_in_seconds=7200,\n)\n</code></pre> <p>The model evaluation Processing Job will be running the Python code from the file src/evaluate_model_metrics.py. You can open and review the file.</p> <p>Launch the Processing Job, passing the defined above parameters, custom script, path and the S3 bucket location of the test data.</p> <pre><code>from sagemaker.processing import ProcessingInput, ProcessingOutput\n\nprocessor.run(\n    code=\"src/evaluate_model_metrics.py\",\n    inputs=[\n        ProcessingInput(  \n            input_name=\"model-tar-s3-uri\",                        \n            source=model_tar_s3_uri,                               \n            destination=\"/opt/ml/processing/input/model/\"\n        ),\n        ProcessingInput(\n            input_name=\"evaluation-data-s3-uri\",\n            source=processed_test_data_s3_uri,                                    \n            destination=\"/opt/ml/processing/input/data/\",\n        ),\n    ],\n    outputs=[\n        ProcessingOutput(s3_upload_mode=\"EndOfJob\", output_name=\"metrics\", source=\"/opt/ml/processing/output/metrics\"),\n    ],\n    arguments=[\"--max-seq-length\", str(max_seq_length)],\n    logs=True,\n    wait=False,\n)\n</code></pre> <pre><code>Job Name:  sagemaker-scikit-learn-2023-06-12-03-14-44-443\nInputs:  [{'InputName': 'model-tar-s3-uri', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-610140168408/pytorch-training-230612-0238-001-e2bd7fda/output/model.tar.gz', 'LocalPath': '/opt/ml/processing/input/model/', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'evaluation-data-s3-uri', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-610140168408/transformed/data/sentiment-test/', 'LocalPath': '/opt/ml/processing/input/data/', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-610140168408/sagemaker-scikit-learn-2023-06-12-03-14-44-443/input/code/evaluate_model_metrics.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\nOutputs:  [{'OutputName': 'metrics', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-610140168408/sagemaker-scikit-learn-2023-06-12-03-14-44-443/output/metrics', 'LocalPath': '/opt/ml/processing/output/metrics', 'S3UploadMode': 'EndOfJob'}}]\n</code></pre> <p>You can see the information about the Processing Jobs using the <code>describe</code> function. The result is in dictionary format. Let's pull the Processing Job name:</p> <pre><code>scikit_processing_job_name = processor.jobs[-1].describe()[\"ProcessingJobName\"]\n\nprint('Processing Job name: {}'.format(scikit_processing_job_name))\n</code></pre> <pre><code>Processing Job name: sagemaker-scikit-learn-2023-06-12-03-14-44-443\n</code></pre> <p></p>"},{"location":"datascience_on_aws/automatic_model_tuning/#exercise-7","title":"Exercise 7","text":"<p>Pull the Processing Job status from the Processing Job description.</p> <p>Instructions: Print the keys of the Processing Job description dictionary, choose the one related to the status of the Processing Job and print the value of it.</p> <pre><code>print(processor.jobs[-1].describe().keys())\n</code></pre> <pre><code>dict_keys(['ProcessingInputs', 'ProcessingOutputConfig', 'ProcessingJobName', 'ProcessingResources', 'StoppingCondition', 'AppSpecification', 'RoleArn', 'ProcessingJobArn', 'ProcessingJobStatus', 'LastModifiedTime', 'CreationTime', 'ResponseMetadata'])\n</code></pre> <pre><code>### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\nscikit_processing_job_status = processor.jobs[-1].describe()['ProcessingJobStatus'] # Replace None\n### END SOLUTION - DO NOT delete this comment for grading purposes\nprint('Processing job status: {}'.format(scikit_processing_job_status))\n</code></pre> <pre><code>Processing job status: InProgress\n</code></pre> <p>Review the created Processing Job in the AWS console.</p> <p>Instructions:  - open the link - notice that you are in the section <code>Amazon SageMaker</code> -&gt; <code>Processing Jobs</code> - check the name of the Processing Job, its status and other available information</p> <pre><code>from IPython.core.display import display, HTML\n\ndisplay(\n    HTML(\n        '&lt;b&gt;Review &lt;a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={}#/processing-jobs/{}\"&gt;Processing Job&lt;/a&gt;&lt;/b&gt;'.format(\n            region, scikit_processing_job_name\n        )\n    )\n)\n</code></pre> <p>Review Processing Job</p> <p>Wait for about 5 minutes to review the CloudWatch Logs. You may open the file src/evaluate_model_metrics.py again and examine the outputs of the code in the CloudWatch Logs.</p> <pre><code>from IPython.core.display import display, HTML\n\ndisplay(\n    HTML(\n        '&lt;b&gt;Review &lt;a target=\"blank\" href=\"https://console.aws.amazon.com/cloudwatch/home?region={}#logStream:group=/aws/sagemaker/ProcessingJobs;prefix={};streamFilter=typeLogStreamPrefix\"&gt;CloudWatch Logs&lt;/a&gt; after about 5 minutes&lt;/b&gt;'.format(\n            region, scikit_processing_job_name\n        )\n    )\n)\n</code></pre> <p>Review CloudWatch Logs after about 5 minutes</p> <p>After the completion of the Processing Job you can also review the output in the S3 bucket.</p> <pre><code>from IPython.core.display import display, HTML\n\ndisplay(\n    HTML(\n        '&lt;b&gt;Review &lt;a target=\"blank\" href=\"https://s3.console.aws.amazon.com/s3/buckets/{}/{}/?region={}&amp;tab=overview\"&gt;S3 output data&lt;/a&gt; after the Processing Job has completed&lt;/b&gt;'.format(\n            bucket, scikit_processing_job_name, region\n        )\n    )\n)\n</code></pre> <p>Review S3 output data after the Processing Job has completed</p> <p>Monitor the Processing Job:</p> <pre><code>from pprint import pprint\n\nrunning_processor = sagemaker.processing.ProcessingJob.from_processing_name(\n    processing_job_name=scikit_processing_job_name, sagemaker_session=sess\n)\n\nprocessing_job_description = running_processor.describe()\n\npprint(processing_job_description)\n</code></pre> <pre><code>{'AppSpecification': {'ContainerArguments': ['--max-seq-length', '128'],\n                      'ContainerEntrypoint': ['python3',\n                                              '/opt/ml/processing/input/code/evaluate_model_metrics.py'],\n                      'ImageUri': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:0.23-1-cpu-py3'},\n 'CreationTime': datetime.datetime(2023, 6, 12, 3, 14, 44, 964000, tzinfo=tzlocal()),\n 'LastModifiedTime': datetime.datetime(2023, 6, 12, 3, 18, 26, 397000, tzinfo=tzlocal()),\n 'ProcessingInputs': [{'AppManaged': False,\n                       'InputName': 'model-tar-s3-uri',\n                       'S3Input': {'LocalPath': '/opt/ml/processing/input/model/',\n                                   'S3CompressionType': 'None',\n                                   'S3DataDistributionType': 'FullyReplicated',\n                                   'S3DataType': 'S3Prefix',\n                                   'S3InputMode': 'File',\n                                   'S3Uri': 's3://sagemaker-us-east-1-610140168408/pytorch-training-230612-0238-001-e2bd7fda/output/model.tar.gz'}},\n                      {'AppManaged': False,\n                       'InputName': 'evaluation-data-s3-uri',\n                       'S3Input': {'LocalPath': '/opt/ml/processing/input/data/',\n                                   'S3CompressionType': 'None',\n                                   'S3DataDistributionType': 'FullyReplicated',\n                                   'S3DataType': 'S3Prefix',\n                                   'S3InputMode': 'File',\n                                   'S3Uri': 's3://sagemaker-us-east-1-610140168408/transformed/data/sentiment-test/'}},\n                      {'AppManaged': False,\n                       'InputName': 'code',\n                       'S3Input': {'LocalPath': '/opt/ml/processing/input/code',\n                                   'S3CompressionType': 'None',\n                                   'S3DataDistributionType': 'FullyReplicated',\n                                   'S3DataType': 'S3Prefix',\n                                   'S3InputMode': 'File',\n                                   'S3Uri': 's3://sagemaker-us-east-1-610140168408/sagemaker-scikit-learn-2023-06-12-03-14-44-443/input/code/evaluate_model_metrics.py'}}],\n 'ProcessingJobArn': 'arn:aws:sagemaker:us-east-1:610140168408:processing-job/sagemaker-scikit-learn-2023-06-12-03-14-44-443',\n 'ProcessingJobName': 'sagemaker-scikit-learn-2023-06-12-03-14-44-443',\n 'ProcessingJobStatus': 'InProgress',\n 'ProcessingOutputConfig': {'Outputs': [{'AppManaged': False,\n                                         'OutputName': 'metrics',\n                                         'S3Output': {'LocalPath': '/opt/ml/processing/output/metrics',\n                                                      'S3UploadMode': 'EndOfJob',\n                                                      'S3Uri': 's3://sagemaker-us-east-1-610140168408/sagemaker-scikit-learn-2023-06-12-03-14-44-443/output/metrics'}}]},\n 'ProcessingResources': {'ClusterConfig': {'InstanceCount': 1,\n                                           'InstanceType': 'ml.c5.2xlarge',\n                                           'VolumeSizeInGB': 30}},\n 'ProcessingStartTime': datetime.datetime(2023, 6, 12, 3, 18, 26, 394000, tzinfo=tzlocal()),\n 'ResponseMetadata': {'HTTPHeaders': {'content-length': '2367',\n                                      'content-type': 'application/x-amz-json-1.1',\n                                      'date': 'Mon, 12 Jun 2023 03:19:32 GMT',\n                                      'x-amzn-requestid': '617a6701-8bdd-4c06-9091-c8fefea9ed4f'},\n                      'HTTPStatusCode': 200,\n                      'RequestId': '617a6701-8bdd-4c06-9091-c8fefea9ed4f',\n                      'RetryAttempts': 0},\n 'RoleArn': 'arn:aws:iam::610140168408:role/sagemaker-studio-vpc-firewall-us-east-1-sagemaker-execution-role',\n 'StoppingCondition': {'MaxRuntimeInSeconds': 7200}}\n</code></pre> <p>Wait for the Processing Job to complete.</p>"},{"location":"datascience_on_aws/automatic_model_tuning/#this-cell-will-take-approximately-5-10-minutes-to-run","title":"This cell will take approximately 5-10 minutes to run.","text":"<pre><code>%%time\n\nrunning_processor.wait(logs=False)\n</code></pre> <pre><code>.............!CPU times: user 43 ms, sys: 25.2 ms, total: 68.2 ms\nWall time: 1min 5s\n</code></pre> <p>Please wait until ^^ Processing Job ^^ completes above</p> <p></p>"},{"location":"datascience_on_aws/automatic_model_tuning/#33-inspect-the-processed-output-data","title":"3.3. Inspect the processed output data","text":"<p>Let's take a look at the results of the Processing Job. Get the S3 bucket location of the output metrics:</p> <pre><code>processing_job_description = running_processor.describe()\n\noutput_config = processing_job_description[\"ProcessingOutputConfig\"]\nfor output in output_config[\"Outputs\"]:\n    if output[\"OutputName\"] == \"metrics\":\n        processed_metrics_s3_uri = output[\"S3Output\"][\"S3Uri\"]\n\nprint(processed_metrics_s3_uri)\n</code></pre> <pre><code>s3://sagemaker-us-east-1-610140168408/sagemaker-scikit-learn-2023-06-12-03-14-44-443/output/metrics\n</code></pre> <p>List the content of the folder:</p> <pre><code>!aws s3 ls $processed_metrics_s3_uri/\n</code></pre> <pre><code>2023-06-12 03:20:39      19519 confusion_matrix.png\n2023-06-12 03:20:39         56 evaluation.json\n</code></pre> <p>The test accuracy can be pulled from the <code>evaluation.json</code> file.</p> <pre><code>import json\nfrom pprint import pprint\n\nmetrics_json = sagemaker.s3.S3Downloader.read_file(\"{}/evaluation.json\".format(\n    processed_metrics_s3_uri\n))\n\nprint('Test accuracy: {}'.format(json.loads(metrics_json)))\n</code></pre> <pre><code>Test accuracy: {'metrics': {'accuracy': {'value': 0.7346278317152104}}}\n</code></pre> <p>Copy image with the confusion matrix generated during the model evaluation into the folder <code>generated</code>.</p> <pre><code>!aws s3 cp $processed_metrics_s3_uri/confusion_matrix.png ./generated/\n\nimport time\ntime.sleep(10) # Slight delay for our notebook to recognize the newly-downloaded file\n</code></pre> <pre><code>download: s3://sagemaker-us-east-1-610140168408/sagemaker-scikit-learn-2023-06-12-03-14-44-443/output/metrics/confusion_matrix.png to generated/confusion_matrix.png\n</code></pre> <p>Show and review the confusion matrix, which is a table of all combinations of true (actual) and predicted labels. Each cell contains the number of the reviews for the corresponding sentiments. You can see that the highest numbers of the reviews appear in the diagonal cells, where the predicted sentiment equals the actual one.</p> <pre><code>%%html\n\n&lt;img src='./generated/confusion_matrix.png'&gt;\n</code></pre> <p></p> <p>Upload the notebook into S3 bucket for grading purposes.</p> <p>Note: you may need to click on \"Save\" button before the upload.</p> <pre><code>!aws s3 cp ./C3_W1_Assignment.ipynb s3://$bucket/C3_W1_Assignment_Learner.ipynb\n</code></pre> <pre><code>\n</code></pre>"},{"location":"datascience_on_aws/classifier_bert_amazon_sagemaker/","title":"Train a review classifier with BERT and Amazon SageMaker","text":""},{"location":"datascience_on_aws/classifier_bert_amazon_sagemaker/#train-a-review-classifier-with-bert-and-amazon-sagemaker","title":"Train a review classifier with BERT and Amazon SageMaker","text":""},{"location":"datascience_on_aws/classifier_bert_amazon_sagemaker/#introduction","title":"Introduction","text":"<p>In the previous lab you performed Feature Engineering on the raw dataset, preparing it for training the model. Now you will train a text classifier using a variant of BERT called RoBERTa - a Robustly Optimized BERT Pretraining Approach - within a PyTorch model ran as a SageMaker Training Job.</p> <p>Let's review Amazon SageMaker \"Bring Your Own Script\" scheme:</p> <p></p> <p>In this lab you will cover each part of the scheme. First, install and import the required modules:</p> <pre><code># please ignore warning messages during the installation\n!pip install --disable-pip-version-check -q sagemaker==2.35.0\n!conda install -q -y pytorch==1.6.0 -c pytorch\n!pip install --disable-pip-version-check -q transformers==3.5.1\n</code></pre> <pre><code>\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting package metadata (current_repodata.json): ...working... done\nSolving environment: ...working... failed with initial frozen solve. Retrying with flexible solve.\nCollecting package metadata (repodata.json): ...working... done\nSolving environment: ...working... done\n\n## Package Plan ##\n\n  environment location: /opt/conda\n\n  added / updated specs:\n    - pytorch==1.6.0\n\n\nThe following packages will be downloaded:\n\n    package                    |            build\n    ---------------------------|-----------------\n    ca-certificates-2023.05.30 |       h06a4308_0         120 KB\n    certifi-2022.12.7          |   py37h06a4308_0         150 KB\n    cudatoolkit-10.2.89        |       hfd86e86_1       365.1 MB\n    ninja-1.10.2               |       h06a4308_5           8 KB\n    ninja-base-1.10.2          |       hd09550d_5         109 KB\n    pytorch-1.6.0              |py3.7_cuda10.2.89_cudnn7.6.5_0       537.7 MB  pytorch\n    ------------------------------------------------------------\n                                           Total:       903.1 MB\n\nThe following NEW packages will be INSTALLED:\n\n  cudatoolkit        pkgs/main/linux-64::cudatoolkit-10.2.89-hfd86e86_1 None\n  ninja              pkgs/main/linux-64::ninja-1.10.2-h06a4308_5 None\n  ninja-base         pkgs/main/linux-64::ninja-base-1.10.2-hd09550d_5 None\n  pytorch            pytorch/linux-64::pytorch-1.6.0-py3.7_cuda10.2.89_cudnn7.6.5_0 None\n\nThe following packages will be UPDATED:\n\n  ca-certificates    conda-forge::ca-certificates-2022.12.~ --&gt; pkgs/main::ca-certificates-2023.05.30-h06a4308_0 None\n\nThe following packages will be SUPERSEDED by a higher-priority channel:\n\n  certifi            conda-forge/noarch::certifi-2022.12.7~ --&gt; pkgs/main/linux-64::certifi-2022.12.7-py37h06a4308_0 None\n\n\nPreparing transaction: ...working... done\nVerifying transaction: ...working... done\nExecuting transaction: ...working... done\nRetrieving notices: ...working... done\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n</code></pre> <pre><code>import boto3\nimport sagemaker\nimport pandas as pd\nimport numpy as np\nimport botocore\n\nconfig = botocore.config.Config(user_agent_extra='dlai-pds/c2/w2')\n\n# low-level service client of the boto3 session\nsm = boto3.client(service_name='sagemaker', \n                  config=config)\n\nsm_runtime = boto3.client('sagemaker-runtime',\n                          config=config)\n\nsess = sagemaker.Session(sagemaker_client=sm,\n                         sagemaker_runtime_client=sm_runtime)\n\nbucket = sess.default_bucket()\nrole = sagemaker.get_execution_role()\nregion = sess.boto_region_name\n</code></pre>                         Clean data in minutes                     Automatically visualize data, and improve data quality in a few clicks. Learn more Import Data Wrangler widget Remind me later Don't show again <pre><code>import matplotlib.pyplot as plt\n%matplotlib inline\n%config InlineBackend.figure_format='retina'\n</code></pre> <p></p>"},{"location":"datascience_on_aws/classifier_bert_amazon_sagemaker/#1-configure-dataset-hyper-parameters-and-evaluation-metrics","title":"1. Configure dataset, hyper-parameters and evaluation metrics","text":""},{"location":"datascience_on_aws/classifier_bert_amazon_sagemaker/#11-configure-dataset","title":"1.1. Configure dataset","text":"<p>You have already transformed and balanced the data into a format that the model expects. Let's copy this data to S3. You will be using training and validation datasets to train the model. Test dataset will be used for tuning later. Setup the paths:</p> <pre><code>processed_train_data_s3_uri = 's3://{}/data/sentiment-train/'.format(bucket)\nprocessed_validation_data_s3_uri = 's3://{}/data/sentiment-validation/'.format(bucket)\n</code></pre> <p>Upload the data to S3 bucket:</p> <pre><code>!aws s3 cp --recursive ./data/sentiment-train $processed_train_data_s3_uri\n!aws s3 cp --recursive ./data/sentiment-validation $processed_validation_data_s3_uri\n</code></pre> <pre><code>upload: data/sentiment-train/part-algo-1-womens_clothing_ecommerce_reviews.tsv to s3://sagemaker-us-east-1-118847640144/data/sentiment-train/part-algo-1-womens_clothing_ecommerce_reviews.tsv\nupload: data/sentiment-validation/part-algo-1-womens_clothing_ecommerce_reviews.tsv to s3://sagemaker-us-east-1-118847640144/data/sentiment-validation/part-algo-1-womens_clothing_ecommerce_reviews.tsv\n</code></pre> <p>Check the existence of those files in the S3 bucket:</p> <pre><code>!aws s3 ls --recursive $processed_train_data_s3_uri\n</code></pre> <pre><code>2023-06-11 14:23:03    4894416 data/sentiment-train/part-algo-1-womens_clothing_ecommerce_reviews.tsv\n</code></pre> <pre><code>!aws s3 ls --recursive $processed_validation_data_s3_uri\n</code></pre> <pre><code>2023-06-11 14:23:04     276522 data/sentiment-validation/part-algo-1-womens_clothing_ecommerce_reviews.tsv\n</code></pre> <p>You will need to setup the input data channels, wrapping the S3 locations in a <code>TrainingInput</code> object to use with the SageMaker Training Job. This can be organized as a dictionary</p> <pre><code>data_channels = {\n    'train': ..., # training data\n    'validation': ... # validation data\n}\n</code></pre> <p>where training and validation data are the Amazon SageMaker channels for S3 input data sources.</p> <p></p>"},{"location":"datascience_on_aws/classifier_bert_amazon_sagemaker/#exercise-1","title":"Exercise 1","text":"<p>Create a train data channel.</p> <p>Instructions: Pass the S3 input path for training data into the <code>sagemaker.inputs.TrainingInput</code> function.</p> <pre><code>s3_input_train_data = sagemaker.inputs.TrainingInput(\n    ### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n    s3_data=processed_train_data_s3_uri # Replace None\n    ### END SOLUTION - DO NOT delete this comment for grading purposes\n)\n</code></pre> <p></p>"},{"location":"datascience_on_aws/classifier_bert_amazon_sagemaker/#exercise-2","title":"Exercise 2","text":"<p>Create a validation data channel.</p> <p>Instructions: Pass the S3 input path for validation data into the <code>sagemaker.inputs.TrainingInput</code> function.</p> <pre><code>s3_input_validation_data = sagemaker.inputs.TrainingInput(\n    ### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n    s3_data=processed_validation_data_s3_uri # Replace None\n    ### END SOLUTION - DO NOT delete this comment for grading purposes\n)\n</code></pre> <p></p>"},{"location":"datascience_on_aws/classifier_bert_amazon_sagemaker/#exercise-3","title":"Exercise 3","text":"<p>Organize data channels defined above as a dictionary.</p> <pre><code>data_channels = {\n    ### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n    'train': s3_input_train_data, # Replace None\n    'validation': s3_input_validation_data # Replace None\n    ### END SOLUTION - DO NOT delete this comment for grading purposes\n}\n</code></pre> <p></p>"},{"location":"datascience_on_aws/classifier_bert_amazon_sagemaker/#12-configure-model-hyper-parameters","title":"1.2. Configure model hyper-parameters","text":"<p>Set the Training Job parameters including the instance type, instance count, learning rate, batch size etc. For the purposes of this lab, you will use a relatively small instance type. Please refer to this link for additional instance types that may work for your use cases outside of this lab.</p> <pre><code>max_seq_length=128 # maximum number of input tokens passed to BERT model\nfreeze_bert_layer=False # specifies the depth of training within the network\nepochs=3\nlearning_rate=2e-5\ntrain_batch_size=256\ntrain_steps_per_epoch=50\nvalidation_batch_size=256\nvalidation_steps_per_epoch=50\nseed=42\nrun_validation=True\n\ntrain_instance_count=1\ntrain_instance_type='ml.c5.9xlarge'\ntrain_volume_size=256\ninput_mode='File'\n</code></pre> <p>Some of them will be passed into the PyTorch estimator in the hyperparameters argument. Let's setup the dictionary for that:</p> <pre><code>hyperparameters={\n    'max_seq_length': max_seq_length,\n    'freeze_bert_layer': freeze_bert_layer,\n    'epochs': epochs,\n    'learning_rate': learning_rate,\n    'train_batch_size': train_batch_size,\n    'train_steps_per_epoch': train_steps_per_epoch,\n    'validation_batch_size': validation_batch_size,\n    'validation_steps_per_epoch': validation_steps_per_epoch,    \n    'seed': seed,\n    'run_validation': run_validation\n}\n</code></pre> <p></p>"},{"location":"datascience_on_aws/classifier_bert_amazon_sagemaker/#13-setup-evaluation-metrics","title":"1.3. Setup evaluation metrics","text":"<p>Choose loss and accuracy as the evaluation metrics. The regular expressions <code>Regex</code> will capture the values of metrics that the algorithm will emit.</p> <pre><code>metric_definitions = [\n     {'Name': 'validation:loss', 'Regex': 'val_loss: ([0-9.]+)'},\n     {'Name': 'validation:accuracy', 'Regex': 'val_acc: ([0-9.]+)'},\n]\n</code></pre> <p>For example, these sample log lines...</p> <pre><code>[step: 100] val_loss: 0.76 - val_acc: 70.92%\n</code></pre> <p>...will produce the following metrics in CloudWatch:</p> <p><code>validation:loss</code> =  0.76</p> <p><code>validation:accuracy</code> = 70.92</p> <p></p> <p></p>"},{"location":"datascience_on_aws/classifier_bert_amazon_sagemaker/#14-setup-debugger-and-profiler","title":"1.4. Setup Debugger and Profiler","text":"<p>Amazon SageMaker Debugger can be used to profile machine learning models, helping to identify and fix training issues caused by hardware resource usage. Setting some parameters in the SageMaker estimator, without any change to the training code, you can enable the collection of infrastructure and model metrics such as: CPU and GPU, RAM and GPU RAM, data loading time, time spent in ML operators running on CPU and GPU, distributed training metrics and many more. In addition, you can visualize how much time is spent in different phases, such as preprocessing, training loop, and postprocessing. If needed, you can drill down on each training epoch, and even on each function in your training script.</p> <p>Define Debugger Rules as described here:  https://docs.aws.amazon.com/sagemaker/latest/dg/debugger-built-in-rules.html</p> <pre><code>from sagemaker.debugger import Rule, ProfilerRule, rule_configs\nfrom sagemaker.debugger import DebuggerHookConfig\nfrom sagemaker.debugger import ProfilerConfig, FrameworkProfile\n</code></pre> <p><code>DebuggerHookConfig</code> provides options to customize how debugging information is emitted and saved. <code>s3_output_path</code> argument value defines the location in Amazon S3 to store the output.</p> <pre><code>debugger_hook_config = DebuggerHookConfig(\n    s3_output_path='s3://{}'.format(bucket),\n)\n</code></pre> <p><code>ProfilerConfig</code> sets the configuration for collecting system and framework metrics of SageMaker Training Jobs. Parameter <code>system_monitor_interval_millis</code> sets the time interval to collect system metrics (in milliseconds). Parameter <code>framework_profile_params</code> is the object for framework metrics profiling. Here you will set its local path, the step at which to start profiling, <code>start_step</code>, and the number of steps to profile, <code>num_steps</code>.</p> <pre><code>from sagemaker.debugger import ProfilerConfig, FrameworkProfile\n\nprofiler_config = ProfilerConfig(\n    system_monitor_interval_millis=500,\n    framework_profile_params=FrameworkProfile(local_path=\"/opt/ml/output/profiler/\", start_step=5, num_steps=10)\n)\n</code></pre> <p>For monitoring and profiling the built-in rules you can use the <code>ProfilerReport</code>. It creates a profiling report and updates when the individual rules are triggered. If you trigger this <code>ProfilerReport</code> rule without any customized parameter as in the cell below, then the <code>ProfilerReport</code> rule triggers all of the built-in rules for monitoring and profiling with their default parameter values.</p> <p>The profiling report can be downloaded while the Training Job is running or after the job has finished.</p> <pre><code>rules=[ProfilerRule.sagemaker(rule_configs.ProfilerReport())]\n</code></pre> <p></p>"},{"location":"datascience_on_aws/classifier_bert_amazon_sagemaker/#2-train-model","title":"2. Train model","text":""},{"location":"datascience_on_aws/classifier_bert_amazon_sagemaker/#21-setup-the-roberta-and-pytorch-script-to-run-on-sagemaker","title":"2.1. Setup the RoBERTa and PyTorch script to run on SageMaker","text":"<p>You will prepare the PyTorch model to run as a SageMaker Training Job in a separate Python file, which will be called during the training. </p> <p>Here you will be using the pre-trained model <code>roberta-base</code>. The information about the available models can be found in the Hugging Face website.</p> <p></p>"},{"location":"datascience_on_aws/classifier_bert_amazon_sagemaker/#exercise-4","title":"Exercise 4","text":"<ol> <li>Open the file src/train.py. Go through the comments to understand its content.</li> <li>Find and review the <code>configure_model()</code> function, which contains the RoBERTa model configuration. </li> <li>In the following function investigate given mapping <code>label2id</code> of a 0-indexed list of classes used by BERT [0, 1, 2] to the list of the sentiment values [-1, 0, 1]:</li> </ol> <pre><code>    config = RobertaConfig.from_pretrained(\n        PRE_TRAINED_MODEL_NAME, \n        num_labels=len(classes),\n        id2label={\n            ...: ...,\n            ...: ...,\n            ...: ...,\n        },\n        label2id={\n            -1: 0,\n            0: 1,\n            1: 2,\n        }\n    )\n\n</code></pre> <ol> <li> <p>Update the function setting up the opposite mapping <code>id2label</code>: sentiment values [-1, 0, 1] to a 0-indexed list of classes used by BERT.</p> </li> <li> <p>Save the file src/train.py (with the menu command File -&gt; Save Python File).</p> </li> </ol> <pre><code>import sys, importlib\nsys.path.append('src/')\n\nimport train\n\n# reload the module if it has been previously loaded\nif 'train' in sys.modules:\n    importlib.reload(train)\n\n# Ignore warnings below\nconfig = train.configure_model()\n\nlabel_0 = config.id2label[0]\nlabel_1 = config.id2label[1]\nlabel_2 = config.id2label[2]\n\nupdated_correctly = False\n\nif label_0 != -1 or label_1 != 0 or label_2 != 1:\n    print('#######################################################################################')\n    print('Please check that the function \\'configure_model\\' in the file src/train.py is complete.')\n    print('########################################################################################')\n    raise Exception('Please check that the function \\'configure_model\\' in the file src/train.py is complete.')\nelse:\n    print('##################')    \n    print('Updated correctly!')        \n    print('##################')        \n\n    updated_correctly = True\n</code></pre> <pre><code>HBox(children=(FloatProgress(value=0.0, description='Downloading', max=481.0, style=ProgressStyle(description_\u2026\n\n\n\n##################\nUpdated correctly!\n##################\n</code></pre> <p>Setup the PyTorch estimator to train our model. For more information on the PyTorch estimator, see the documentation here. </p> <pre><code>from sagemaker.pytorch import PyTorch as PyTorchEstimator\n\nif updated_correctly:\n    estimator = PyTorchEstimator(\n        entry_point='train.py',\n        source_dir='src',\n        role=role,\n        instance_count=train_instance_count,\n        instance_type=train_instance_type,\n        volume_size=train_volume_size,\n        py_version='py3', # dynamically retrieves the correct training image (Python 3)\n        framework_version='1.6.0', # dynamically retrieves the correct training image (PyTorch)\n        hyperparameters=hyperparameters,\n        metric_definitions=metric_definitions,\n        input_mode=input_mode,\n        debugger_hook_config=debugger_hook_config,\n        profiler_config=profiler_config,\n        rules=rules\n    )\n</code></pre> <p></p>"},{"location":"datascience_on_aws/classifier_bert_amazon_sagemaker/#exercise-5","title":"Exercise 5","text":"<p>Launch the SageMaker Training Job which will be fitting the model to the dataset.</p> <p>Instructions: Use the <code>estimator.fit</code> function, passing the configured train and validation inputs (data channels).</p> <pre><code>estimator.fit(\n    inputs=..., # train and validation input\n    wait=False # do not wait for the job to complete before continuing\n)\n</code></pre> <pre><code>estimator.fit(\n    ### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n    inputs=data_channels, # Replace None\n    ### END SOLUTION - DO NOT delete this comment for grading purposes\n    wait=False\n)\n</code></pre> <p>You can refer to the last Training Job using the estimator function <code>latest_training_job</code>. Then the Training Job name can be found with the <code>name</code> function:</p> <pre><code>training_job_name = estimator.latest_training_job.name\n\nprint('Training Job name: {}'.format(training_job_name))\n</code></pre> <pre><code>Training Job name: pytorch-training-2023-06-11-14-31-02-662\n</code></pre> <p>You can also load the information about the Training Job using the function <code>describe()</code>. The result is in dictionary format. Let's check that it has the same Training Job name:</p> <pre><code>training_job_name = estimator.latest_training_job.describe()['TrainingJobName']\n\nprint('Training Job name: {}'.format(training_job_name))\n</code></pre> <pre><code>Training Job name: pytorch-training-2023-06-11-14-31-02-662\n</code></pre> <p></p>"},{"location":"datascience_on_aws/classifier_bert_amazon_sagemaker/#exercise-6","title":"Exercise 6","text":"<p>Pull the Training Job status from the Training Job description.</p> <p>Instructions: Print the keys of the Training Job description dictionary, choose the one related to the primary status of the Training Job and print the value of it.</p> <pre><code>print(estimator.latest_training_job.describe().keys())\n</code></pre> <pre><code>dict_keys(['TrainingJobName', 'TrainingJobArn', 'TrainingJobStatus', 'SecondaryStatus', 'HyperParameters', 'AlgorithmSpecification', 'RoleArn', 'InputDataConfig', 'OutputDataConfig', 'ResourceConfig', 'StoppingCondition', 'CreationTime', 'LastModifiedTime', 'SecondaryStatusTransitions', 'EnableNetworkIsolation', 'EnableInterContainerTrafficEncryption', 'EnableManagedSpotTraining', 'DebugHookConfig', 'ProfilerConfig', 'ProfilerRuleConfigurations', 'ProfilerRuleEvaluationStatuses', 'ProfilingStatus', 'ResponseMetadata'])\n</code></pre> <pre><code>### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\ntraining_job_status_primary = estimator.latest_training_job.describe()['TrainingJobStatus'] # Replace None\n### END SOLUTION - DO NOT delete this comment for grading purposes\nprint('Training Job status: {}'.format(training_job_status_primary))\n</code></pre> <pre><code>Training Job status: InProgress\n</code></pre> <p>Review the Training Job in the console.</p> <p>Instructions:  - open the link - notice that you are in the section <code>Amazon SageMaker</code> -&gt; <code>Training jobs</code> - check the name of the Training Job, its status and other available information - review metrics in the <code>Monitor</code> section</p> <pre><code>from IPython.core.display import display, HTML\n\ndisplay(HTML('&lt;b&gt;Review &lt;a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={}#/jobs/{}\"&gt;Training Job&lt;/a&gt;&lt;/b&gt;'.format(region, training_job_name)))\n</code></pre> <p>Review Training Job</p> <p>Review the Cloud Watch logs (after about 5 minutes).</p> <p>Instructions:  - open the link - open the log stream with the name, which starts from the training job name - have a quick look at the log messages</p> <pre><code>from IPython.core.display import display, HTML\n\ndisplay(HTML('&lt;b&gt;Review &lt;a target=\"blank\" href=\"https://console.aws.amazon.com/cloudwatch/home?region={}#logStream:group=/aws/sagemaker/TrainingJobs;prefix={};streamFilter=typeLogStreamPrefix\"&gt;CloudWatch logs&lt;/a&gt; after about 5 minutes&lt;/b&gt;'.format(region, training_job_name)))\n</code></pre> <p>Review CloudWatch logs after about 5 minutes</p> <pre><code>from IPython.core.display import display, HTML\n\ndisplay(HTML('&lt;b&gt;Review &lt;a target=\"blank\" href=\"https://s3.console.aws.amazon.com/s3/buckets/{}/{}/?region={}&amp;tab=overview\"&gt;S3 output data&lt;/a&gt; after the Training Job has completed&lt;/b&gt;'.format(bucket, training_job_name, region)))\n\n</code></pre> <p>Review S3 output data after the Training Job has completed</p> <p>Wait for the Training Job to complete.</p>"},{"location":"datascience_on_aws/classifier_bert_amazon_sagemaker/#this-cell-will-take-approximately-30-40-minutes-to-run","title":"This cell will take approximately 30-40 minutes to run.","text":"<pre><code>%%time\n\nestimator.latest_training_job.wait(logs=False)\n</code></pre> <pre><code>2023-06-11 14:33:47 Starting - Preparing the instances for training\n2023-06-11 14:33:47 Downloading - Downloading input data\n2023-06-11 14:33:47 Training - Training image download completed. Training in progress...............................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n2023-06-11 15:13:38 Uploading - Uploading generated training model.....................................\n2023-06-11 15:16:49 Completed - Training job completed\nCPU times: user 2.33 s, sys: 216 ms, total: 2.55 s\nWall time: 42min 44s\n</code></pre> <p>Wait until the ^^ Training Job ^^ completes above</p> <p>Review the training metrics.</p> <pre><code>df_metrics = estimator.training_job_analytics.dataframe()\ndf_metrics\n</code></pre> timestamp metric_name value 0 0.0 validation:loss 1.10 1 1320.0 validation:loss 1.02 2 1860.0 validation:loss 0.66 3 0.0 validation:accuracy 34.77 4 1320.0 validation:accuracy 50.39 5 1860.0 validation:accuracy 69.14 <p>You can query and plot the training metrics:</p> <pre><code>df_metrics.query(\"metric_name=='validation:accuracy'\").plot(x='timestamp', y='value')\n</code></pre> <pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7efca8950990&gt;\n</code></pre> <p></p> <p></p>"},{"location":"datascience_on_aws/classifier_bert_amazon_sagemaker/#22-analyze-debugger-results","title":"2.2. Analyze Debugger results","text":"<p>You can now explore the debugger output data:</p> <pre><code>from IPython.core.display import display, HTML\n\ndisplay(\n    HTML(\n        '&lt;b&gt;Review &lt;a target=\"blank\" href=\"https://s3.console.aws.amazon.com/s3/buckets/{}?prefix={}/\"&gt;S3 debugger output data&lt;/a&gt;&lt;/b&gt;'.format(\n            bucket, training_job_name\n        )\n    )\n)\n</code></pre> <p>Review S3 debugger output data</p> <p></p>"},{"location":"datascience_on_aws/classifier_bert_amazon_sagemaker/#23-download-sagemaker-debugger-profiling-report","title":"2.3. Download SageMaker debugger profiling report","text":"<p>You can download and review the debugger profiling report. Here is the path in the S3 bucket:</p> <pre><code>profiler_report_s3_uri = \"s3://{}/{}/rule-output/ProfilerReport/profiler-output\".format(bucket, training_job_name)\n</code></pre> <p>You can list the report files:</p> <pre><code>!aws s3 ls $profiler_report_s3_uri/\n</code></pre> <pre><code>                           PRE profiler-reports/\n2023-06-11 15:13:55     364652 profiler-report.html\n2023-06-11 15:13:54     211703 profiler-report.ipynb\n</code></pre> <p>The folder <code>profiler-reports</code> contains the built-in rule analysis components, stored in JSON and a Jupyter notebook. They are aggregated into the report.</p> <pre><code>!aws s3 cp --recursive $profiler_report_s3_uri ./profiler_report/\n</code></pre> <pre><code>download: s3://sagemaker-us-east-1-118847640144/pytorch-training-2023-06-11-14-31-02-662/rule-output/ProfilerReport/profiler-output/profiler-reports/GPUMemoryIncrease.json to profiler_report/profiler-reports/GPUMemoryIncrease.json\ndownload: s3://sagemaker-us-east-1-118847640144/pytorch-training-2023-06-11-14-31-02-662/rule-output/ProfilerReport/profiler-output/profiler-reports/LowGPUUtilization.json to profiler_report/profiler-reports/LowGPUUtilization.json\ndownload: s3://sagemaker-us-east-1-118847640144/pytorch-training-2023-06-11-14-31-02-662/rule-output/ProfilerReport/profiler-output/profiler-reports/BatchSize.json to profiler_report/profiler-reports/BatchSize.json\ndownload: s3://sagemaker-us-east-1-118847640144/pytorch-training-2023-06-11-14-31-02-662/rule-output/ProfilerReport/profiler-output/profiler-reports/IOBottleneck.json to profiler_report/profiler-reports/IOBottleneck.json\ndownload: s3://sagemaker-us-east-1-118847640144/pytorch-training-2023-06-11-14-31-02-662/rule-output/ProfilerReport/profiler-output/profiler-reports/CPUBottleneck.json to profiler_report/profiler-reports/CPUBottleneck.json\ndownload: s3://sagemaker-us-east-1-118847640144/pytorch-training-2023-06-11-14-31-02-662/rule-output/ProfilerReport/profiler-output/profiler-reports/LoadBalancing.json to profiler_report/profiler-reports/LoadBalancing.json\ndownload: s3://sagemaker-us-east-1-118847640144/pytorch-training-2023-06-11-14-31-02-662/rule-output/ProfilerReport/profiler-output/profiler-report.html to profiler_report/profiler-report.html\ndownload: s3://sagemaker-us-east-1-118847640144/pytorch-training-2023-06-11-14-31-02-662/rule-output/ProfilerReport/profiler-output/profiler-report.ipynb to profiler_report/profiler-report.ipynb\ndownload: s3://sagemaker-us-east-1-118847640144/pytorch-training-2023-06-11-14-31-02-662/rule-output/ProfilerReport/profiler-output/profiler-reports/MaxInitializationTime.json to profiler_report/profiler-reports/MaxInitializationTime.json\ndownload: s3://sagemaker-us-east-1-118847640144/pytorch-training-2023-06-11-14-31-02-662/rule-output/ProfilerReport/profiler-output/profiler-reports/OverallSystemUsage.json to profiler_report/profiler-reports/OverallSystemUsage.json\ndownload: s3://sagemaker-us-east-1-118847640144/pytorch-training-2023-06-11-14-31-02-662/rule-output/ProfilerReport/profiler-output/profiler-reports/Dataloader.json to profiler_report/profiler-reports/Dataloader.json\ndownload: s3://sagemaker-us-east-1-118847640144/pytorch-training-2023-06-11-14-31-02-662/rule-output/ProfilerReport/profiler-output/profiler-reports/StepOutlier.json to profiler_report/profiler-reports/StepOutlier.json\ndownload: s3://sagemaker-us-east-1-118847640144/pytorch-training-2023-06-11-14-31-02-662/rule-output/ProfilerReport/profiler-output/profiler-reports/OverallFrameworkMetrics.json to profiler_report/profiler-reports/OverallFrameworkMetrics.json\n</code></pre> <p>You can review the profiler report in the console.</p> <p>Note: Click <code>Trust HTML</code> in the profiler-report.html tab that opens (on top of the document).</p> <pre><code>from IPython.core.display import display, HTML\n\ndisplay(HTML('&lt;b&gt;Review &lt;a target=\"blank\" href=\"./profiler_report/profiler-report.html\"&gt;profiler report&lt;/a&gt;&lt;/b&gt;'))\n</code></pre> <p>Review profiler report</p> <p></p>"},{"location":"datascience_on_aws/classifier_bert_amazon_sagemaker/#3-deploy-the-model","title":"3. Deploy the model","text":"<p>Create a custom <code>SentimentPredictor</code> that encapsulates a JSONLines serializer and deserializer. To be passed into the <code>PyTorchModel</code> it needs to be wrapped as a class.</p> <pre><code>from sagemaker.predictor import Predictor\nfrom sagemaker.serializers import JSONLinesSerializer\nfrom sagemaker.deserializers import JSONLinesDeserializer\n\nclass SentimentPredictor(Predictor):\n    def __init__(self, endpoint_name, sagemaker_session):\n        super().__init__(endpoint_name, \n                         sagemaker_session=sagemaker_session, \n                         serializer=JSONLinesSerializer(),\n                         deserializer=JSONLinesDeserializer())\n</code></pre> <pre><code>import time\nfrom sagemaker.pytorch.model import PyTorchModel\n\ntimestamp = int(time.time())\n\npytorch_model_name = '{}-{}-{}'.format(training_job_name, 'pt', timestamp)\n\nmodel = PyTorchModel(name=pytorch_model_name,\n                     model_data=estimator.model_data,\n                     predictor_cls=SentimentPredictor,\n                     entry_point='inference.py',\n                     source_dir='src',\n                     framework_version='1.6.0',\n                     py_version='py3',\n                     role=role)\n</code></pre> <pre><code>import time\n\npytorch_endpoint_name = '{}-{}-{}'.format(training_job_name, 'pt', timestamp)\n\nprint(pytorch_endpoint_name)\n</code></pre> <pre><code>pytorch-training-2023-06-11-14-31-02-662-pt-1686496734\n</code></pre>"},{"location":"datascience_on_aws/classifier_bert_amazon_sagemaker/#this-cell-will-take-approximately-5-10-minutes-to-run","title":"This cell will take approximately 5-10 minutes to run.","text":"<pre><code>%%time\n\npredictor = model.deploy(initial_instance_count=1, \n                         instance_type='ml.m5.large', \n                         endpoint_name=pytorch_endpoint_name)\n</code></pre> <pre><code>----------!CPU times: user 2min 15s, sys: 9.04 s, total: 2min 24s\nWall time: 7min 27s\n</code></pre> <p>Review the Endpoint in the AWS console.</p> <p>Instructions:  - open the link - notice that you are in the section <code>Amazon SageMaker</code> -&gt; <code>Endpoints</code> - check the name of the Endpoint, its status and other available information</p> <pre><code>from IPython.core.display import display, HTML\n\ndisplay(HTML('&lt;b&gt;Review &lt;a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={}#/endpoints/{}\"&gt;SageMaker REST Endpoint&lt;/a&gt;&lt;/b&gt;'.format(region, pytorch_endpoint_name)))\n</code></pre> <p>Review SageMaker REST Endpoint</p> <p></p>"},{"location":"datascience_on_aws/classifier_bert_amazon_sagemaker/#4-test-model","title":"4. Test model","text":"<p>Here, we will pass sample strings of text to the endpoint in order to see the sentiment. We give you one example of each, however, feel free to play around and change the strings yourself!</p> <pre><code>inputs = [\n    {\"features\": [\"I love this product!\"]},\n    {\"features\": [\"OK, but not great.\"]},\n    {\"features\": [\"This is not the right product.\"]},\n]\n\npredictor = SentimentPredictor(endpoint_name=pytorch_endpoint_name,\n                               sagemaker_session=sess)\n\npredicted_classes = predictor.predict(inputs)\n\nfor predicted_class in predicted_classes:\n    print(\"Predicted class {} with probability {}\".format(predicted_class['predicted_label'], predicted_class['probability']))\n</code></pre> <pre><code>Predicted class 1 with probability 0.9605445861816406\nPredicted class 0 with probability 0.5798221230506897\nPredicted class -1 with probability 0.7667604684829712\n</code></pre> <p>Upload the notebook and train.py file into S3 bucket for grading purposes.</p> <p>Note: you may need to save the file before the upload.</p> <pre><code>!aws s3 cp ./C2_W2_Assignment.ipynb s3://$bucket/C2_W2_Assignment_Learner.ipynb\n!aws s3 cp ./src/train.py s3://$bucket/src/C2_W2_train_Learner.py\n</code></pre> <pre><code>upload: ./C2_W2_Assignment.ipynb to s3://sagemaker-us-east-1-118847640144/C2_W2_Assignment_Learner.ipynb\nupload: src/train.py to s3://sagemaker-us-east-1-118847640144/src/C2_W2_train_Learner.py\n</code></pre> <p>Please go to the main lab window and click on <code>Submit</code> button (see the <code>Finish the lab</code> section of the instructions).</p> <pre><code>\n</code></pre>"},{"location":"datascience_on_aws/detect_bias_amazon_sagemaker_clarify/","title":"Detect data bias with Amazon SageMaker Clarify","text":""},{"location":"datascience_on_aws/detect_bias_amazon_sagemaker_clarify/#detect-data-bias-with-amazon-sagemaker-clarify","title":"Detect data bias with Amazon SageMaker Clarify","text":""},{"location":"datascience_on_aws/detect_bias_amazon_sagemaker_clarify/#introduction","title":"Introduction","text":"<p>Bias can be present in your data before any model training occurs. Inspecting the dataset for bias can help detect collection gaps, inform your feature engineering, and understand societal biases the dataset may reflect. In this lab you will analyze bias on the dataset, generate and analyze bias report, and prepare the dataset for the model training.</p> <p>First, let's install and import required modules.</p> <pre><code># please ignore warning messages during the installation\n!pip install --disable-pip-version-check -q sagemaker==2.35.0\n</code></pre> <pre><code>\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n</code></pre> <pre><code>import boto3\nimport sagemaker\nimport pandas as pd\nimport numpy as np\nimport botocore\n\nconfig = botocore.config.Config(user_agent_extra='dlai-pds/c1/w2')\n\n# low-level service client of the boto3 session\nsm = boto3.client(service_name='sagemaker', \n                  config=config)\n\nsess = sagemaker.Session(sagemaker_client=sm)\n\nbucket = sess.default_bucket()\nrole = sagemaker.get_execution_role()\nregion = sess.boto_region_name\n</code></pre>                         Clean data in minutes                     Automatically visualize data, and improve data quality in a few clicks. Learn more Import Data Wrangler widget Remind me later Don't show again <pre><code>import matplotlib.pyplot as plt\n%matplotlib inline\n%config InlineBackend.figure_format='retina'\n</code></pre> <p></p>"},{"location":"datascience_on_aws/detect_bias_amazon_sagemaker_clarify/#1-analyze-the-dataset","title":"1. Analyze the dataset","text":""},{"location":"datascience_on_aws/detect_bias_amazon_sagemaker_clarify/#11-create-a-pandas-data-frame-from-the-csv-file","title":"1.1. Create a pandas data frame from the CSV file","text":"<p>Create a pandas dataframe from each of the product categories and concatenate them into one.</p> <pre><code>!aws s3 cp 's3://dlai-practical-data-science/data/transformed/womens_clothing_ecommerce_reviews_transformed.csv' ./\n</code></pre> <pre><code>download: s3://dlai-practical-data-science/data/transformed/womens_clothing_ecommerce_reviews_transformed.csv to ./womens_clothing_ecommerce_reviews_transformed.csv\n</code></pre> <pre><code>path = './womens_clothing_ecommerce_reviews_transformed.csv'\n\ndf = pd.read_csv(path)\ndf.head()\n</code></pre> sentiment review_body product_category 0 1 If this product was in petite  i would get the... Blouses 1 1 Love this dress!  it's sooo pretty.  i happene... Dresses 2 0 I had such high hopes for this dress and reall... Dresses 3 1 I love  love  love this jumpsuit. it's fun  fl... Pants 4 1 This shirt is very flattering to all due to th... Blouses <p>As you saw in the previous lab, there are way more positive reviews than negative or neutral. Such a dataset is called unbalanced. </p> <p>In this case, using a relatively small data subset you could visualize the occurring unbalances. At scale, you would need to perform bias analysis. Let's use this dataset as an example.</p> <pre><code>import seaborn as sns\n\nsns.countplot(data=df, x='sentiment', hue='product_category')\n\nplt.legend(loc='upper right',bbox_to_anchor=(1.3, 1.1))\n</code></pre> <pre><code>&lt;matplotlib.legend.Legend at 0x7fb430c7cd10&gt;\n</code></pre> <p></p> <p></p>"},{"location":"datascience_on_aws/detect_bias_amazon_sagemaker_clarify/#12-upload-the-dataset-to-s3-bucket","title":"1.2. Upload the dataset to S3 bucket","text":"<p>Upload the dataset to a private S3 bucket in a folder called <code>bias/unbalanced</code>.</p> <pre><code>data_s3_uri_unbalanced = sess.upload_data(bucket=bucket, \n                               key_prefix='bias/unbalanced', \n                               path='./womens_clothing_ecommerce_reviews_transformed.csv')\ndata_s3_uri_unbalanced\n</code></pre> <pre><code>'s3://sagemaker-us-east-1-505802170089/bias/unbalanced/womens_clothing_ecommerce_reviews_transformed.csv'\n</code></pre> <p>You can review the uploaded CSV file in the S3 bucket.</p> <p>Instructions:  - open the link - click on the S3 bucket name <code>sagemaker-us-east-1-ACCOUNT</code> - go to the folder <code>bias/unbalanced</code> - check the existence of the file <code>womens_clothing_ecommerce_reviews_transformed.csv</code></p> <pre><code>from IPython.core.display import display, HTML\n\ndisplay(HTML('&lt;b&gt;Review &lt;a target=\"top\" href=\"https://s3.console.aws.amazon.com/s3/home?region={}#\"&gt;Amazon S3 bucket&lt;/a&gt;&lt;/b&gt;'.format(region)))\n</code></pre> <p>Review Amazon S3 bucket</p> <p></p>"},{"location":"datascience_on_aws/detect_bias_amazon_sagemaker_clarify/#2-analyze-class-imbalance-on-the-dataset-with-amazon-sagemaker-clarify","title":"2. Analyze class imbalance on the dataset with Amazon SageMaker Clarify","text":"<p>Let's analyze bias in <code>sentiment</code> with respect to the <code>product_category</code> facet on the dataset.</p> <p></p>"},{"location":"datascience_on_aws/detect_bias_amazon_sagemaker_clarify/#21-configure-a-dataconfig","title":"2.1. Configure a <code>DataConfig</code>","text":"<p>Information about the input data needs to be provided to the processor. This can be done with the <code>DataConfig</code> of the Clarify container. It stores information about the dataset to be analyzed, for example the dataset file, its format, headers and labels.</p> <p></p>"},{"location":"datascience_on_aws/detect_bias_amazon_sagemaker_clarify/#exercise-1","title":"Exercise 1","text":"<p>Configure a <code>DataConfig</code> for Clarify.</p> <p>Instructions: Use <code>DataConfig</code> to configure the target column (<code>'sentiment'</code> label), data input (<code>data_s3_uri_unbalanced</code>) and output paths (<code>bias_report_unbalanced_output_path</code>) with their formats (header names and the dataset type):</p> <pre><code>data_config_unbalanced = clarify.DataConfig(\n    s3_data_input_path=..., # S3 object path containing the unbalanced dataset\n    s3_output_path=..., # path to store the output\n    label='...', # target column\n    headers=df_unbalanced.columns.to_list(),\n    dataset_type='text/csv'\n)\n</code></pre> <pre><code>from sagemaker import clarify\n\nbias_report_unbalanced_output_path = 's3://{}/bias/generated_bias_report/unbalanced'.format(bucket)\n\ndata_config_unbalanced = clarify.DataConfig(\n    ### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n    s3_data_input_path='s3://sagemaker-us-east-1-505802170089/bias/unbalanced/womens_clothing_ecommerce_reviews_transformed.csv', # Replace None\n    s3_output_path=bias_report_unbalanced_output_path, # Replace None\n    label='sentiment', # Replace None\n    ### END SOLUTION - DO NOT delete this comment for grading purposes\n    headers=df.columns.to_list(),\n    dataset_type='text/csv'\n)\n</code></pre> <p></p>"},{"location":"datascience_on_aws/detect_bias_amazon_sagemaker_clarify/#22-configure-biasconfig","title":"2.2. Configure <code>BiasConfig</code>","text":"<p>Bias is measured by calculating a metric and comparing it across groups. To compute it, you will specify the required information in the <code>BiasConfig</code> API. SageMaker Clarify needs the sensitive columns (<code>facet_name</code>) and the desirable outcomes (<code>label_values_or_threshold</code>). Here <code>product_category</code> is the sensitive facet and the desired outcome is with the <code>sentiment==1</code>.</p> <p>SageMaker Clarify can handle both categorical and continuous data for <code>label_values_or_threshold</code>. In this case you are using categorical data.</p> <pre><code>bias_config_unbalanced = clarify.BiasConfig(\n    label_values_or_threshold=[1], # desired sentiment\n    facet_name='product_category' # sensitive column (facet)\n)\n</code></pre> <p></p>"},{"location":"datascience_on_aws/detect_bias_amazon_sagemaker_clarify/#23-configure-amazon-sagemaker-clarify-as-a-processing-job","title":"2.3. Configure Amazon SageMaker Clarify as a processing job","text":"<p>Now you need to construct an object called <code>SageMakerClarifyProcessor</code>. This allows you to scale the process of data bias detection using two parameters, <code>instance_count</code> and <code>instance_type</code>. <code>Instance_count</code> represents how many nodes you want in the distributor cluster during the data detection. <code>Instance_type</code> specifies the processing capability (compute capacity, memory capacity) available for each one of those nodes. For the purposes of this lab, you will use a relatively small instance type. Please refer to this link for additional instance types that may work for your use case outside of this lab.</p> <pre><code>clarify_processor_unbalanced = clarify.SageMakerClarifyProcessor(role=role,\n                                                      instance_count=1,\n                                                      instance_type='ml.m5.large',\n                                                      sagemaker_session=sess)\n</code></pre> <p></p>"},{"location":"datascience_on_aws/detect_bias_amazon_sagemaker_clarify/#24-run-the-amazon-sagemaker-clarify-processing-job","title":"2.4. Run the Amazon SageMaker Clarify processing job","text":""},{"location":"datascience_on_aws/detect_bias_amazon_sagemaker_clarify/#exercise-2","title":"Exercise 2","text":"<p>Run the configured processing job to compute the requested bias <code>methods</code> of the input data</p> <p>Instructions: Apply the <code>run_pre_training_bias</code> method to the configured Clarify processor, passing the configured input/output data (<code>data_config_unbalanced</code>), configuration of sensitive groups (<code>bias_config_unbalanced</code>) with the other job setup parameters:</p> <pre><code>clarify_processor_unbalanced.run_pre_training_bias(\n    data_config=..., # configured input/output data\n    data_bias_config=..., # configured sensitive groups\n    methods=[\"CI\", \"DPL\", \"KL\", \"JS\", \"LP\", \"TVD\", \"KS\"], # selector of a subset of potential metrics\n    wait=False, # whether the call should wait until the job completes (default: True)\n    logs=False # whether to show the logs produced by the job. Only meaningful when wait is True (default: True)\n)\n</code></pre> <pre><code>clarify_processor_unbalanced.run_pre_training_bias(\n    ### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n    data_config=data_config_unbalanced, # Replace None\n    data_bias_config=bias_config_unbalanced, # Replace None\n    ### END SOLUTION - DO NOT delete this comment for grading purposes\n    methods=[\"CI\", \"DPL\", \"KL\", \"JS\", \"LP\", \"TVD\", \"KS\"],\n    wait=False,\n    logs=False\n)\n</code></pre> <pre><code>Job Name:  Clarify-Pretraining-Bias-2023-06-09-13-54-14-420\nInputs:  [{'InputName': 'dataset', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-505802170089/bias/unbalanced/womens_clothing_ecommerce_reviews_transformed.csv', 'LocalPath': '/opt/ml/processing/input/data', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'analysis_config', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-505802170089/bias/generated_bias_report/unbalanced/analysis_config.json', 'LocalPath': '/opt/ml/processing/input/config', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\nOutputs:  [{'OutputName': 'analysis_result', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-505802170089/bias/generated_bias_report/unbalanced', 'LocalPath': '/opt/ml/processing/output', 'S3UploadMode': 'EndOfJob'}}]\n</code></pre> <pre><code>run_unbalanced_bias_processing_job_name = clarify_processor_unbalanced.latest_job.job_name\nprint(run_unbalanced_bias_processing_job_name)\n</code></pre> <pre><code>Clarify-Pretraining-Bias-2023-06-09-13-54-14-420\n</code></pre> <p></p>"},{"location":"datascience_on_aws/detect_bias_amazon_sagemaker_clarify/#25-run-and-review-the-amazon-sagemaker-clarify-processing-job-on-the-unbalanced-dataset","title":"2.5. Run and review the Amazon SageMaker Clarify processing job on the unbalanced dataset","text":"<p>Review the created Amazon SageMaker Clarify processing job and the Cloud Watch logs.</p> <p>Instructions:  - open the link - note that you are in the section Amazon SageMaker -&gt; Processing jobs - check the processing job name - note which other properties of the processing job you can see in the console</p> <pre><code>from IPython.core.display import display, HTML\n\ndisplay(HTML('&lt;b&gt;Review &lt;a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={}#/processing-jobs/{}\"&gt;processing job&lt;/a&gt;&lt;/b&gt;'.format(region, run_unbalanced_bias_processing_job_name)))\n\n</code></pre> <p>Review processing job</p> <p>Instructions:  - open the link - open the log stream with the name, which starts from the processing job name - have a quick look at the log messages</p> <pre><code>from IPython.core.display import display, HTML\n\ndisplay(HTML('&lt;b&gt;Review &lt;a target=\"blank\" href=\"https://console.aws.amazon.com/cloudwatch/home?region={}#logStream:group=/aws/sagemaker/ProcessingJobs;prefix={};streamFilter=typeLogStreamPrefix\"&gt;CloudWatch logs&lt;/a&gt; after about 5 minutes&lt;/b&gt;'.format(region, run_unbalanced_bias_processing_job_name)))\n</code></pre> <p>Review CloudWatch logs after about 5 minutes</p> <pre><code>running_processor = sagemaker.processing.ProcessingJob.from_processing_name(processing_job_name=run_unbalanced_bias_processing_job_name,\n                                                                            sagemaker_session=sess)\n</code></pre>"},{"location":"datascience_on_aws/detect_bias_amazon_sagemaker_clarify/#this-cell-will-take-approximately-5-10-minutes-to-run","title":"This cell will take approximately 5-10 minutes to run.","text":"<pre><code>%%time\n\nrunning_processor.wait(logs=False)\n</code></pre> <pre><code>!CPU times: user 5.23 ms, sys: 292 \u00b5s, total: 5.53 ms\nWall time: 56.6 ms\n</code></pre>"},{"location":"datascience_on_aws/detect_bias_amazon_sagemaker_clarify/#26-analyze-unbalanced-bias-report","title":"2.6. Analyze unbalanced bias report","text":"<p>In this run, you analyzed bias for <code>sentiment</code> relative to the <code>product_category</code> for the unbalanced data. Let's have a look at the bias report.</p> <p>List the files in the output path <code>bias_report_unbalanced_output_path</code>:</p> <pre><code>!aws s3 ls $bias_report_unbalanced_output_path/\n</code></pre> <pre><code>2023-06-09 14:00:41      31732 analysis.json\n2023-06-09 13:54:15        346 analysis_config.json\n2023-06-09 14:00:41    1251091 report.html\n2023-06-09 14:00:41     990884 report.ipynb\n2023-06-09 14:00:41     846666 report.pdf\n</code></pre> <p>Download generated bias report from S3 bucket:</p> <pre><code>!aws s3 cp --recursive $bias_report_unbalanced_output_path ./generated_bias_report/unbalanced/\n</code></pre> <pre><code>download: s3://sagemaker-us-east-1-505802170089/bias/generated_bias_report/unbalanced/analysis_config.json to generated_bias_report/unbalanced/analysis_config.json\ndownload: s3://sagemaker-us-east-1-505802170089/bias/generated_bias_report/unbalanced/analysis.json to generated_bias_report/unbalanced/analysis.json\ndownload: s3://sagemaker-us-east-1-505802170089/bias/generated_bias_report/unbalanced/report.ipynb to generated_bias_report/unbalanced/report.ipynb\ndownload: s3://sagemaker-us-east-1-505802170089/bias/generated_bias_report/unbalanced/report.pdf to generated_bias_report/unbalanced/report.pdf\ndownload: s3://sagemaker-us-east-1-505802170089/bias/generated_bias_report/unbalanced/report.html to generated_bias_report/unbalanced/report.html\n</code></pre> <p>Review the downloaded bias report (in HTML format):</p> <pre><code>from IPython.core.display import display, HTML\n\ndisplay(HTML('&lt;b&gt;Review &lt;a target=\"blank\" href=\"./generated_bias_report/unbalanced/report.html\"&gt;unbalanced bias report&lt;/a&gt;&lt;/b&gt;'))\n</code></pre> <p>Review unbalanced bias report</p> <p>The bias report shows a number of metrics, but here you can focus on just two of them:  - Class Imbalance (CI). Measures the imbalance in the number of members between different facet values. Answers the question, does a <code>product_category</code> have disproportionately more reviews than others? Values of CI will become equal for even distribution between facets. Here, different CI values show the existence of imbalance. - Difference in Positive Proportions in Labels (DPL). Measures the imbalance of positive outcomes between different facet values. Answers the question, does a <code>product_category</code> have disproportionately higher ratings than others? With the range over the interval from -1 to 1, if there is no bias, you want to see this value as close as possible to zero. Here, non-zero values indicate the imbalances.</p> <p></p>"},{"location":"datascience_on_aws/detect_bias_amazon_sagemaker_clarify/#3-balance-the-dataset-by-product_category-and-sentiment","title":"3. Balance the dataset by <code>product_category</code> and <code>sentiment</code>","text":"<p>Let's balance the dataset by <code>product_category</code> and <code>sentiment</code>. Then you can configure and run SageMaker Clarify processing job to analyze the bias of it. Which metrics values do you expect to see in the bias report?</p> <pre><code>df_grouped_by = df.groupby(['product_category', 'sentiment'])\ndf_balanced = df_grouped_by.apply(lambda x: x.sample(df_grouped_by.size().min()).reset_index(drop=True))\n</code></pre> <pre><code>df_balanced\n</code></pre> sentiment review_body product_category product_category sentiment Blouses -1 0 -1 An absolutely gorgeous  but poorly fitting blo... Blouses 1 -1 I just can't get past how different the blouse... Blouses 2 -1 I'll start by saying the fabric and concept ar... Blouses 3 -1 The beadwork is gorgeous  but the sleeves are ... Blouses 4 -1 Loved the fit and colors  but the fabric is ve... Blouses ... ... ... ... ... ... Trend 1 4 1 Never spent this much on a dress so it needs t... Trend 5 1 I love this tunic! it's wool but the same kind... Trend 6 1 This dress us high quality and feels great  ho... Trend 7 1 Besides being my favorite color to wear  this ... Trend 8 1 This dress is just my style. i have been waiti... Trend <p>486 rows \u00d7 3 columns</p> <p>Visualize the distribution of review sentiment in the balanced dataset.</p> <pre><code>import seaborn as sns\n\nsns.countplot(data=df_balanced, x='sentiment', hue='product_category')\n\nplt.legend(loc='upper right',bbox_to_anchor=(1.3, 1.1))\n\n</code></pre> <pre><code>&lt;matplotlib.legend.Legend at 0x7fb42a9217d0&gt;\n</code></pre> <p></p> <p></p>"},{"location":"datascience_on_aws/detect_bias_amazon_sagemaker_clarify/#4-analyze-bias-on-balanced-dataset-with-amazon-sagemaker-clarify","title":"4. Analyze bias on balanced dataset with Amazon SageMaker Clarify","text":"<p>Let's analyze bias in <code>sentiment</code> with respect to the <code>product_category</code> facet on your balanced dataset.</p> <p>Save and upload balanced data to S3 bucket.</p> <pre><code>path_balanced = './womens_clothing_ecommerce_reviews_balanced.csv'\ndf_balanced.to_csv(path_balanced, index=False, header=True)\n\ndata_s3_uri_balanced = sess.upload_data(bucket=bucket, key_prefix='bias/balanced', path=path_balanced)\ndata_s3_uri_balanced\n</code></pre> <pre><code>'s3://sagemaker-us-east-1-505802170089/bias/balanced/womens_clothing_ecommerce_reviews_balanced.csv'\n</code></pre> <p>You can review the uploaded CSV file in the S3 bucket and prefix <code>bias/balanced</code>.</p> <pre><code>from IPython.core.display import display, HTML\n\ndisplay(HTML('&lt;b&gt;Review &lt;a target=\"top\" href=\"https://s3.console.aws.amazon.com/s3/home?region={}#\"&gt;Amazon S3 bucket&lt;/a&gt;&lt;/b&gt;'.format(region)))\n</code></pre> <p>Review Amazon S3 bucket</p> <p></p>"},{"location":"datascience_on_aws/detect_bias_amazon_sagemaker_clarify/#41-configure-a-dataconfig","title":"4.1. Configure a <code>DataConfig</code>","text":""},{"location":"datascience_on_aws/detect_bias_amazon_sagemaker_clarify/#exercise-3","title":"Exercise 3","text":"<p>Configure a <code>DataConfig</code> for Clarify to analyze bias on the balanced dataset.</p> <p>Instructions: Pass the S3 object path containing the balanced dataset, the path to store the output (<code>bias_report_balanced_output_path</code>) and the target column. You can use exercise 1 as an example.</p> <pre><code>from sagemaker import clarify\n\nbias_report_balanced_output_path = 's3://{}/bias/generated_bias_report/balanced'.format(bucket)\n\ndata_config_balanced = clarify.DataConfig(\n    ### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n    s3_data_input_path='s3://sagemaker-us-east-1-505802170089/bias/balanced/womens_clothing_ecommerce_reviews_balanced.csv', # Replace None\n    s3_output_path=bias_report_balanced_output_path, # Replace None\n    label='sentiment', # Replace None\n    ### END SOLUTION - DO NOT delete this comment for grading purposes\n    headers=df_balanced.columns.to_list(),\n    dataset_type='text/csv'\n)\n</code></pre> <p></p>"},{"location":"datascience_on_aws/detect_bias_amazon_sagemaker_clarify/#42-configure-biasconfig","title":"4.2. Configure <code>BiasConfig</code>","text":"<p><code>BiasConfig</code> for the balanced dataset will have the same settings as before.</p> <pre><code>bias_config_balanced = clarify.BiasConfig(\n    label_values_or_threshold=[1], # desired sentiment\n    facet_name='product_category' # sensitive column (facet)\n)\n</code></pre> <p></p>"},{"location":"datascience_on_aws/detect_bias_amazon_sagemaker_clarify/#43-configure-sagemaker-clarify-as-a-processing-job","title":"4.3. Configure SageMaker Clarify as a processing job","text":"<p><code>SageMakerClarifyProcessor</code> object will also have the same parameters.</p> <pre><code>clarify_processor_balanced = clarify.SageMakerClarifyProcessor(role=role,\n                                                      instance_count=1,\n                                                      instance_type='ml.m5.large',\n                                                      sagemaker_session=sess)\n</code></pre> <p></p>"},{"location":"datascience_on_aws/detect_bias_amazon_sagemaker_clarify/#44-run-the-amazon-sagemaker-clarify-processing-job","title":"4.4. Run the Amazon SageMaker Clarify processing job","text":""},{"location":"datascience_on_aws/detect_bias_amazon_sagemaker_clarify/#exercise-4","title":"Exercise 4","text":"<p>Run the configured processing job for the balanced dataset.</p> <p>Instructions: Apply the <code>run_pre_training_bias</code> method to the configured Clarify processor, passing the input/output data, configuration of sensitive groups with the other job setup parameters. You can use exercise 2 as an example.</p> <pre><code>clarify_processor_balanced.run_pre_training_bias(\n    ### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n    data_config=data_config_balanced , # Replace None\n    data_bias_config=bias_config_balanced, # Replace None\n    ### END SOLUTION - DO NOT delete this comment for grading purposes\n    methods=[\"CI\", \"DPL\", \"KL\", \"JS\", \"LP\", \"TVD\", \"KS\"],\n    wait=False,\n    logs=False\n)\n</code></pre> <pre><code>Job Name:  Clarify-Pretraining-Bias-2023-06-09-14-10-36-505\nInputs:  [{'InputName': 'dataset', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-505802170089/bias/balanced/womens_clothing_ecommerce_reviews_balanced.csv', 'LocalPath': '/opt/ml/processing/input/data', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'analysis_config', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-505802170089/bias/generated_bias_report/balanced/analysis_config.json', 'LocalPath': '/opt/ml/processing/input/config', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\nOutputs:  [{'OutputName': 'analysis_result', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-505802170089/bias/generated_bias_report/balanced', 'LocalPath': '/opt/ml/processing/output', 'S3UploadMode': 'EndOfJob'}}]\n</code></pre> <pre><code>run_balanced_bias_processing_job_name = clarify_processor_balanced.latest_job.job_name\nprint(run_balanced_bias_processing_job_name)\n</code></pre> <pre><code>Clarify-Pretraining-Bias-2023-06-09-14-10-36-505\n</code></pre> <p></p>"},{"location":"datascience_on_aws/detect_bias_amazon_sagemaker_clarify/#45-run-and-review-the-clarify-processing-job-on-the-balanced-dataset","title":"4.5. Run and review the Clarify processing job on the balanced dataset","text":"<p>Review the results of the run following the links:</p> <pre><code>from IPython.core.display import display, HTML\n\ndisplay(HTML('&lt;b&gt;Review &lt;a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={}#/processing-jobs/{}\"&gt;processing job&lt;/a&gt;&lt;/b&gt;'.format(region, run_balanced_bias_processing_job_name)))\n\n</code></pre> <p>Review processing job</p> <pre><code>from IPython.core.display import display, HTML\n\ndisplay(HTML('&lt;b&gt;Review &lt;a target=\"blank\" href=\"https://console.aws.amazon.com/cloudwatch/home?region={}#logStream:group=/aws/sagemaker/ProcessingJobs;prefix={};streamFilter=typeLogStreamPrefix\"&gt;CloudWatch logs&lt;/a&gt; after about 5 minutes&lt;/b&gt;'.format(region, run_balanced_bias_processing_job_name)))\n\n</code></pre> <p>Review CloudWatch logs after about 5 minutes</p> <pre><code>running_processor = sagemaker.processing.ProcessingJob.from_processing_name(processing_job_name=run_balanced_bias_processing_job_name,\n                                                                            sagemaker_session=sess)\n</code></pre>"},{"location":"datascience_on_aws/detect_bias_amazon_sagemaker_clarify/#this-cell-will-take-approximately-5-10-minutes-to-run_1","title":"This cell will take approximately 5-10 minutes to run.","text":"<pre><code>%%time\n\nrunning_processor.wait(logs=False)\n</code></pre> <pre><code>!CPU times: user 4.75 ms, sys: 574 \u00b5s, total: 5.32 ms\nWall time: 58.3 ms\n</code></pre>"},{"location":"datascience_on_aws/detect_bias_amazon_sagemaker_clarify/#46-analyze-balanced-bias-report","title":"4.6. Analyze balanced bias report","text":"<p>List the files in the output path <code>bias_report_balanced_output_path</code>:</p> <pre><code>!aws s3 ls $bias_report_balanced_output_path/\n</code></pre> <pre><code>2023-06-09 14:17:10      29889 analysis.json\n2023-06-09 14:10:37        346 analysis_config.json\n2023-06-09 14:17:10    1226587 report.html\n2023-06-09 14:17:10     966380 report.ipynb\n2023-06-09 14:17:10     834280 report.pdf\n</code></pre> <p>Download generated bias report from S3 bucket:</p> <pre><code>!aws s3 cp --recursive $bias_report_balanced_output_path ./generated_bias_report/balanced/\n</code></pre> <pre><code>download: s3://sagemaker-us-east-1-505802170089/bias/generated_bias_report/balanced/analysis_config.json to generated_bias_report/balanced/analysis_config.json\ndownload: s3://sagemaker-us-east-1-505802170089/bias/generated_bias_report/balanced/analysis.json to generated_bias_report/balanced/analysis.json\ndownload: s3://sagemaker-us-east-1-505802170089/bias/generated_bias_report/balanced/report.html to generated_bias_report/balanced/report.html\ndownload: s3://sagemaker-us-east-1-505802170089/bias/generated_bias_report/balanced/report.ipynb to generated_bias_report/balanced/report.ipynb\ndownload: s3://sagemaker-us-east-1-505802170089/bias/generated_bias_report/balanced/report.pdf to generated_bias_report/balanced/report.pdf\n</code></pre> <p>Review the downloaded bias report (in HTML format):</p> <pre><code>from IPython.core.display import display, HTML\n\ndisplay(HTML('&lt;b&gt;Review &lt;a target=\"blank\" href=\"./generated_bias_report/balanced/report.html\"&gt;balanced bias report&lt;/a&gt;&lt;/b&gt;'))\n</code></pre> <p>Review balanced bias report</p> <p>In this run, you analyzed bias for <code>sentiment</code> relative to the <code>product_category</code> for the balanced data.  Note that the Class Imbalance (CI) metric is equal across all product categories for the target label, <code>sentiment</code>. And Difference in Positive Proportions in Labels (DPL) metric values are zero.</p> <p>Upload the notebook into S3 bucket for grading purposes.</p> <p>Note: you may need to click on \"Save\" button before the upload.</p> <pre><code>!aws s3 cp ./C1_W2_Assignment.ipynb s3://$bucket/C1_W2_Assignment_Learner.ipynb\n</code></pre> <pre><code>upload: ./C1_W2_Assignment.ipynb to s3://sagemaker-us-east-1-505802170089/C1_W2_Assignment_Learner.ipynb\n</code></pre> <p>Please go to the main lab window and click on <code>Submit</code> button (see the <code>Finish the lab</code> section of the instructions).</p> <pre><code>\n</code></pre>"},{"location":"datascience_on_aws/sagemaker_autopilot/","title":"Train a model with Amazon SageMaker Autopilot","text":""},{"location":"datascience_on_aws/sagemaker_autopilot/#train-a-model-with-amazon-sagemaker-autopilot","title":"Train a model with Amazon SageMaker Autopilot","text":""},{"location":"datascience_on_aws/sagemaker_autopilot/#introduction","title":"Introduction","text":"<p>In this lab, you will use Amazon Sagemaker Autopilot to train a BERT-based natural language processing (NLP) model. The model will analyze customer feedback and classify the messages into positive (1), neutral (0) and negative (-1) sentiment.</p> <p>Amazon SageMaker Autopilot automatically trains and tunes the best machine learning models for classification or regression, based on your data while allowing to maintain full control and visibility.</p> <p>SageMaker Autopilot will inspect the raw dataset, apply feature processors, pick the best set of algorithms, train and tune multiple models, and then rank the models based on performance - all with just a few clicks.  Autopilot transparently generates a set of Python scripts and notebooks for a complete end-to-end pipeline including data analysis, candidate generation, feature engineering, and model training/tuning.</p> <p>SageMaker Autopilot job consists of the following high-level steps:  * Data analysis where the data is summarized and analyzed to determine which feature engineering techniques, hyper-parameters, and models to explore. * Feature engineering where the data is scrubbed, balanced, combined, and split into train and validation. * Model training and tuning where the top performing features, hyper-parameters, and models are selected and trained.</p> <p></p> <p>These re-usable scripts and notebooks give us full visibility into how the model candidates were created.  Since Autopilot integrates natively with SageMaker Studio, we can visually explore the different models generated by SageMaker Autopilot.</p> <p>SageMaker Autopilot can be used by people without machine learning experience to automatically train a model from a dataset.  Additionally, experienced developers can use Autopilot to train a baseline model from which they can iterate and manually improve.</p> <p>Autopilot is available through the SageMaker Studio UI and AWS Python SDK.  In this notebook, you will use the AWS Python SDK to train a series of text-classification models and deploy the model with the highest accuracy.</p> <p>For more details on Autopilot, have a look at this Amazon Science Publication.</p>"},{"location":"datascience_on_aws/sagemaker_autopilot/#use-case-analyze-customer-sentiment","title":"Use case: analyze customer sentiment","text":"<p>Customer feedback appears across many channels including social media and partner websites.  As a company, you want to capture this valuable product feedback to spot negative trends and improve the situation, if needed. Here you will train a model to classify the feedback messages into positive (1), neutral (0) and negative (-1) sentiment.</p> <p>First, let's install and import required modules.</p> <pre><code># please ignore warning messages during the installation\n!pip install --disable-pip-version-check -q sagemaker==2.35.0\n</code></pre> <pre><code>\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n</code></pre> <pre><code>import boto3\nimport sagemaker\nimport pandas as pd\nimport numpy as np\nimport botocore\nimport time\nimport json\n\nconfig = botocore.config.Config(user_agent_extra='dlai-pds/c1/w3')\n\n# low-level service client of the boto3 session\nsm = boto3.client(service_name='sagemaker', \n                  config=config)\n\nsm_runtime = boto3.client('sagemaker-runtime',\n                          config=config)\n\nsess = sagemaker.Session(sagemaker_client=sm,\n                         sagemaker_runtime_client=sm_runtime)\n\nbucket = sess.default_bucket()\nrole = sagemaker.get_execution_role()\nregion = sess.boto_region_name\n</code></pre>                         Clean data in minutes                     Automatically visualize data, and improve data quality in a few clicks. Learn more Import Data Wrangler widget Remind me later Don't show again <pre><code>import matplotlib.pyplot as plt\n%matplotlib inline\n%config InlineBackend.figure_format='retina'\n</code></pre> <p></p>"},{"location":"datascience_on_aws/sagemaker_autopilot/#1-review-transformed-dataset","title":"1. Review transformed dataset","text":"<p>Let's transform the dataset into a format that Autopilot recognizes.  Specifically, a comma-separated file of <code>label,features</code> as shown here:</p> <pre><code>sentiment,review_body\n-1,\"this is bad\"\n0,\"this is ok\"\n1,\"this is great\"\n...\n</code></pre> <p>Sentiment is one of three classes: negative (-1), neutral (0), or positive (1).  Autopilot requires that the target variable, <code>sentiment</code> is first and the set of features, just <code>review_body</code> in this case, come next.</p> <pre><code>!aws s3 cp 's3://dlai-practical-data-science/data/balanced/womens_clothing_ecommerce_reviews_balanced.csv' ./\n</code></pre> <pre><code>download: s3://dlai-practical-data-science/data/balanced/womens_clothing_ecommerce_reviews_balanced.csv to ./womens_clothing_ecommerce_reviews_balanced.csv\n</code></pre> <pre><code>path = './womens_clothing_ecommerce_reviews_balanced.csv'\n\ndf = pd.read_csv(path, delimiter=',')\ndf.head()\n</code></pre> sentiment review_body product_category 0 -1 This suit did nothing for me. the top has zero... Swim 1 -1 Like other reviewers  i saw this dress on the ... Dresses 2 -1 I wish i had read the reviews before purchasin... Knits 3 -1 I ordered these pants in my usual size (xl) an... Legwear 4 -1 I noticed this top on one of the sales associa... Knits <pre><code>path_autopilot = './womens_clothing_ecommerce_reviews_balanced_for_autopilot.csv'\n\ndf[['sentiment', 'review_body']].to_csv(path_autopilot, \n                                        sep=',', \n                                        index=False)\n</code></pre> <p></p>"},{"location":"datascience_on_aws/sagemaker_autopilot/#2-configure-the-autopilot-job","title":"2. Configure the Autopilot job","text":""},{"location":"datascience_on_aws/sagemaker_autopilot/#21-upload-data-to-s3-bucket","title":"2.1. Upload data to S3 bucket","text":"<pre><code>autopilot_train_s3_uri = sess.upload_data(bucket=bucket, key_prefix='autopilot/data', path=path_autopilot)\nautopilot_train_s3_uri\n</code></pre> <pre><code>'s3://sagemaker-us-east-1-118176282599/autopilot/data/womens_clothing_ecommerce_reviews_balanced_for_autopilot.csv'\n</code></pre> <p>Check the existence of the dataset in this S3 bucket folder:</p> <pre><code>!aws s3 ls $autopilot_train_s3_uri\n</code></pre> <pre><code>2023-06-11 00:14:26    2253749 womens_clothing_ecommerce_reviews_balanced_for_autopilot.csv\n</code></pre> <p></p>"},{"location":"datascience_on_aws/sagemaker_autopilot/#22-s3-output-for-generated-assets","title":"2.2. S3 output for generated assets","text":"<p>Set the S3 output path for the Autopilot outputs. This includes Jupyter notebooks (analysis), Python scripts (feature engineering), and trained models.</p> <pre><code>model_output_s3_uri = 's3://{}/autopilot'.format(bucket)\n\nprint(model_output_s3_uri)\n</code></pre> <pre><code>s3://sagemaker-us-east-1-118176282599/autopilot\n</code></pre> <p></p>"},{"location":"datascience_on_aws/sagemaker_autopilot/#23-configure-the-autopilot-job","title":"2.3. Configure the Autopilot job","text":"<p>Create the Autopilot job name.</p> <pre><code>import time\n\ntimestamp = int(time.time())\n\nauto_ml_job_name = 'automl-dm-{}'.format(timestamp)\n</code></pre> <p>When configuring our Autopilot job, you need to specify the maximum number of candidates, <code>max_candidates</code>, to explore as well as the input/output S3 locations and target column to predict. In this case, you want to predict <code>sentiment</code> from the review text.</p> <p></p>"},{"location":"datascience_on_aws/sagemaker_autopilot/#exercise-1","title":"Exercise 1","text":"<p>Configure the Autopilot job.</p> <p>Instructions: Create an instance of the <code>sagemaker.automl.automl.AutoML</code> estimator class passing the required configuration parameters. Target attribute for predictions here is <code>sentiment</code>.</p> <pre><code>automl = sagemaker.automl.automl.AutoML(\n    target_attribute_name='...', # the name of the target attribute for predictions\n    base_job_name=..., # Autopilot job name\n    output_path=..., # output data path\n    max_candidates=..., # maximum number of candidates\n    sagemaker_session=sess,\n    role=role,\n    max_runtime_per_training_job_in_seconds=1200,\n    total_job_runtime_in_seconds=7200\n)\n</code></pre> <pre><code>max_candidates = 3\n\nautoml = sagemaker.automl.automl.AutoML(\n    ### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n    target_attribute_name='sentiment', # Replace None\n    base_job_name=auto_ml_job_name, # Replace None\n    output_path=model_output_s3_uri, # Replace None\n    ### END SOLUTION - DO NOT delete this comment for grading purposes\n    max_candidates=max_candidates,\n    sagemaker_session=sess,\n    role=role,\n    max_runtime_per_training_job_in_seconds=1200,\n    total_job_runtime_in_seconds=7200\n)\n</code></pre> <p></p>"},{"location":"datascience_on_aws/sagemaker_autopilot/#3-launch-the-autopilot-job","title":"3. Launch the Autopilot job","text":""},{"location":"datascience_on_aws/sagemaker_autopilot/#exercise-2","title":"Exercise 2","text":"<p>Launch the Autopilot job.</p> <p>Instructions: Call <code>fit</code> function of the configured estimator passing the S3 bucket input data path and the Autopilot job name.</p> <pre><code>automl.fit(\n    ..., # input data path\n    job_name=auto_ml_job_name, # Autopilot job name\n    wait=False, \n    logs=False\n)\n</code></pre> <pre><code>automl.fit(\n    ### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n    autopilot_train_s3_uri, # Replace None\n    ### END SOLUTION - DO NOT delete this comment for grading purposes\n    job_name=auto_ml_job_name, \n    wait=False, \n    logs=False\n)\n</code></pre> <p></p>"},{"location":"datascience_on_aws/sagemaker_autopilot/#4-track-autopilot-job-progress","title":"4. Track Autopilot job progress","text":"<p>Once the Autopilot job has been launched, you can track the job progress directly from the notebook using the SDK capabilities.</p> <p></p>"},{"location":"datascience_on_aws/sagemaker_autopilot/#41-autopilot-job-description","title":"4.1. Autopilot job description","text":"<p>Function <code>describe_auto_ml_job</code> of the Amazon SageMaker service returns the information about the AutoML job in dictionary format. You can review the response syntax and response elements in the documentation.</p> <pre><code>job_description_response = automl.describe_auto_ml_job(job_name=auto_ml_job_name)\n</code></pre> <p></p>"},{"location":"datascience_on_aws/sagemaker_autopilot/#42-autopilot-job-status","title":"4.2. Autopilot job status","text":"<p>To track the job progress you can use two response elements: <code>AutoMLJobStatus</code> and <code>AutoMLJobSecondaryStatus</code>, which correspond to the primary (Completed | InProgress | Failed | Stopped | Stopping) and secondary (AnalyzingData | FeatureEngineering | ModelTuning etc.) job states respectively. To see if the AutoML job has started, you can check the existence of the <code>AutoMLJobStatus</code> and <code>AutoMLJobSecondaryStatus</code> elements in the job description response.</p> <p>In this notebook, you will use the following scheme to track the job progress:</p> <pre><code># check if the job is still at certain stage\nwhile [check 'AutoMLJobStatus' and 'AutoMLJobSecondaryStatus'] in job_description_response:\n    # update the job description response\n    job_description_response = automl.describe_auto_ml_job(AutoMLJobName=auto_ml_job_name)\n    # print the message the Autopilot job is in the stage ...\n    print([message])\n    # git a time step to check the status again\n    sleep(15)\nprint(\"Autopilot job complete...\")\n</code></pre> <pre><code>while 'AutoMLJobStatus' not in job_description_response.keys() and 'AutoMLJobSecondaryStatus' not in job_description_response.keys():\n    job_description_response = automl.describe_auto_ml_job(job_name=auto_ml_job_name)\n    print('[INFO] Autopilot job has not yet started. Please wait. ')\n    # function `json.dumps` encodes JSON string for printing.\n    print(json.dumps(job_description_response, indent=4, sort_keys=True, default=str))\n    print('[INFO] Waiting for Autopilot job to start...')\n    sleep(15)\n\nprint('[OK] AutoML job started.')\n</code></pre> <pre><code>[OK] AutoML job started.\n</code></pre> <p></p>"},{"location":"datascience_on_aws/sagemaker_autopilot/#43-review-the-sagemaker-processing-jobs","title":"4.3. Review the SageMaker processing jobs","text":"<p>The Autopilot creates required SageMaker processing jobs during the run:</p> <ul> <li>First processing job (data splitter) checks the data sanity, performs stratified shuffling and splits the data into training and validation. </li> <li>Second processing job (candidate generator) first streams through the data to compute statistics for the dataset. Then, uses these statistics to identify the problem type, and possible types of every column-predictor: numeric, categorical, natural language, etc.</li> </ul> <pre><code>from IPython.core.display import display, HTML\n\ndisplay(HTML('&lt;b&gt;Review &lt;a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={}#/processing-jobs/\"&gt;processing jobs&lt;/a&gt;&lt;/b&gt;'.format(region)))\n\n</code></pre> <p>Review processing jobs</p> <p>You can review the updates on that page during the run of the Autopilot job.</p> <p></p>"},{"location":"datascience_on_aws/sagemaker_autopilot/#44-wait-for-the-data-analysis-step-to-finish","title":"4.4. Wait for the data analysis step to finish","text":"<p>Here you will use the same scheme as above to check the completion of the data analysis step. This step can be identified with the (primary) job status value <code>InProgress</code> and secondary job status values <code>Starting</code> and then <code>AnalyzingData</code>.</p>"},{"location":"datascience_on_aws/sagemaker_autopilot/#this-cell-will-take-approximately-10-minutes-to-run","title":"This cell will take approximately 10 minutes to run.","text":"<pre><code>%%time\n\njob_status = job_description_response['AutoMLJobStatus']\njob_sec_status = job_description_response['AutoMLJobSecondaryStatus']\n\nif job_status not in ('Stopped', 'Failed'):\n    while job_status in ('InProgress') and job_sec_status in ('Starting', 'AnalyzingData'):\n        job_description_response = automl.describe_auto_ml_job(job_name=auto_ml_job_name)\n        job_status = job_description_response['AutoMLJobStatus']\n        job_sec_status = job_description_response['AutoMLJobSecondaryStatus']\n        print(job_status, job_sec_status)\n        time.sleep(15)\n    print('[OK] Data analysis phase completed.\\n')\n\nprint(json.dumps(job_description_response, indent=4, sort_keys=True, default=str))\n</code></pre> <pre><code>InProgress AnalyzingData\nInProgress AnalyzingData\nInProgress AnalyzingData\nInProgress AnalyzingData\nInProgress AnalyzingData\nInProgress AnalyzingData\nInProgress AnalyzingData\nInProgress AnalyzingData\nInProgress AnalyzingData\nInProgress AnalyzingData\nInProgress AnalyzingData\nInProgress AnalyzingData\nInProgress AnalyzingData\nInProgress AnalyzingData\nInProgress AnalyzingData\nInProgress AnalyzingData\nInProgress AnalyzingData\nInProgress AnalyzingData\nInProgress AnalyzingData\nInProgress AnalyzingData\nInProgress AnalyzingData\nInProgress AnalyzingData\nInProgress AnalyzingData\nInProgress AnalyzingData\nInProgress AnalyzingData\nInProgress AnalyzingData\nInProgress AnalyzingData\nInProgress FeatureEngineering\n[OK] Data analysis phase completed.\n\n{\n    \"AutoMLJobArn\": \"arn:aws:sagemaker:us-east-1:118176282599:automl-job/automl-dm-1686442502\",\n    \"AutoMLJobArtifacts\": {\n        \"CandidateDefinitionNotebookLocation\": \"s3://sagemaker-us-east-1-118176282599/autopilot/automl-dm-1686442502/sagemaker-automl-candidates/automl-dm-1686442502-pr-1-e714c26cd8e14eb1aef147dd6164f1e716772/notebooks/SageMakerAutopilotCandidateDefinitionNotebook.ipynb\",\n        \"DataExplorationNotebookLocation\": \"s3://sagemaker-us-east-1-118176282599/autopilot/automl-dm-1686442502/sagemaker-automl-candidates/automl-dm-1686442502-pr-1-e714c26cd8e14eb1aef147dd6164f1e716772/notebooks/SageMakerAutopilotDataExplorationNotebook.ipynb\"\n    },\n    \"AutoMLJobConfig\": {\n        \"CompletionCriteria\": {\n            \"MaxAutoMLJobRuntimeInSeconds\": 7200,\n            \"MaxCandidates\": 3,\n            \"MaxRuntimePerTrainingJobInSeconds\": 1200\n        },\n        \"SecurityConfig\": {\n            \"EnableInterContainerTrafficEncryption\": false\n        }\n    },\n    \"AutoMLJobName\": \"automl-dm-1686442502\",\n    \"AutoMLJobSecondaryStatus\": \"FeatureEngineering\",\n    \"AutoMLJobStatus\": \"InProgress\",\n    \"CreationTime\": \"2023-06-11 00:18:41.002000+00:00\",\n    \"GenerateCandidateDefinitionsOnly\": false,\n    \"InputDataConfig\": [\n        {\n            \"ChannelType\": \"training\",\n            \"ContentType\": \"text/csv;header=present\",\n            \"DataSource\": {\n                \"S3DataSource\": {\n                    \"S3DataType\": \"S3Prefix\",\n                    \"S3Uri\": \"s3://sagemaker-us-east-1-118176282599/autopilot/data/womens_clothing_ecommerce_reviews_balanced_for_autopilot.csv\"\n                }\n            },\n            \"TargetAttributeName\": \"sentiment\"\n        }\n    ],\n    \"LastModifiedTime\": \"2023-06-11 00:27:53.735000+00:00\",\n    \"OutputDataConfig\": {\n        \"S3OutputPath\": \"s3://sagemaker-us-east-1-118176282599/autopilot\"\n    },\n    \"ResolvedAttributes\": {\n        \"AutoMLJobObjective\": {\n            \"MetricName\": \"Accuracy\"\n        },\n        \"CompletionCriteria\": {\n            \"MaxAutoMLJobRuntimeInSeconds\": 7200,\n            \"MaxCandidates\": 3,\n            \"MaxRuntimePerTrainingJobInSeconds\": 1200\n        },\n        \"ProblemType\": \"MulticlassClassification\"\n    },\n    \"ResponseMetadata\": {\n        \"HTTPHeaders\": {\n            \"content-length\": \"1811\",\n            \"content-type\": \"application/x-amz-json-1.1\",\n            \"date\": \"Sun, 11 Jun 2023 00:27:54 GMT\",\n            \"x-amzn-requestid\": \"17ac024c-2b98-4697-a81d-076e4b60e7db\"\n        },\n        \"HTTPStatusCode\": 200,\n        \"RequestId\": \"17ac024c-2b98-4697-a81d-076e4b60e7db\",\n        \"RetryAttempts\": 0\n    },\n    \"RoleArn\": \"arn:aws:iam::118176282599:role/sagemaker-studio-vpc-firewall-us-east-1-sagemaker-execution-role\"\n}\nCPU times: user 140 ms, sys: 14.5 ms, total: 154 ms\nWall time: 7min 4s\n</code></pre> <p>Wait for Autopilot to finish generating the notebooks.</p> <p></p>"},{"location":"datascience_on_aws/sagemaker_autopilot/#45-view-generated-notebooks","title":"4.5. View generated notebooks","text":"<p>Once data analysis is complete, SageMaker AutoPilot generates two notebooks:  * Data exploration * Candidate definition</p> <p>Notebooks are included in the AutoML job artifacts generated during the run. Before checking the existence of the notebooks, you can check if the artifacts have been generated.</p> <p></p>"},{"location":"datascience_on_aws/sagemaker_autopilot/#exercise-3","title":"Exercise 3","text":"<p>Check if the Autopilot job artifacts have been generated.</p> <p>Instructions: Use status check scheme described above. The generation of artifacts can be identified by existence of <code>AutoMLJobArtifacts</code> element in the keys of the job description response.</p> <pre><code>### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n# get the information about the running Autopilot job\njob_description_response =  automl.describe_auto_ml_job(job_name=auto_ml_job_name) # Replace None\n\n# keep in the while loop until the Autopilot job artifacts will be generated\nwhile 'AutoMLJobArtifacts' not in job_description_response: # Replace all None\n    # update the information about the running Autopilot job\n    job_description_response =  automl.describe_auto_ml_job(job_name=auto_ml_job_name) # Replace None\n    ### END SOLUTION - DO NOT delete this comment for grading purposes\n    print('[INFO] Autopilot job has not yet generated the artifacts. Please wait. ')\n    print(json.dumps(job_description_response, indent=4, sort_keys=True, default=str))\n    print('[INFO] Waiting for AutoMLJobArtifacts...')\n    time.sleep(15)\n\nprint('[OK] AutoMLJobArtifacts generated.')\n</code></pre> <pre><code>[OK] AutoMLJobArtifacts generated.\n</code></pre> <p>Wait for Autopilot to make the notebooks available.</p> <p></p>"},{"location":"datascience_on_aws/sagemaker_autopilot/#exercise-4","title":"Exercise 4","text":"<p>Check if the notebooks have been created.</p> <p>Instructions: Use status check scheme described above. Notebooks creation can be identified by existence of <code>DataExplorationNotebookLocation</code> element in the keys of the <code>job_description_response['AutoMLJobArtifacts']</code> dictionary.</p> <pre><code>### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n# get the information about the running Autopilot job\njob_description_response =  automl.describe_auto_ml_job(job_name=auto_ml_job_name) # Replace None\n\n# keep in the while loop until the notebooks will be created\nwhile 'DataExplorationNotebookLocation' not in job_description_response['AutoMLJobArtifacts']: # Replace all None\n    # update the information about the running Autopilot job\n    job_description_response =  automl.describe_auto_ml_job(job_name=auto_ml_job_name) # Replace None\n    ### END SOLUTION - DO NOT delete this comment for grading purposes\n    print('[INFO] Autopilot job has not yet generated the notebooks. Please wait. ')\n    print(json.dumps(job_description_response, indent=4, sort_keys=True, default=str))\n    print('[INFO] Waiting for DataExplorationNotebookLocation...')\n    time.sleep(15)\n\nprint('[OK] DataExplorationNotebookLocation found.')   \n</code></pre> <pre><code>[OK] DataExplorationNotebookLocation found.\n</code></pre> <p>Review the generated resources in S3 directly. Following the link, you can find the notebooks in the folder <code>notebooks</code> and download them by clicking on object <code>Actions</code>/<code>Object actions</code> -&gt; <code>Download as</code>/<code>Download</code>.</p> <pre><code>from IPython.core.display import display, HTML\n\ngenerated_resources = job_description_response['AutoMLJobArtifacts']['DataExplorationNotebookLocation']\ndownload_path = generated_resources.rsplit('/notebooks/SageMakerAutopilotDataExplorationNotebook.ipynb')[0]\njob_id = download_path.rsplit('/', 1)[-1]\n\nif not job_id: \n    print('No AutoMLJobArtifacts found.')\nelse: \n    display(HTML('&lt;b&gt;Review &lt;a target=\"blank\" href=\"https://s3.console.aws.amazon.com/s3/buckets/{}/autopilot/{}/sagemaker-automl-candidates/{}/\"&gt;generated notebooks&lt;/a&gt; in S3 bucket&lt;/b&gt;'.format(bucket, auto_ml_job_name, job_id)))\n</code></pre> <p>Review generated notebooks in S3 bucket</p> <p></p>"},{"location":"datascience_on_aws/sagemaker_autopilot/#5-feature-engineering","title":"5. Feature engineering","text":""},{"location":"datascience_on_aws/sagemaker_autopilot/#exercise-5","title":"Exercise 5","text":"<p>Check the completion of the feature engineering step.</p> <p>Instructions: Use status check scheme described above. Feature engineering step can be identified with the (primary) job status value <code>InProgress</code> and secondary job status value <code>FeatureEngineering</code>.</p>"},{"location":"datascience_on_aws/sagemaker_autopilot/#this-cell-will-take-approximately-10-minutes-to-run_1","title":"This cell will take approximately 10 minutes to run.","text":"<pre><code>%%time\n\njob_description_response = automl.describe_auto_ml_job(job_name=auto_ml_job_name)\njob_status = job_description_response['AutoMLJobStatus']\njob_sec_status = job_description_response['AutoMLJobSecondaryStatus']\nprint(job_status)\nprint(job_sec_status)\nif job_status not in ('Stopped', 'Failed'):\n    ### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n    while job_status == 'InProgress' and job_sec_status == 'FeatureEngineering': # Replace all None\n    ### END SOLUTION - DO NOT delete this comment for grading purposes\n        job_description_response = automl.describe_auto_ml_job(job_name=auto_ml_job_name)\n        job_status = job_description_response['AutoMLJobStatus']\n        job_sec_status = job_description_response['AutoMLJobSecondaryStatus']\n        print(job_status, job_sec_status)\n        time.sleep(5)\n    print('[OK] Feature engineering phase completed.\\n')\n\nprint(json.dumps(job_description_response, indent=4, sort_keys=True, default=str))\n</code></pre> <pre><code>Completed\nCompleted\n[OK] Feature engineering phase completed.\n\n{\n    \"AutoMLJobArn\": \"arn:aws:sagemaker:us-east-1:118176282599:automl-job/automl-dm-1686442502\",\n    \"AutoMLJobArtifacts\": {\n        \"CandidateDefinitionNotebookLocation\": \"s3://sagemaker-us-east-1-118176282599/autopilot/automl-dm-1686442502/sagemaker-automl-candidates/automl-dm-1686442502-pr-1-e714c26cd8e14eb1aef147dd6164f1e716772/notebooks/SageMakerAutopilotCandidateDefinitionNotebook.ipynb\",\n        \"DataExplorationNotebookLocation\": \"s3://sagemaker-us-east-1-118176282599/autopilot/automl-dm-1686442502/sagemaker-automl-candidates/automl-dm-1686442502-pr-1-e714c26cd8e14eb1aef147dd6164f1e716772/notebooks/SageMakerAutopilotDataExplorationNotebook.ipynb\"\n    },\n    \"AutoMLJobConfig\": {\n        \"CompletionCriteria\": {\n            \"MaxAutoMLJobRuntimeInSeconds\": 7200,\n            \"MaxCandidates\": 3,\n            \"MaxRuntimePerTrainingJobInSeconds\": 1200\n        },\n        \"SecurityConfig\": {\n            \"EnableInterContainerTrafficEncryption\": false\n        }\n    },\n    \"AutoMLJobName\": \"automl-dm-1686442502\",\n    \"AutoMLJobSecondaryStatus\": \"Completed\",\n    \"AutoMLJobStatus\": \"Completed\",\n    \"BestCandidate\": {\n        \"CandidateName\": \"automl-dm-1686442502mz14M1LlWIif-003-3edcf70f\",\n        \"CandidateProperties\": {\n            \"CandidateArtifactLocations\": {\n                \"Explainability\": \"s3://sagemaker-us-east-1-118176282599/autopilot/automl-dm-1686442502/documentation/explainability/output\",\n                \"ModelInsights\": \"s3://sagemaker-us-east-1-118176282599/autopilot/automl-dm-1686442502/documentation/model_monitor/output\"\n            },\n            \"CandidateMetrics\": [\n                {\n                    \"MetricName\": \"F1macro\",\n                    \"Set\": \"Validation\",\n                    \"StandardMetricName\": \"F1macro\",\n                    \"Value\": 0.3875199854373932\n                },\n                {\n                    \"MetricName\": \"PrecisionMacro\",\n                    \"Set\": \"Validation\",\n                    \"StandardMetricName\": \"PrecisionMacro\",\n                    \"Value\": 0.38436999917030334\n                },\n                {\n                    \"MetricName\": \"Accuracy\",\n                    \"Set\": \"Validation\",\n                    \"StandardMetricName\": \"Accuracy\",\n                    \"Value\": 0.4448699951171875\n                },\n                {\n                    \"MetricName\": \"BalancedAccuracy\",\n                    \"Set\": \"Validation\",\n                    \"StandardMetricName\": \"BalancedAccuracy\",\n                    \"Value\": 0.4448699951171875\n                },\n                {\n                    \"MetricName\": \"LogLoss\",\n                    \"Set\": \"Validation\",\n                    \"StandardMetricName\": \"LogLoss\",\n                    \"Value\": 1.0707199573516846\n                },\n                {\n                    \"MetricName\": \"RecallMacro\",\n                    \"Set\": \"Validation\",\n                    \"StandardMetricName\": \"RecallMacro\",\n                    \"Value\": 0.4448699951171875\n                }\n            ]\n        },\n        \"CandidateStatus\": \"Completed\",\n        \"CandidateSteps\": [\n            {\n                \"CandidateStepArn\": \"arn:aws:sagemaker:us-east-1:118176282599:processing-job/automl-dm-1686442502-db-1-9f01d69b6f1748ffaa453bf5ffcadbf9bf862\",\n                \"CandidateStepName\": \"automl-dm-1686442502-db-1-9f01d69b6f1748ffaa453bf5ffcadbf9bf862\",\n                \"CandidateStepType\": \"AWS::SageMaker::ProcessingJob\"\n            },\n            {\n                \"CandidateStepArn\": \"arn:aws:sagemaker:us-east-1:118176282599:training-job/automl-dm-1686442502-dpp2-1-751fd38c75ef4d339ff058a3b55b5c15131\",\n                \"CandidateStepName\": \"automl-dm-1686442502-dpp2-1-751fd38c75ef4d339ff058a3b55b5c15131\",\n                \"CandidateStepType\": \"AWS::SageMaker::TrainingJob\"\n            },\n            {\n                \"CandidateStepArn\": \"arn:aws:sagemaker:us-east-1:118176282599:transform-job/automl-dm-1686442502-dpp2-rpb-1-a16890496794430c8e042c497405955\",\n                \"CandidateStepName\": \"automl-dm-1686442502-dpp2-rpb-1-a16890496794430c8e042c497405955\",\n                \"CandidateStepType\": \"AWS::SageMaker::TransformJob\"\n            },\n            {\n                \"CandidateStepArn\": \"arn:aws:sagemaker:us-east-1:118176282599:training-job/automl-dm-1686442502mz14M1LlWIif-003-3edcf70f\",\n                \"CandidateStepName\": \"automl-dm-1686442502mz14M1LlWIif-003-3edcf70f\",\n                \"CandidateStepType\": \"AWS::SageMaker::TrainingJob\"\n            }\n        ],\n        \"CreationTime\": \"2023-06-11 00:37:31+00:00\",\n        \"EndTime\": \"2023-06-11 00:39:08+00:00\",\n        \"FinalAutoMLJobObjectiveMetric\": {\n            \"MetricName\": \"validation:accuracy\",\n            \"StandardMetricName\": \"Accuracy\",\n            \"Value\": 0.4448699951171875\n        },\n        \"InferenceContainers\": [\n            {\n                \"Environment\": {\n                    \"AUTOML_SPARSE_ENCODE_RECORDIO_PROTOBUF\": \"1\",\n                    \"AUTOML_TRANSFORM_MODE\": \"feature-transform\",\n                    \"SAGEMAKER_DEFAULT_INVOCATIONS_ACCEPT\": \"application/x-recordio-protobuf\",\n                    \"SAGEMAKER_PROGRAM\": \"sagemaker_serve\",\n                    \"SAGEMAKER_SUBMIT_DIRECTORY\": \"/opt/ml/model/code\"\n                },\n                \"Image\": \"683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-sklearn-automl:2.5-1-cpu-py3\",\n                \"ModelDataUrl\": \"s3://sagemaker-us-east-1-118176282599/autopilot/automl-dm-1686442502/data-processor-models/automl-dm-1686442502-dpp2-1-751fd38c75ef4d339ff058a3b55b5c15131/output/model.tar.gz\"\n            },\n            {\n                \"Environment\": {\n                    \"MAX_CONTENT_LENGTH\": \"20971520\",\n                    \"SAGEMAKER_DEFAULT_INVOCATIONS_ACCEPT\": \"text/csv\",\n                    \"SAGEMAKER_INFERENCE_OUTPUT\": \"predicted_label\",\n                    \"SAGEMAKER_INFERENCE_SUPPORTED\": \"predicted_label,probability,probabilities\"\n                },\n                \"Image\": \"683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-xgboost:1.3-1-cpu-py3\",\n                \"ModelDataUrl\": \"s3://sagemaker-us-east-1-118176282599/autopilot/automl-dm-1686442502/tuning/automl-dm--dpp2-xgb/automl-dm-1686442502mz14M1LlWIif-003-3edcf70f/output/model.tar.gz\"\n            },\n            {\n                \"Environment\": {\n                    \"AUTOML_TRANSFORM_MODE\": \"inverse-label-transform\",\n                    \"SAGEMAKER_DEFAULT_INVOCATIONS_ACCEPT\": \"text/csv\",\n                    \"SAGEMAKER_INFERENCE_INPUT\": \"predicted_label\",\n                    \"SAGEMAKER_INFERENCE_OUTPUT\": \"predicted_label\",\n                    \"SAGEMAKER_INFERENCE_SUPPORTED\": \"predicted_label,probability,labels,probabilities\",\n                    \"SAGEMAKER_PROGRAM\": \"sagemaker_serve\",\n                    \"SAGEMAKER_SUBMIT_DIRECTORY\": \"/opt/ml/model/code\"\n                },\n                \"Image\": \"683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-sklearn-automl:2.5-1-cpu-py3\",\n                \"ModelDataUrl\": \"s3://sagemaker-us-east-1-118176282599/autopilot/automl-dm-1686442502/data-processor-models/automl-dm-1686442502-dpp2-1-751fd38c75ef4d339ff058a3b55b5c15131/output/model.tar.gz\"\n            }\n        ],\n        \"LastModifiedTime\": \"2023-06-11 00:39:32.778000+00:00\",\n        \"ObjectiveStatus\": \"Succeeded\"\n    },\n    \"CreationTime\": \"2023-06-11 00:18:41.002000+00:00\",\n    \"EndTime\": \"2023-06-11 00:47:50.026000+00:00\",\n    \"GenerateCandidateDefinitionsOnly\": false,\n    \"InputDataConfig\": [\n        {\n            \"ChannelType\": \"training\",\n            \"ContentType\": \"text/csv;header=present\",\n            \"DataSource\": {\n                \"S3DataSource\": {\n                    \"S3DataType\": \"S3Prefix\",\n                    \"S3Uri\": \"s3://sagemaker-us-east-1-118176282599/autopilot/data/womens_clothing_ecommerce_reviews_balanced_for_autopilot.csv\"\n                }\n            },\n            \"TargetAttributeName\": \"sentiment\"\n        }\n    ],\n    \"LastModifiedTime\": \"2023-06-11 00:47:50.063000+00:00\",\n    \"OutputDataConfig\": {\n        \"S3OutputPath\": \"s3://sagemaker-us-east-1-118176282599/autopilot\"\n    },\n    \"ResolvedAttributes\": {\n        \"AutoMLJobObjective\": {\n            \"MetricName\": \"Accuracy\"\n        },\n        \"CompletionCriteria\": {\n            \"MaxAutoMLJobRuntimeInSeconds\": 7200,\n            \"MaxCandidates\": 3,\n            \"MaxRuntimePerTrainingJobInSeconds\": 1200\n        },\n        \"ProblemType\": \"MulticlassClassification\"\n    },\n    \"ResponseMetadata\": {\n        \"HTTPHeaders\": {\n            \"content-length\": \"6021\",\n            \"content-type\": \"application/x-amz-json-1.1\",\n            \"date\": \"Sun, 11 Jun 2023 00:54:39 GMT\",\n            \"x-amzn-requestid\": \"47f5baf0-1c30-41fc-837a-93b3974586b3\"\n        },\n        \"HTTPStatusCode\": 200,\n        \"RequestId\": \"47f5baf0-1c30-41fc-837a-93b3974586b3\",\n        \"RetryAttempts\": 0\n    },\n    \"RoleArn\": \"arn:aws:iam::118176282599:role/sagemaker-studio-vpc-firewall-us-east-1-sagemaker-execution-role\"\n}\nCPU times: user 16.5 ms, sys: 0 ns, total: 16.5 ms\nWall time: 160 ms\n</code></pre>"},{"location":"datascience_on_aws/sagemaker_autopilot/#6-model-training-and-tuning","title":"6. Model training and tuning","text":"<p>When you launched the Autopilot job, you requested that 3 model candidates are generated and compared. Therefore, you should see three (3) SageMaker training jobs below.</p> <pre><code>from IPython.core.display import display, HTML\n\ndisplay(HTML('&lt;b&gt;Review &lt;a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={}#/hyper-tuning-jobs/\"&gt;hyper-parameter tuning jobs&lt;/a&gt;&lt;/b&gt;'.format(region)))\n\n</code></pre> <p>Review hyper-parameter tuning jobs</p> <p></p>"},{"location":"datascience_on_aws/sagemaker_autopilot/#61-wait-for-training-and-tuning","title":"6.1. Wait for training and tuning","text":""},{"location":"datascience_on_aws/sagemaker_autopilot/#exercise-6","title":"Exercise 6","text":"<p>Check the completion of the model tuning step.</p> <p>Instructions: Use status check scheme described above. Model tuning step can be identified with the (primary) job status value <code>InProgress</code> and secondary job status value <code>ModelTuning</code>.</p>"},{"location":"datascience_on_aws/sagemaker_autopilot/#this-cell-will-take-approximately-5-10-minutes-to-run","title":"This cell will take approximately 5-10 minutes to run.","text":"<pre><code>%%time\n\njob_description_response = automl.describe_auto_ml_job(job_name=auto_ml_job_name)\njob_status = job_description_response['AutoMLJobStatus']\njob_sec_status = job_description_response['AutoMLJobSecondaryStatus']\nprint(job_status)\nprint(job_sec_status)\nif job_status not in ('Stopped', 'Failed'):\n    ### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n    while job_status == 'InProgress' and job_sec_status == 'ModelTuning': # Replace all None\n    ### END SOLUTION - DO NOT delete this comment for grading purposes\n        job_description_response = automl.describe_auto_ml_job(job_name=auto_ml_job_name)\n        job_status = job_description_response['AutoMLJobStatus']\n        job_sec_status = job_description_response['AutoMLJobSecondaryStatus']\n        print(job_status, job_sec_status)\n        time.sleep(5)\n    print('[OK] Model tuning phase completed.\\n')\n\nprint(json.dumps(job_description_response, indent=4, sort_keys=True, default=str))\n\n</code></pre> <pre><code>Completed\nCompleted\n[OK] Model tuning phase completed.\n\n{\n    \"AutoMLJobArn\": \"arn:aws:sagemaker:us-east-1:118176282599:automl-job/automl-dm-1686442502\",\n    \"AutoMLJobArtifacts\": {\n        \"CandidateDefinitionNotebookLocation\": \"s3://sagemaker-us-east-1-118176282599/autopilot/automl-dm-1686442502/sagemaker-automl-candidates/automl-dm-1686442502-pr-1-e714c26cd8e14eb1aef147dd6164f1e716772/notebooks/SageMakerAutopilotCandidateDefinitionNotebook.ipynb\",\n        \"DataExplorationNotebookLocation\": \"s3://sagemaker-us-east-1-118176282599/autopilot/automl-dm-1686442502/sagemaker-automl-candidates/automl-dm-1686442502-pr-1-e714c26cd8e14eb1aef147dd6164f1e716772/notebooks/SageMakerAutopilotDataExplorationNotebook.ipynb\"\n    },\n    \"AutoMLJobConfig\": {\n        \"CompletionCriteria\": {\n            \"MaxAutoMLJobRuntimeInSeconds\": 7200,\n            \"MaxCandidates\": 3,\n            \"MaxRuntimePerTrainingJobInSeconds\": 1200\n        },\n        \"SecurityConfig\": {\n            \"EnableInterContainerTrafficEncryption\": false\n        }\n    },\n    \"AutoMLJobName\": \"automl-dm-1686442502\",\n    \"AutoMLJobSecondaryStatus\": \"Completed\",\n    \"AutoMLJobStatus\": \"Completed\",\n    \"BestCandidate\": {\n        \"CandidateName\": \"automl-dm-1686442502mz14M1LlWIif-003-3edcf70f\",\n        \"CandidateProperties\": {\n            \"CandidateArtifactLocations\": {\n                \"Explainability\": \"s3://sagemaker-us-east-1-118176282599/autopilot/automl-dm-1686442502/documentation/explainability/output\",\n                \"ModelInsights\": \"s3://sagemaker-us-east-1-118176282599/autopilot/automl-dm-1686442502/documentation/model_monitor/output\"\n            },\n            \"CandidateMetrics\": [\n                {\n                    \"MetricName\": \"F1macro\",\n                    \"Set\": \"Validation\",\n                    \"StandardMetricName\": \"F1macro\",\n                    \"Value\": 0.3875199854373932\n                },\n                {\n                    \"MetricName\": \"PrecisionMacro\",\n                    \"Set\": \"Validation\",\n                    \"StandardMetricName\": \"PrecisionMacro\",\n                    \"Value\": 0.38436999917030334\n                },\n                {\n                    \"MetricName\": \"Accuracy\",\n                    \"Set\": \"Validation\",\n                    \"StandardMetricName\": \"Accuracy\",\n                    \"Value\": 0.4448699951171875\n                },\n                {\n                    \"MetricName\": \"BalancedAccuracy\",\n                    \"Set\": \"Validation\",\n                    \"StandardMetricName\": \"BalancedAccuracy\",\n                    \"Value\": 0.4448699951171875\n                },\n                {\n                    \"MetricName\": \"LogLoss\",\n                    \"Set\": \"Validation\",\n                    \"StandardMetricName\": \"LogLoss\",\n                    \"Value\": 1.0707199573516846\n                },\n                {\n                    \"MetricName\": \"RecallMacro\",\n                    \"Set\": \"Validation\",\n                    \"StandardMetricName\": \"RecallMacro\",\n                    \"Value\": 0.4448699951171875\n                }\n            ]\n        },\n        \"CandidateStatus\": \"Completed\",\n        \"CandidateSteps\": [\n            {\n                \"CandidateStepArn\": \"arn:aws:sagemaker:us-east-1:118176282599:processing-job/automl-dm-1686442502-db-1-9f01d69b6f1748ffaa453bf5ffcadbf9bf862\",\n                \"CandidateStepName\": \"automl-dm-1686442502-db-1-9f01d69b6f1748ffaa453bf5ffcadbf9bf862\",\n                \"CandidateStepType\": \"AWS::SageMaker::ProcessingJob\"\n            },\n            {\n                \"CandidateStepArn\": \"arn:aws:sagemaker:us-east-1:118176282599:training-job/automl-dm-1686442502-dpp2-1-751fd38c75ef4d339ff058a3b55b5c15131\",\n                \"CandidateStepName\": \"automl-dm-1686442502-dpp2-1-751fd38c75ef4d339ff058a3b55b5c15131\",\n                \"CandidateStepType\": \"AWS::SageMaker::TrainingJob\"\n            },\n            {\n                \"CandidateStepArn\": \"arn:aws:sagemaker:us-east-1:118176282599:transform-job/automl-dm-1686442502-dpp2-rpb-1-a16890496794430c8e042c497405955\",\n                \"CandidateStepName\": \"automl-dm-1686442502-dpp2-rpb-1-a16890496794430c8e042c497405955\",\n                \"CandidateStepType\": \"AWS::SageMaker::TransformJob\"\n            },\n            {\n                \"CandidateStepArn\": \"arn:aws:sagemaker:us-east-1:118176282599:training-job/automl-dm-1686442502mz14M1LlWIif-003-3edcf70f\",\n                \"CandidateStepName\": \"automl-dm-1686442502mz14M1LlWIif-003-3edcf70f\",\n                \"CandidateStepType\": \"AWS::SageMaker::TrainingJob\"\n            }\n        ],\n        \"CreationTime\": \"2023-06-11 00:37:31+00:00\",\n        \"EndTime\": \"2023-06-11 00:39:08+00:00\",\n        \"FinalAutoMLJobObjectiveMetric\": {\n            \"MetricName\": \"validation:accuracy\",\n            \"StandardMetricName\": \"Accuracy\",\n            \"Value\": 0.4448699951171875\n        },\n        \"InferenceContainers\": [\n            {\n                \"Environment\": {\n                    \"AUTOML_SPARSE_ENCODE_RECORDIO_PROTOBUF\": \"1\",\n                    \"AUTOML_TRANSFORM_MODE\": \"feature-transform\",\n                    \"SAGEMAKER_DEFAULT_INVOCATIONS_ACCEPT\": \"application/x-recordio-protobuf\",\n                    \"SAGEMAKER_PROGRAM\": \"sagemaker_serve\",\n                    \"SAGEMAKER_SUBMIT_DIRECTORY\": \"/opt/ml/model/code\"\n                },\n                \"Image\": \"683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-sklearn-automl:2.5-1-cpu-py3\",\n                \"ModelDataUrl\": \"s3://sagemaker-us-east-1-118176282599/autopilot/automl-dm-1686442502/data-processor-models/automl-dm-1686442502-dpp2-1-751fd38c75ef4d339ff058a3b55b5c15131/output/model.tar.gz\"\n            },\n            {\n                \"Environment\": {\n                    \"MAX_CONTENT_LENGTH\": \"20971520\",\n                    \"SAGEMAKER_DEFAULT_INVOCATIONS_ACCEPT\": \"text/csv\",\n                    \"SAGEMAKER_INFERENCE_OUTPUT\": \"predicted_label\",\n                    \"SAGEMAKER_INFERENCE_SUPPORTED\": \"predicted_label,probability,probabilities\"\n                },\n                \"Image\": \"683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-xgboost:1.3-1-cpu-py3\",\n                \"ModelDataUrl\": \"s3://sagemaker-us-east-1-118176282599/autopilot/automl-dm-1686442502/tuning/automl-dm--dpp2-xgb/automl-dm-1686442502mz14M1LlWIif-003-3edcf70f/output/model.tar.gz\"\n            },\n            {\n                \"Environment\": {\n                    \"AUTOML_TRANSFORM_MODE\": \"inverse-label-transform\",\n                    \"SAGEMAKER_DEFAULT_INVOCATIONS_ACCEPT\": \"text/csv\",\n                    \"SAGEMAKER_INFERENCE_INPUT\": \"predicted_label\",\n                    \"SAGEMAKER_INFERENCE_OUTPUT\": \"predicted_label\",\n                    \"SAGEMAKER_INFERENCE_SUPPORTED\": \"predicted_label,probability,labels,probabilities\",\n                    \"SAGEMAKER_PROGRAM\": \"sagemaker_serve\",\n                    \"SAGEMAKER_SUBMIT_DIRECTORY\": \"/opt/ml/model/code\"\n                },\n                \"Image\": \"683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-sklearn-automl:2.5-1-cpu-py3\",\n                \"ModelDataUrl\": \"s3://sagemaker-us-east-1-118176282599/autopilot/automl-dm-1686442502/data-processor-models/automl-dm-1686442502-dpp2-1-751fd38c75ef4d339ff058a3b55b5c15131/output/model.tar.gz\"\n            }\n        ],\n        \"LastModifiedTime\": \"2023-06-11 00:39:32.778000+00:00\",\n        \"ObjectiveStatus\": \"Succeeded\"\n    },\n    \"CreationTime\": \"2023-06-11 00:18:41.002000+00:00\",\n    \"EndTime\": \"2023-06-11 00:47:50.026000+00:00\",\n    \"GenerateCandidateDefinitionsOnly\": false,\n    \"InputDataConfig\": [\n        {\n            \"ChannelType\": \"training\",\n            \"ContentType\": \"text/csv;header=present\",\n            \"DataSource\": {\n                \"S3DataSource\": {\n                    \"S3DataType\": \"S3Prefix\",\n                    \"S3Uri\": \"s3://sagemaker-us-east-1-118176282599/autopilot/data/womens_clothing_ecommerce_reviews_balanced_for_autopilot.csv\"\n                }\n            },\n            \"TargetAttributeName\": \"sentiment\"\n        }\n    ],\n    \"LastModifiedTime\": \"2023-06-11 00:47:50.063000+00:00\",\n    \"OutputDataConfig\": {\n        \"S3OutputPath\": \"s3://sagemaker-us-east-1-118176282599/autopilot\"\n    },\n    \"ResolvedAttributes\": {\n        \"AutoMLJobObjective\": {\n            \"MetricName\": \"Accuracy\"\n        },\n        \"CompletionCriteria\": {\n            \"MaxAutoMLJobRuntimeInSeconds\": 7200,\n            \"MaxCandidates\": 3,\n            \"MaxRuntimePerTrainingJobInSeconds\": 1200\n        },\n        \"ProblemType\": \"MulticlassClassification\"\n    },\n    \"ResponseMetadata\": {\n        \"HTTPHeaders\": {\n            \"content-length\": \"6021\",\n            \"content-type\": \"application/x-amz-json-1.1\",\n            \"date\": \"Sun, 11 Jun 2023 00:55:37 GMT\",\n            \"x-amzn-requestid\": \"13de1f93-4957-485e-886e-2b95e0cea1a3\"\n        },\n        \"HTTPStatusCode\": 200,\n        \"RequestId\": \"13de1f93-4957-485e-886e-2b95e0cea1a3\",\n        \"RetryAttempts\": 0\n    },\n    \"RoleArn\": \"arn:aws:iam::118176282599:role/sagemaker-studio-vpc-firewall-us-east-1-sagemaker-execution-role\"\n}\nCPU times: user 12.4 ms, sys: 3.14 ms, total: 15.5 ms\nWall time: 194 ms\n</code></pre> <p>Please wait until ^^ Autopilot ^^ completes above</p> <p>Finally, you can check the completion of the Autopilot job looking for the <code>Completed</code> job status.</p> <pre><code>%%time\n\nfrom pprint import pprint\n\njob_description_response = automl.describe_auto_ml_job(job_name=auto_ml_job_name)\npprint(job_description_response)\njob_status = job_description_response['AutoMLJobStatus']\njob_sec_status = job_description_response['AutoMLJobSecondaryStatus']\nprint('Job status:  {}'.format(job_status))\nprint('Secondary job status:  {}'.format(job_sec_status))\nif job_status not in ('Stopped', 'Failed'):\n    while job_status not in ('Completed'):\n        job_description_response = automl.describe_auto_ml_job(job_name=auto_ml_job_name)\n        job_status = job_description_response['AutoMLJobStatus']\n        job_sec_status = job_description_response['AutoMLJobSecondaryStatus']\n        print('Job status:  {}'.format(job_status))\n        print('Secondary job status:  {}'.format(job_sec_status))        \n        time.sleep(10)\n    print('[OK] Autopilot job completed.\\n')\nelse:\n    print('Job status: {}'.format(job_status))\n    print('Secondary job status: {}'.format(job_status))\n</code></pre> <pre><code>{'AutoMLJobArn': 'arn:aws:sagemaker:us-east-1:118176282599:automl-job/automl-dm-1686442502',\n 'AutoMLJobArtifacts': {'CandidateDefinitionNotebookLocation': 's3://sagemaker-us-east-1-118176282599/autopilot/automl-dm-1686442502/sagemaker-automl-candidates/automl-dm-1686442502-pr-1-e714c26cd8e14eb1aef147dd6164f1e716772/notebooks/SageMakerAutopilotCandidateDefinitionNotebook.ipynb',\n                        'DataExplorationNotebookLocation': 's3://sagemaker-us-east-1-118176282599/autopilot/automl-dm-1686442502/sagemaker-automl-candidates/automl-dm-1686442502-pr-1-e714c26cd8e14eb1aef147dd6164f1e716772/notebooks/SageMakerAutopilotDataExplorationNotebook.ipynb'},\n 'AutoMLJobConfig': {'CompletionCriteria': {'MaxAutoMLJobRuntimeInSeconds': 7200,\n                                            'MaxCandidates': 3,\n                                            'MaxRuntimePerTrainingJobInSeconds': 1200},\n                     'SecurityConfig': {'EnableInterContainerTrafficEncryption': False}},\n 'AutoMLJobName': 'automl-dm-1686442502',\n 'AutoMLJobSecondaryStatus': 'Completed',\n 'AutoMLJobStatus': 'Completed',\n 'BestCandidate': {'CandidateName': 'automl-dm-1686442502mz14M1LlWIif-003-3edcf70f',\n                   'CandidateProperties': {'CandidateArtifactLocations': {'Explainability': 's3://sagemaker-us-east-1-118176282599/autopilot/automl-dm-1686442502/documentation/explainability/output',\n                                                                          'ModelInsights': 's3://sagemaker-us-east-1-118176282599/autopilot/automl-dm-1686442502/documentation/model_monitor/output'},\n                                           'CandidateMetrics': [{'MetricName': 'F1macro',\n                                                                 'Set': 'Validation',\n                                                                 'StandardMetricName': 'F1macro',\n                                                                 'Value': 0.3875199854373932},\n                                                                {'MetricName': 'PrecisionMacro',\n                                                                 'Set': 'Validation',\n                                                                 'StandardMetricName': 'PrecisionMacro',\n                                                                 'Value': 0.38436999917030334},\n                                                                {'MetricName': 'Accuracy',\n                                                                 'Set': 'Validation',\n                                                                 'StandardMetricName': 'Accuracy',\n                                                                 'Value': 0.4448699951171875},\n                                                                {'MetricName': 'BalancedAccuracy',\n                                                                 'Set': 'Validation',\n                                                                 'StandardMetricName': 'BalancedAccuracy',\n                                                                 'Value': 0.4448699951171875},\n                                                                {'MetricName': 'LogLoss',\n                                                                 'Set': 'Validation',\n                                                                 'StandardMetricName': 'LogLoss',\n                                                                 'Value': 1.0707199573516846},\n                                                                {'MetricName': 'RecallMacro',\n                                                                 'Set': 'Validation',\n                                                                 'StandardMetricName': 'RecallMacro',\n                                                                 'Value': 0.4448699951171875}]},\n                   'CandidateStatus': 'Completed',\n                   'CandidateSteps': [{'CandidateStepArn': 'arn:aws:sagemaker:us-east-1:118176282599:processing-job/automl-dm-1686442502-db-1-9f01d69b6f1748ffaa453bf5ffcadbf9bf862',\n                                       'CandidateStepName': 'automl-dm-1686442502-db-1-9f01d69b6f1748ffaa453bf5ffcadbf9bf862',\n                                       'CandidateStepType': 'AWS::SageMaker::ProcessingJob'},\n                                      {'CandidateStepArn': 'arn:aws:sagemaker:us-east-1:118176282599:training-job/automl-dm-1686442502-dpp2-1-751fd38c75ef4d339ff058a3b55b5c15131',\n                                       'CandidateStepName': 'automl-dm-1686442502-dpp2-1-751fd38c75ef4d339ff058a3b55b5c15131',\n                                       'CandidateStepType': 'AWS::SageMaker::TrainingJob'},\n                                      {'CandidateStepArn': 'arn:aws:sagemaker:us-east-1:118176282599:transform-job/automl-dm-1686442502-dpp2-rpb-1-a16890496794430c8e042c497405955',\n                                       'CandidateStepName': 'automl-dm-1686442502-dpp2-rpb-1-a16890496794430c8e042c497405955',\n                                       'CandidateStepType': 'AWS::SageMaker::TransformJob'},\n                                      {'CandidateStepArn': 'arn:aws:sagemaker:us-east-1:118176282599:training-job/automl-dm-1686442502mz14M1LlWIif-003-3edcf70f',\n                                       'CandidateStepName': 'automl-dm-1686442502mz14M1LlWIif-003-3edcf70f',\n                                       'CandidateStepType': 'AWS::SageMaker::TrainingJob'}],\n                   'CreationTime': datetime.datetime(2023, 6, 11, 0, 37, 31, tzinfo=tzlocal()),\n                   'EndTime': datetime.datetime(2023, 6, 11, 0, 39, 8, tzinfo=tzlocal()),\n                   'FinalAutoMLJobObjectiveMetric': {'MetricName': 'validation:accuracy',\n                                                     'StandardMetricName': 'Accuracy',\n                                                     'Value': 0.4448699951171875},\n                   'InferenceContainers': [{'Environment': {'AUTOML_SPARSE_ENCODE_RECORDIO_PROTOBUF': '1',\n                                                            'AUTOML_TRANSFORM_MODE': 'feature-transform',\n                                                            'SAGEMAKER_DEFAULT_INVOCATIONS_ACCEPT': 'application/x-recordio-protobuf',\n                                                            'SAGEMAKER_PROGRAM': 'sagemaker_serve',\n                                                            'SAGEMAKER_SUBMIT_DIRECTORY': '/opt/ml/model/code'},\n                                            'Image': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-sklearn-automl:2.5-1-cpu-py3',\n                                            'ModelDataUrl': 's3://sagemaker-us-east-1-118176282599/autopilot/automl-dm-1686442502/data-processor-models/automl-dm-1686442502-dpp2-1-751fd38c75ef4d339ff058a3b55b5c15131/output/model.tar.gz'},\n                                           {'Environment': {'MAX_CONTENT_LENGTH': '20971520',\n                                                            'SAGEMAKER_DEFAULT_INVOCATIONS_ACCEPT': 'text/csv',\n                                                            'SAGEMAKER_INFERENCE_OUTPUT': 'predicted_label',\n                                                            'SAGEMAKER_INFERENCE_SUPPORTED': 'predicted_label,probability,probabilities'},\n                                            'Image': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-xgboost:1.3-1-cpu-py3',\n                                            'ModelDataUrl': 's3://sagemaker-us-east-1-118176282599/autopilot/automl-dm-1686442502/tuning/automl-dm--dpp2-xgb/automl-dm-1686442502mz14M1LlWIif-003-3edcf70f/output/model.tar.gz'},\n                                           {'Environment': {'AUTOML_TRANSFORM_MODE': 'inverse-label-transform',\n                                                            'SAGEMAKER_DEFAULT_INVOCATIONS_ACCEPT': 'text/csv',\n                                                            'SAGEMAKER_INFERENCE_INPUT': 'predicted_label',\n                                                            'SAGEMAKER_INFERENCE_OUTPUT': 'predicted_label',\n                                                            'SAGEMAKER_INFERENCE_SUPPORTED': 'predicted_label,probability,labels,probabilities',\n                                                            'SAGEMAKER_PROGRAM': 'sagemaker_serve',\n                                                            'SAGEMAKER_SUBMIT_DIRECTORY': '/opt/ml/model/code'},\n                                            'Image': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-sklearn-automl:2.5-1-cpu-py3',\n                                            'ModelDataUrl': 's3://sagemaker-us-east-1-118176282599/autopilot/automl-dm-1686442502/data-processor-models/automl-dm-1686442502-dpp2-1-751fd38c75ef4d339ff058a3b55b5c15131/output/model.tar.gz'}],\n                   'LastModifiedTime': datetime.datetime(2023, 6, 11, 0, 39, 32, 778000, tzinfo=tzlocal()),\n                   'ObjectiveStatus': 'Succeeded'},\n 'CreationTime': datetime.datetime(2023, 6, 11, 0, 18, 41, 2000, tzinfo=tzlocal()),\n 'EndTime': datetime.datetime(2023, 6, 11, 0, 47, 50, 26000, tzinfo=tzlocal()),\n 'GenerateCandidateDefinitionsOnly': False,\n 'InputDataConfig': [{'ChannelType': 'training',\n                      'ContentType': 'text/csv;header=present',\n                      'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix',\n                                                      'S3Uri': 's3://sagemaker-us-east-1-118176282599/autopilot/data/womens_clothing_ecommerce_reviews_balanced_for_autopilot.csv'}},\n                      'TargetAttributeName': 'sentiment'}],\n 'LastModifiedTime': datetime.datetime(2023, 6, 11, 0, 47, 50, 63000, tzinfo=tzlocal()),\n 'OutputDataConfig': {'S3OutputPath': 's3://sagemaker-us-east-1-118176282599/autopilot'},\n 'ResolvedAttributes': {'AutoMLJobObjective': {'MetricName': 'Accuracy'},\n                        'CompletionCriteria': {'MaxAutoMLJobRuntimeInSeconds': 7200,\n                                               'MaxCandidates': 3,\n                                               'MaxRuntimePerTrainingJobInSeconds': 1200},\n                        'ProblemType': 'MulticlassClassification'},\n 'ResponseMetadata': {'HTTPHeaders': {'content-length': '6021',\n                                      'content-type': 'application/x-amz-json-1.1',\n                                      'date': 'Sun, 11 Jun 2023 00:55:51 GMT',\n                                      'x-amzn-requestid': 'f754c81f-eecc-47dd-ad82-cd1af9bb41e6'},\n                      'HTTPStatusCode': 200,\n                      'RequestId': 'f754c81f-eecc-47dd-ad82-cd1af9bb41e6',\n                      'RetryAttempts': 0},\n 'RoleArn': 'arn:aws:iam::118176282599:role/sagemaker-studio-vpc-firewall-us-east-1-sagemaker-execution-role'}\nJob status:  Completed\nSecondary job status:  Completed\n[OK] Autopilot job completed.\n\nCPU times: user 61.5 ms, sys: 11 ms, total: 72.5 ms\nWall time: 203 ms\n</code></pre> <p>Before moving to the next section make sure the status above indicates <code>Autopilot job completed</code>.</p> <p></p>"},{"location":"datascience_on_aws/sagemaker_autopilot/#62-compare-model-candidates","title":"6.2. Compare model candidates","text":"<p>Once model tuning is complete, you can view all the candidates (pipeline evaluations with different hyperparameter combinations) that were explored by AutoML and sort them by their final performance metric.</p> <p></p>"},{"location":"datascience_on_aws/sagemaker_autopilot/#exercise-7","title":"Exercise 7","text":"<p>List candidates generated by Autopilot sorted by accuracy from highest to lowest.</p> <p>Instructions: Use <code>list_candidates</code> function passing the Autopilot job name <code>auto_ml_job_name</code> with the accuracy field <code>FinalObjectiveMetricValue</code>. It returns the list of candidates with the information about them.</p> <pre><code>candidates = automl.list_candidates(\n    job_name=..., # Autopilot job name\n    sort_by='...' # accuracy field name\n)\n</code></pre> <pre><code>candidates = automl.list_candidates(\n    ### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n    job_name=auto_ml_job_name, # Replace None\n    sort_by='FinalObjectiveMetricValue' # Replace None\n    ### END SOLUTION - DO NOT delete this comment for grading purposes\n)\n</code></pre> <p>You can review the response syntax and response elements of the function <code>list_candidates</code> in the documentation. Now let's put the candidate existence check into the loop:</p> <pre><code>while candidates == []:\n    candidates = automl.list_candidates(job_name=auto_ml_job_name)\n    print('[INFO] Autopilot job is generating the candidates. Please wait.')\n    time.sleep(10)\n\nprint('[OK] Candidates generated.') \n</code></pre> <pre><code>[OK] Candidates generated.\n</code></pre> <p>The information about each of the candidates is in the dictionary with the following keys:</p> <pre><code>print(candidates[0].keys())\n</code></pre> <pre><code>dict_keys(['CandidateName', 'FinalAutoMLJobObjectiveMetric', 'ObjectiveStatus', 'CandidateSteps', 'CandidateStatus', 'InferenceContainers', 'CreationTime', 'EndTime', 'LastModifiedTime', 'CandidateProperties'])\n</code></pre> <p><code>CandidateName</code> contains the candidate name and the <code>FinalAutoMLJobObjectiveMetric</code> element contains the metric information which can be used to identify the best candidate later. Let's check that they were generated.</p> <pre><code>while 'CandidateName' not in candidates[0]:\n    candidates = automl.list_candidates(job_name=auto_ml_job_name)\n    print('[INFO] Autopilot job is generating CandidateName. Please wait. ')\n    sleep(10)\n\nprint('[OK] CandidateName generated.')\n</code></pre> <pre><code>[OK] CandidateName generated.\n</code></pre> <pre><code>while 'FinalAutoMLJobObjectiveMetric' not in candidates[0]:\n    candidates = automl.list_candidates(job_name=auto_ml_job_name)\n    print('[INFO] Autopilot job is generating FinalAutoMLJobObjectiveMetric. Please wait. ')\n    sleep(10)\n\nprint('[OK] FinalAutoMLJobObjectiveMetric generated.')\n</code></pre> <pre><code>[OK] FinalAutoMLJobObjectiveMetric generated.\n</code></pre> <pre><code>print(json.dumps(candidates, indent=4, sort_keys=True, default=str))\n</code></pre> <pre><code>[\n    {\n        \"CandidateName\": \"automl-dm-1686442502mz14M1LlWIif-003-3edcf70f\",\n        \"CandidateProperties\": {\n            \"CandidateArtifactLocations\": {\n                \"Explainability\": \"s3://sagemaker-us-east-1-118176282599/autopilot/automl-dm-1686442502/documentation/explainability/output\",\n                \"ModelInsights\": \"s3://sagemaker-us-east-1-118176282599/autopilot/automl-dm-1686442502/documentation/model_monitor/output\"\n            },\n            \"CandidateMetrics\": [\n                {\n                    \"MetricName\": \"F1macro\",\n                    \"Set\": \"Validation\",\n                    \"StandardMetricName\": \"F1macro\",\n                    \"Value\": 0.3875199854373932\n                },\n                {\n                    \"MetricName\": \"PrecisionMacro\",\n                    \"Set\": \"Validation\",\n                    \"StandardMetricName\": \"PrecisionMacro\",\n                    \"Value\": 0.38436999917030334\n                },\n                {\n                    \"MetricName\": \"Accuracy\",\n                    \"Set\": \"Validation\",\n                    \"StandardMetricName\": \"Accuracy\",\n                    \"Value\": 0.4448699951171875\n                },\n                {\n                    \"MetricName\": \"BalancedAccuracy\",\n                    \"Set\": \"Validation\",\n                    \"StandardMetricName\": \"BalancedAccuracy\",\n                    \"Value\": 0.4448699951171875\n                },\n                {\n                    \"MetricName\": \"LogLoss\",\n                    \"Set\": \"Validation\",\n                    \"StandardMetricName\": \"LogLoss\",\n                    \"Value\": 1.0707199573516846\n                },\n                {\n                    \"MetricName\": \"RecallMacro\",\n                    \"Set\": \"Validation\",\n                    \"StandardMetricName\": \"RecallMacro\",\n                    \"Value\": 0.4448699951171875\n                }\n            ]\n        },\n        \"CandidateStatus\": \"Completed\",\n        \"CandidateSteps\": [\n            {\n                \"CandidateStepArn\": \"arn:aws:sagemaker:us-east-1:118176282599:processing-job/automl-dm-1686442502-db-1-9f01d69b6f1748ffaa453bf5ffcadbf9bf862\",\n                \"CandidateStepName\": \"automl-dm-1686442502-db-1-9f01d69b6f1748ffaa453bf5ffcadbf9bf862\",\n                \"CandidateStepType\": \"AWS::SageMaker::ProcessingJob\"\n            },\n            {\n                \"CandidateStepArn\": \"arn:aws:sagemaker:us-east-1:118176282599:training-job/automl-dm-1686442502-dpp2-1-751fd38c75ef4d339ff058a3b55b5c15131\",\n                \"CandidateStepName\": \"automl-dm-1686442502-dpp2-1-751fd38c75ef4d339ff058a3b55b5c15131\",\n                \"CandidateStepType\": \"AWS::SageMaker::TrainingJob\"\n            },\n            {\n                \"CandidateStepArn\": \"arn:aws:sagemaker:us-east-1:118176282599:transform-job/automl-dm-1686442502-dpp2-rpb-1-a16890496794430c8e042c497405955\",\n                \"CandidateStepName\": \"automl-dm-1686442502-dpp2-rpb-1-a16890496794430c8e042c497405955\",\n                \"CandidateStepType\": \"AWS::SageMaker::TransformJob\"\n            },\n            {\n                \"CandidateStepArn\": \"arn:aws:sagemaker:us-east-1:118176282599:training-job/automl-dm-1686442502mz14M1LlWIif-003-3edcf70f\",\n                \"CandidateStepName\": \"automl-dm-1686442502mz14M1LlWIif-003-3edcf70f\",\n                \"CandidateStepType\": \"AWS::SageMaker::TrainingJob\"\n            }\n        ],\n        \"CreationTime\": \"2023-06-11 00:37:31+00:00\",\n        \"EndTime\": \"2023-06-11 00:39:08+00:00\",\n        \"FinalAutoMLJobObjectiveMetric\": {\n            \"MetricName\": \"validation:accuracy\",\n            \"StandardMetricName\": \"Accuracy\",\n            \"Value\": 0.4448699951171875\n        },\n        \"InferenceContainers\": [\n            {\n                \"Environment\": {\n                    \"AUTOML_SPARSE_ENCODE_RECORDIO_PROTOBUF\": \"1\",\n                    \"AUTOML_TRANSFORM_MODE\": \"feature-transform\",\n                    \"SAGEMAKER_DEFAULT_INVOCATIONS_ACCEPT\": \"application/x-recordio-protobuf\",\n                    \"SAGEMAKER_PROGRAM\": \"sagemaker_serve\",\n                    \"SAGEMAKER_SUBMIT_DIRECTORY\": \"/opt/ml/model/code\"\n                },\n                \"Image\": \"683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-sklearn-automl:2.5-1-cpu-py3\",\n                \"ModelDataUrl\": \"s3://sagemaker-us-east-1-118176282599/autopilot/automl-dm-1686442502/data-processor-models/automl-dm-1686442502-dpp2-1-751fd38c75ef4d339ff058a3b55b5c15131/output/model.tar.gz\"\n            },\n            {\n                \"Environment\": {\n                    \"MAX_CONTENT_LENGTH\": \"20971520\",\n                    \"SAGEMAKER_DEFAULT_INVOCATIONS_ACCEPT\": \"text/csv\",\n                    \"SAGEMAKER_INFERENCE_OUTPUT\": \"predicted_label\",\n                    \"SAGEMAKER_INFERENCE_SUPPORTED\": \"predicted_label,probability,probabilities\"\n                },\n                \"Image\": \"683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-xgboost:1.3-1-cpu-py3\",\n                \"ModelDataUrl\": \"s3://sagemaker-us-east-1-118176282599/autopilot/automl-dm-1686442502/tuning/automl-dm--dpp2-xgb/automl-dm-1686442502mz14M1LlWIif-003-3edcf70f/output/model.tar.gz\"\n            },\n            {\n                \"Environment\": {\n                    \"AUTOML_TRANSFORM_MODE\": \"inverse-label-transform\",\n                    \"SAGEMAKER_DEFAULT_INVOCATIONS_ACCEPT\": \"text/csv\",\n                    \"SAGEMAKER_INFERENCE_INPUT\": \"predicted_label\",\n                    \"SAGEMAKER_INFERENCE_OUTPUT\": \"predicted_label\",\n                    \"SAGEMAKER_INFERENCE_SUPPORTED\": \"predicted_label,probability,labels,probabilities\",\n                    \"SAGEMAKER_PROGRAM\": \"sagemaker_serve\",\n                    \"SAGEMAKER_SUBMIT_DIRECTORY\": \"/opt/ml/model/code\"\n                },\n                \"Image\": \"683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-sklearn-automl:2.5-1-cpu-py3\",\n                \"ModelDataUrl\": \"s3://sagemaker-us-east-1-118176282599/autopilot/automl-dm-1686442502/data-processor-models/automl-dm-1686442502-dpp2-1-751fd38c75ef4d339ff058a3b55b5c15131/output/model.tar.gz\"\n            }\n        ],\n        \"LastModifiedTime\": \"2023-06-11 00:39:32.778000+00:00\",\n        \"ObjectiveStatus\": \"Succeeded\"\n    },\n    {\n        \"CandidateName\": \"automl-dm-1686442502mz14M1LlWIif-001-6af82389\",\n        \"CandidateProperties\": {\n            \"CandidateMetrics\": [\n                {\n                    \"MetricName\": \"F1macro\",\n                    \"Set\": \"Validation\",\n                    \"StandardMetricName\": \"F1macro\",\n                    \"Value\": 0.3560900092124939\n                },\n                {\n                    \"MetricName\": \"PrecisionMacro\",\n                    \"Set\": \"Validation\",\n                    \"StandardMetricName\": \"PrecisionMacro\",\n                    \"Value\": 0.3191100060939789\n                },\n                {\n                    \"MetricName\": \"Accuracy\",\n                    \"Set\": \"Validation\",\n                    \"StandardMetricName\": \"Accuracy\",\n                    \"Value\": 0.4381200075149536\n                },\n                {\n                    \"MetricName\": \"BalancedAccuracy\",\n                    \"Set\": \"Validation\",\n                    \"StandardMetricName\": \"BalancedAccuracy\",\n                    \"Value\": 0.4381200075149536\n                },\n                {\n                    \"MetricName\": \"LogLoss\",\n                    \"Set\": \"Validation\",\n                    \"StandardMetricName\": \"LogLoss\",\n                    \"Value\": 1.0706499814987183\n                },\n                {\n                    \"MetricName\": \"RecallMacro\",\n                    \"Set\": \"Validation\",\n                    \"StandardMetricName\": \"RecallMacro\",\n                    \"Value\": 0.4381200075149536\n                }\n            ]\n        },\n        \"CandidateStatus\": \"Completed\",\n        \"CandidateSteps\": [\n            {\n                \"CandidateStepArn\": \"arn:aws:sagemaker:us-east-1:118176282599:processing-job/automl-dm-1686442502-db-1-9f01d69b6f1748ffaa453bf5ffcadbf9bf862\",\n                \"CandidateStepName\": \"automl-dm-1686442502-db-1-9f01d69b6f1748ffaa453bf5ffcadbf9bf862\",\n                \"CandidateStepType\": \"AWS::SageMaker::ProcessingJob\"\n            },\n            {\n                \"CandidateStepArn\": \"arn:aws:sagemaker:us-east-1:118176282599:training-job/automl-dm-1686442502-dpp0-1-a31705a72fda4381bba79502832ce69c22d\",\n                \"CandidateStepName\": \"automl-dm-1686442502-dpp0-1-a31705a72fda4381bba79502832ce69c22d\",\n                \"CandidateStepType\": \"AWS::SageMaker::TrainingJob\"\n            },\n            {\n                \"CandidateStepArn\": \"arn:aws:sagemaker:us-east-1:118176282599:transform-job/automl-dm-1686442502-dpp0-rpb-1-70d8e54399f946b2aa246d235999a88\",\n                \"CandidateStepName\": \"automl-dm-1686442502-dpp0-rpb-1-70d8e54399f946b2aa246d235999a88\",\n                \"CandidateStepType\": \"AWS::SageMaker::TransformJob\"\n            },\n            {\n                \"CandidateStepArn\": \"arn:aws:sagemaker:us-east-1:118176282599:training-job/automl-dm-1686442502mz14M1LlWIif-001-6af82389\",\n                \"CandidateStepName\": \"automl-dm-1686442502mz14M1LlWIif-001-6af82389\",\n                \"CandidateStepType\": \"AWS::SageMaker::TrainingJob\"\n            }\n        ],\n        \"CreationTime\": \"2023-06-11 00:37:21+00:00\",\n        \"EndTime\": \"2023-06-11 00:38:58+00:00\",\n        \"FinalAutoMLJobObjectiveMetric\": {\n            \"MetricName\": \"validation:accuracy\",\n            \"StandardMetricName\": \"Accuracy\",\n            \"Value\": 0.4381200075149536\n        },\n        \"InferenceContainers\": [\n            {\n                \"Environment\": {\n                    \"AUTOML_SPARSE_ENCODE_RECORDIO_PROTOBUF\": \"1\",\n                    \"AUTOML_TRANSFORM_MODE\": \"feature-transform\",\n                    \"SAGEMAKER_DEFAULT_INVOCATIONS_ACCEPT\": \"application/x-recordio-protobuf\",\n                    \"SAGEMAKER_PROGRAM\": \"sagemaker_serve\",\n                    \"SAGEMAKER_SUBMIT_DIRECTORY\": \"/opt/ml/model/code\"\n                },\n                \"Image\": \"683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-sklearn-automl:2.5-1-cpu-py3\",\n                \"ModelDataUrl\": \"s3://sagemaker-us-east-1-118176282599/autopilot/automl-dm-1686442502/data-processor-models/automl-dm-1686442502-dpp0-1-a31705a72fda4381bba79502832ce69c22d/output/model.tar.gz\"\n            },\n            {\n                \"Environment\": {\n                    \"MAX_CONTENT_LENGTH\": \"20971520\",\n                    \"SAGEMAKER_DEFAULT_INVOCATIONS_ACCEPT\": \"text/csv\",\n                    \"SAGEMAKER_INFERENCE_OUTPUT\": \"predicted_label\",\n                    \"SAGEMAKER_INFERENCE_SUPPORTED\": \"predicted_label,probability,probabilities\"\n                },\n                \"Image\": \"683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-xgboost:1.3-1-cpu-py3\",\n                \"ModelDataUrl\": \"s3://sagemaker-us-east-1-118176282599/autopilot/automl-dm-1686442502/tuning/automl-dm--dpp0-xgb/automl-dm-1686442502mz14M1LlWIif-001-6af82389/output/model.tar.gz\"\n            },\n            {\n                \"Environment\": {\n                    \"AUTOML_TRANSFORM_MODE\": \"inverse-label-transform\",\n                    \"SAGEMAKER_DEFAULT_INVOCATIONS_ACCEPT\": \"text/csv\",\n                    \"SAGEMAKER_INFERENCE_INPUT\": \"predicted_label\",\n                    \"SAGEMAKER_INFERENCE_OUTPUT\": \"predicted_label\",\n                    \"SAGEMAKER_INFERENCE_SUPPORTED\": \"predicted_label,probability,labels,probabilities\",\n                    \"SAGEMAKER_PROGRAM\": \"sagemaker_serve\",\n                    \"SAGEMAKER_SUBMIT_DIRECTORY\": \"/opt/ml/model/code\"\n                },\n                \"Image\": \"683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-sklearn-automl:2.5-1-cpu-py3\",\n                \"ModelDataUrl\": \"s3://sagemaker-us-east-1-118176282599/autopilot/automl-dm-1686442502/data-processor-models/automl-dm-1686442502-dpp0-1-a31705a72fda4381bba79502832ce69c22d/output/model.tar.gz\"\n            }\n        ],\n        \"LastModifiedTime\": \"2023-06-11 00:39:32.702000+00:00\",\n        \"ObjectiveStatus\": \"Succeeded\"\n    },\n    {\n        \"CandidateName\": \"automl-dm-1686442502mz14M1LlWIif-002-abd0be00\",\n        \"CandidateProperties\": {\n            \"CandidateMetrics\": [\n                {\n                    \"MetricName\": \"F1macro\",\n                    \"Set\": \"Validation\",\n                    \"StandardMetricName\": \"F1macro\",\n                    \"Value\": 0.30098000168800354\n                },\n                {\n                    \"MetricName\": \"PrecisionMacro\",\n                    \"Set\": \"Validation\",\n                    \"StandardMetricName\": \"PrecisionMacro\",\n                    \"Value\": 0.2833400070667267\n                },\n                {\n                    \"MetricName\": \"Accuracy\",\n                    \"Set\": \"Validation\",\n                    \"StandardMetricName\": \"Accuracy\",\n                    \"Value\": 0.38874998688697815\n                },\n                {\n                    \"MetricName\": \"BalancedAccuracy\",\n                    \"Set\": \"Validation\",\n                    \"StandardMetricName\": \"BalancedAccuracy\",\n                    \"Value\": 0.38874998688697815\n                },\n                {\n                    \"MetricName\": \"LogLoss\",\n                    \"Set\": \"Validation\",\n                    \"StandardMetricName\": \"LogLoss\",\n                    \"Value\": 1.0960400104522705\n                },\n                {\n                    \"MetricName\": \"RecallMacro\",\n                    \"Set\": \"Validation\",\n                    \"StandardMetricName\": \"RecallMacro\",\n                    \"Value\": 0.38874998688697815\n                }\n            ]\n        },\n        \"CandidateStatus\": \"Completed\",\n        \"CandidateSteps\": [\n            {\n                \"CandidateStepArn\": \"arn:aws:sagemaker:us-east-1:118176282599:processing-job/automl-dm-1686442502-db-1-9f01d69b6f1748ffaa453bf5ffcadbf9bf862\",\n                \"CandidateStepName\": \"automl-dm-1686442502-db-1-9f01d69b6f1748ffaa453bf5ffcadbf9bf862\",\n                \"CandidateStepType\": \"AWS::SageMaker::ProcessingJob\"\n            },\n            {\n                \"CandidateStepArn\": \"arn:aws:sagemaker:us-east-1:118176282599:training-job/automl-dm-1686442502-dpp1-1-58e2e4ed3eb04319a142e43b45951f74669\",\n                \"CandidateStepName\": \"automl-dm-1686442502-dpp1-1-58e2e4ed3eb04319a142e43b45951f74669\",\n                \"CandidateStepType\": \"AWS::SageMaker::TrainingJob\"\n            },\n            {\n                \"CandidateStepArn\": \"arn:aws:sagemaker:us-east-1:118176282599:transform-job/automl-dm-1686442502-dpp1-csv-1-264f7757da5c41d283bf9ae74f1231f\",\n                \"CandidateStepName\": \"automl-dm-1686442502-dpp1-csv-1-264f7757da5c41d283bf9ae74f1231f\",\n                \"CandidateStepType\": \"AWS::SageMaker::TransformJob\"\n            },\n            {\n                \"CandidateStepArn\": \"arn:aws:sagemaker:us-east-1:118176282599:training-job/automl-dm-1686442502mz14M1LlWIif-002-abd0be00\",\n                \"CandidateStepName\": \"automl-dm-1686442502mz14M1LlWIif-002-abd0be00\",\n                \"CandidateStepType\": \"AWS::SageMaker::TrainingJob\"\n            }\n        ],\n        \"CreationTime\": \"2023-06-11 00:37:24+00:00\",\n        \"EndTime\": \"2023-06-11 00:39:21+00:00\",\n        \"FinalAutoMLJobObjectiveMetric\": {\n            \"MetricName\": \"validation:accuracy\",\n            \"StandardMetricName\": \"Accuracy\",\n            \"Value\": 0.38874998688697815\n        },\n        \"InferenceContainers\": [\n            {\n                \"Environment\": {\n                    \"AUTOML_TRANSFORM_MODE\": \"feature-transform\",\n                    \"SAGEMAKER_DEFAULT_INVOCATIONS_ACCEPT\": \"application/x-recordio-protobuf\",\n                    \"SAGEMAKER_PROGRAM\": \"sagemaker_serve\",\n                    \"SAGEMAKER_SUBMIT_DIRECTORY\": \"/opt/ml/model/code\"\n                },\n                \"Image\": \"683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-sklearn-automl:2.5-1-cpu-py3\",\n                \"ModelDataUrl\": \"s3://sagemaker-us-east-1-118176282599/autopilot/automl-dm-1686442502/data-processor-models/automl-dm-1686442502-dpp1-1-58e2e4ed3eb04319a142e43b45951f74669/output/model.tar.gz\"\n            },\n            {\n                \"Environment\": {\n                    \"MAX_CONTENT_LENGTH\": \"20971520\",\n                    \"SAGEMAKER_DEFAULT_INVOCATIONS_ACCEPT\": \"text/csv\",\n                    \"SAGEMAKER_INFERENCE_OUTPUT\": \"predicted_label\",\n                    \"SAGEMAKER_INFERENCE_SUPPORTED\": \"predicted_label,probability,probabilities\"\n                },\n                \"Image\": \"683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-xgboost:1.3-1-cpu-py3\",\n                \"ModelDataUrl\": \"s3://sagemaker-us-east-1-118176282599/autopilot/automl-dm-1686442502/tuning/automl-dm--dpp1-xgb/automl-dm-1686442502mz14M1LlWIif-002-abd0be00/output/model.tar.gz\"\n            },\n            {\n                \"Environment\": {\n                    \"AUTOML_TRANSFORM_MODE\": \"inverse-label-transform\",\n                    \"SAGEMAKER_DEFAULT_INVOCATIONS_ACCEPT\": \"text/csv\",\n                    \"SAGEMAKER_INFERENCE_INPUT\": \"predicted_label\",\n                    \"SAGEMAKER_INFERENCE_OUTPUT\": \"predicted_label\",\n                    \"SAGEMAKER_INFERENCE_SUPPORTED\": \"predicted_label,probability,labels,probabilities\",\n                    \"SAGEMAKER_PROGRAM\": \"sagemaker_serve\",\n                    \"SAGEMAKER_SUBMIT_DIRECTORY\": \"/opt/ml/model/code\"\n                },\n                \"Image\": \"683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-sklearn-automl:2.5-1-cpu-py3\",\n                \"ModelDataUrl\": \"s3://sagemaker-us-east-1-118176282599/autopilot/automl-dm-1686442502/data-processor-models/automl-dm-1686442502-dpp1-1-58e2e4ed3eb04319a142e43b45951f74669/output/model.tar.gz\"\n            }\n        ],\n        \"LastModifiedTime\": \"2023-06-11 00:39:32.702000+00:00\",\n        \"ObjectiveStatus\": \"Succeeded\"\n    }\n]\n</code></pre> <p>You can print the names of the candidates with their metric values:</p> <pre><code>print(\"metric \" + str(candidates[0]['FinalAutoMLJobObjectiveMetric']['MetricName']))\n\nfor index, candidate in enumerate(candidates):\n    print(str(index) + \"  \" \n        + candidate['CandidateName'] + \"  \" \n        + str(candidate['FinalAutoMLJobObjectiveMetric']['Value']))\n</code></pre> <pre><code>metric validation:accuracy\n0  automl-dm-1686442502mz14M1LlWIif-003-3edcf70f  0.4448699951171875\n1  automl-dm-1686442502mz14M1LlWIif-001-6af82389  0.4381200075149536\n2  automl-dm-1686442502mz14M1LlWIif-002-abd0be00  0.38874998688697815\n</code></pre> <p></p>"},{"location":"datascience_on_aws/sagemaker_autopilot/#63-review-best-candidate","title":"6.3. Review best candidate","text":"<p>Now that you have successfully completed the Autopilot job on the dataset and visualized the trials, you can get the information about the best candidate model and review it.</p> <p></p>"},{"location":"datascience_on_aws/sagemaker_autopilot/#exercise-8","title":"Exercise 8","text":"<p>Get the information about the generated best candidate job. </p> <p>Instructions: Use <code>best_candidate</code> function passing the Autopilot job name. This function will give an error if candidates have not been generated.</p> <pre><code>candidates = automl.list_candidates(job_name=auto_ml_job_name)\n\nif candidates != []:\n    best_candidate = automl.best_candidate(\n        ### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n        job_name=auto_ml_job_name # Replace None\n        ### END SOLUTION - DO NOT delete this comment for grading purposes\n    )\n    print(json.dumps(best_candidate, indent=4, sort_keys=True, default=str))\n</code></pre> <pre><code>{\n    \"CandidateName\": \"automl-dm-1686442502mz14M1LlWIif-003-3edcf70f\",\n    \"CandidateProperties\": {\n        \"CandidateArtifactLocations\": {\n            \"Explainability\": \"s3://sagemaker-us-east-1-118176282599/autopilot/automl-dm-1686442502/documentation/explainability/output\",\n            \"ModelInsights\": \"s3://sagemaker-us-east-1-118176282599/autopilot/automl-dm-1686442502/documentation/model_monitor/output\"\n        },\n        \"CandidateMetrics\": [\n            {\n                \"MetricName\": \"F1macro\",\n                \"Set\": \"Validation\",\n                \"StandardMetricName\": \"F1macro\",\n                \"Value\": 0.3875199854373932\n            },\n            {\n                \"MetricName\": \"PrecisionMacro\",\n                \"Set\": \"Validation\",\n                \"StandardMetricName\": \"PrecisionMacro\",\n                \"Value\": 0.38436999917030334\n            },\n            {\n                \"MetricName\": \"Accuracy\",\n                \"Set\": \"Validation\",\n                \"StandardMetricName\": \"Accuracy\",\n                \"Value\": 0.4448699951171875\n            },\n            {\n                \"MetricName\": \"BalancedAccuracy\",\n                \"Set\": \"Validation\",\n                \"StandardMetricName\": \"BalancedAccuracy\",\n                \"Value\": 0.4448699951171875\n            },\n            {\n                \"MetricName\": \"LogLoss\",\n                \"Set\": \"Validation\",\n                \"StandardMetricName\": \"LogLoss\",\n                \"Value\": 1.0707199573516846\n            },\n            {\n                \"MetricName\": \"RecallMacro\",\n                \"Set\": \"Validation\",\n                \"StandardMetricName\": \"RecallMacro\",\n                \"Value\": 0.4448699951171875\n            }\n        ]\n    },\n    \"CandidateStatus\": \"Completed\",\n    \"CandidateSteps\": [\n        {\n            \"CandidateStepArn\": \"arn:aws:sagemaker:us-east-1:118176282599:processing-job/automl-dm-1686442502-db-1-9f01d69b6f1748ffaa453bf5ffcadbf9bf862\",\n            \"CandidateStepName\": \"automl-dm-1686442502-db-1-9f01d69b6f1748ffaa453bf5ffcadbf9bf862\",\n            \"CandidateStepType\": \"AWS::SageMaker::ProcessingJob\"\n        },\n        {\n            \"CandidateStepArn\": \"arn:aws:sagemaker:us-east-1:118176282599:training-job/automl-dm-1686442502-dpp2-1-751fd38c75ef4d339ff058a3b55b5c15131\",\n            \"CandidateStepName\": \"automl-dm-1686442502-dpp2-1-751fd38c75ef4d339ff058a3b55b5c15131\",\n            \"CandidateStepType\": \"AWS::SageMaker::TrainingJob\"\n        },\n        {\n            \"CandidateStepArn\": \"arn:aws:sagemaker:us-east-1:118176282599:transform-job/automl-dm-1686442502-dpp2-rpb-1-a16890496794430c8e042c497405955\",\n            \"CandidateStepName\": \"automl-dm-1686442502-dpp2-rpb-1-a16890496794430c8e042c497405955\",\n            \"CandidateStepType\": \"AWS::SageMaker::TransformJob\"\n        },\n        {\n            \"CandidateStepArn\": \"arn:aws:sagemaker:us-east-1:118176282599:training-job/automl-dm-1686442502mz14M1LlWIif-003-3edcf70f\",\n            \"CandidateStepName\": \"automl-dm-1686442502mz14M1LlWIif-003-3edcf70f\",\n            \"CandidateStepType\": \"AWS::SageMaker::TrainingJob\"\n        }\n    ],\n    \"CreationTime\": \"2023-06-11 00:37:31+00:00\",\n    \"EndTime\": \"2023-06-11 00:39:08+00:00\",\n    \"FinalAutoMLJobObjectiveMetric\": {\n        \"MetricName\": \"validation:accuracy\",\n        \"StandardMetricName\": \"Accuracy\",\n        \"Value\": 0.4448699951171875\n    },\n    \"InferenceContainers\": [\n        {\n            \"Environment\": {\n                \"AUTOML_SPARSE_ENCODE_RECORDIO_PROTOBUF\": \"1\",\n                \"AUTOML_TRANSFORM_MODE\": \"feature-transform\",\n                \"SAGEMAKER_DEFAULT_INVOCATIONS_ACCEPT\": \"application/x-recordio-protobuf\",\n                \"SAGEMAKER_PROGRAM\": \"sagemaker_serve\",\n                \"SAGEMAKER_SUBMIT_DIRECTORY\": \"/opt/ml/model/code\"\n            },\n            \"Image\": \"683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-sklearn-automl:2.5-1-cpu-py3\",\n            \"ModelDataUrl\": \"s3://sagemaker-us-east-1-118176282599/autopilot/automl-dm-1686442502/data-processor-models/automl-dm-1686442502-dpp2-1-751fd38c75ef4d339ff058a3b55b5c15131/output/model.tar.gz\"\n        },\n        {\n            \"Environment\": {\n                \"MAX_CONTENT_LENGTH\": \"20971520\",\n                \"SAGEMAKER_DEFAULT_INVOCATIONS_ACCEPT\": \"text/csv\",\n                \"SAGEMAKER_INFERENCE_OUTPUT\": \"predicted_label\",\n                \"SAGEMAKER_INFERENCE_SUPPORTED\": \"predicted_label,probability,probabilities\"\n            },\n            \"Image\": \"683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-xgboost:1.3-1-cpu-py3\",\n            \"ModelDataUrl\": \"s3://sagemaker-us-east-1-118176282599/autopilot/automl-dm-1686442502/tuning/automl-dm--dpp2-xgb/automl-dm-1686442502mz14M1LlWIif-003-3edcf70f/output/model.tar.gz\"\n        },\n        {\n            \"Environment\": {\n                \"AUTOML_TRANSFORM_MODE\": \"inverse-label-transform\",\n                \"SAGEMAKER_DEFAULT_INVOCATIONS_ACCEPT\": \"text/csv\",\n                \"SAGEMAKER_INFERENCE_INPUT\": \"predicted_label\",\n                \"SAGEMAKER_INFERENCE_OUTPUT\": \"predicted_label\",\n                \"SAGEMAKER_INFERENCE_SUPPORTED\": \"predicted_label,probability,labels,probabilities\",\n                \"SAGEMAKER_PROGRAM\": \"sagemaker_serve\",\n                \"SAGEMAKER_SUBMIT_DIRECTORY\": \"/opt/ml/model/code\"\n            },\n            \"Image\": \"683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-sklearn-automl:2.5-1-cpu-py3\",\n            \"ModelDataUrl\": \"s3://sagemaker-us-east-1-118176282599/autopilot/automl-dm-1686442502/data-processor-models/automl-dm-1686442502-dpp2-1-751fd38c75ef4d339ff058a3b55b5c15131/output/model.tar.gz\"\n        }\n    ],\n    \"LastModifiedTime\": \"2023-06-11 00:39:32.778000+00:00\",\n    \"ObjectiveStatus\": \"Succeeded\"\n}\n</code></pre> <p>Check the existence of the candidate name for the best candidate.</p> <pre><code>while 'CandidateName' not in best_candidate:\n    best_candidate = automl.best_candidate(job_name=auto_ml_job_name)\n    print('[INFO] Autopilot Job is generating BestCandidate CandidateName. Please wait. ')\n    print(json.dumps(best_candidate, indent=4, sort_keys=True, default=str))\n    sleep(10)\n\nprint('[OK] BestCandidate CandidateName generated.')  \n</code></pre> <pre><code>[OK] BestCandidate CandidateName generated.\n</code></pre> <p>Check the existence of the metric value for the best candidate.</p> <pre><code>while 'FinalAutoMLJobObjectiveMetric' not in best_candidate:\n    best_candidate = automl.best_candidate(job_name=auto_ml_job_name)\n    print('[INFO] Autopilot Job is generating BestCandidate FinalAutoMLJobObjectiveMetric. Please wait. ')\n    print(json.dumps(best_candidate, indent=4, sort_keys=True, default=str))\n    sleep(10)\n\nprint('[OK] BestCandidate FinalAutoMLJobObjectiveMetric generated.')  \n</code></pre> <pre><code>[OK] BestCandidate FinalAutoMLJobObjectiveMetric generated.\n</code></pre> <p>Print the information about the best candidate:</p> <pre><code>best_candidate_identifier = best_candidate['CandidateName']\nprint(\"Candidate name: \" + best_candidate_identifier)\nprint(\"Metric name: \" + best_candidate['FinalAutoMLJobObjectiveMetric']['MetricName'])\nprint(\"Metric value: \" + str(best_candidate['FinalAutoMLJobObjectiveMetric']['Value']))\n</code></pre> <pre><code>Candidate name: automl-dm-1686442502mz14M1LlWIif-003-3edcf70f\nMetric name: validation:accuracy\nMetric value: 0.4448699951171875\n</code></pre> <p></p>"},{"location":"datascience_on_aws/sagemaker_autopilot/#7-review-all-output-in-s3-bucket","title":"7. Review all output in S3 bucket","text":"<p>You will see the artifacts generated by Autopilot including the following:</p> <pre><code>data-processor-models/        # \"models\" learned to transform raw data into features \ndocumentation/                # explainability and other documentation about your model\npreprocessed-data/            # data for train and validation\nsagemaker-automl-candidates/  # candidate models which autopilot compares\ntransformed-data/             # candidate-specific data for train and validation\ntuning/                       # candidate-specific tuning results\nvalidations/                  # validation results\n</code></pre> <pre><code>from IPython.core.display import display, HTML\n\ndisplay(\n    HTML(\n        '&lt;b&gt;Review all &lt;a target=\"blank\" href=\"https://s3.console.aws.amazon.com/s3/buckets/{}?region={}&amp;prefix=autopilot/{}/\"&gt;output in S3&lt;/a&gt;&lt;/b&gt;'.format(\n            bucket, region, auto_ml_job_name\n        )\n    )\n)\n</code></pre> <p>Review all output in S3</p> <p></p>"},{"location":"datascience_on_aws/sagemaker_autopilot/#8-deploy-and-test-best-candidate-model","title":"8. Deploy and test best candidate model","text":""},{"location":"datascience_on_aws/sagemaker_autopilot/#81-deploy-best-candidate-model","title":"8.1. Deploy best candidate model","text":"<p>While batch transformations are supported, you will deploy our model as a REST Endpoint in this example.</p> <p>First, you need to customize the inference response. The inference containers generated by SageMaker Autopilot allow you to select the response content for predictions. By default the inference containers are configured to generate the <code>predicted_label</code>. But you can add <code>probability</code> into the list of inference response keys.</p> <pre><code>inference_response_keys = ['predicted_label', 'probability']\n</code></pre> <p>Now you will create a SageMaker endpoint from the best candidate generated by Autopilot. Wait for SageMaker to deploy the endpoint.</p>"},{"location":"datascience_on_aws/sagemaker_autopilot/#this-cell-will-take-approximately-5-10-minutes-to-run_1","title":"This cell will take approximately 5-10 minutes to run.","text":"<pre><code>autopilot_model = automl.deploy(\n    initial_instance_count=1,\n    instance_type='ml.m5.large',\n    candidate=best_candidate,\n    inference_response_keys=inference_response_keys,\n    predictor_cls=sagemaker.predictor.Predictor,\n    serializer=sagemaker.serializers.JSONSerializer(),\n    deserializer=sagemaker.deserializers.JSONDeserializer()\n)\n\nprint('\\nEndpoint name:  {}'.format(autopilot_model.endpoint_name))\n</code></pre> <pre><code>-------!\nEndpoint name:  sagemaker-sklearn-automl-2023-06-11-01-00-20-871\n</code></pre> <p>Please wait until the ^^ endpoint ^^ is deployed. </p> <p>Review the SageMaker endpoint in the AWS console.</p> <pre><code>from IPython.core.display import display, HTML\n\ndisplay(HTML('&lt;b&gt;Review &lt;a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={}#/endpoints/{}\"&gt;SageMaker REST endpoint&lt;/a&gt;&lt;/b&gt;'.format(region, autopilot_model.endpoint_name)))\n</code></pre> <p>Review SageMaker REST endpoint</p> <p></p>"},{"location":"datascience_on_aws/sagemaker_autopilot/#82-test-the-model","title":"8.2. Test the model","text":"<p>Invoke a few predictions for the actual reviews using the deployed endpoint.</p> <pre><code>#sm_runtime = boto3.client('sagemaker-runtime')\n\nreview_list = ['This product is great!',\n               'OK, but not great.',\n               'This is not the right product.']\n\nfor review in review_list:\n\n    # remove commas from the review since we're passing the inputs as a CSV\n    review = review.replace(\",\", \"\")\n\n    response = sm_runtime.invoke_endpoint(\n        EndpointName=autopilot_model.endpoint_name, # endpoint name\n        ContentType='text/csv', # type of input data\n        Accept='text/csv', # type of the inference in the response\n        Body=review # review text\n        )\n\n    response_body=response['Body'].read().decode('utf-8').strip().split(',')\n\n    print('Review: ', review, ' Predicated class: {}'.format(response_body[0]))\n\nprint(\"(-1 = Negative, 0=Neutral, 1=Positive)\")\n</code></pre> <pre><code>Review:  This product is great!  Predicated class: 1\nReview:  OK but not great.  Predicated class: 1\nReview:  This is not the right product.  Predicated class: 1\n(-1 = Negative, 0=Neutral, 1=Positive)\n</code></pre> <p>You used Amazon SageMaker Autopilot to automatically find the best model, hyper-parameters, and feature-engineering scripts for our dataset. Autopilot uses a uniquely-transparent approach to AutoML by generating re-usable Python scripts and notebooks.</p> <p>Upload the notebook into S3 bucket for grading purposes.</p> <p>Note: you may need to click on \"Save\" button before the upload.</p> <pre><code>!aws s3 cp ./C1_W3_Assignment.ipynb s3://$bucket/C1_W3_Assignment_Learner.ipynb\n</code></pre> <p>Please go to the main lab window and click on <code>Submit</code> button (see the <code>Finish the lab</code> section of the instructions).</p> <pre><code>\n</code></pre>"},{"location":"datascience_on_aws/sagemaker_blazing_text_built_in_algos/","title":"Train a text classifier using Amazon SageMaker BlazingText built-in algorithm","text":""},{"location":"datascience_on_aws/sagemaker_blazing_text_built_in_algos/#train-a-text-classifier-using-amazon-sagemaker-blazingtext-built-in-algorithm","title":"Train a text classifier using Amazon SageMaker BlazingText built-in algorithm","text":""},{"location":"datascience_on_aws/sagemaker_blazing_text_built_in_algos/#introduction","title":"Introduction","text":"<p>In this lab you will use SageMaker BlazingText built-in algorithm to predict the sentiment for each customer review. BlazingText is a variant of FastText which is based on word2vec. For more information on BlazingText, see the documentation here:  https://docs.aws.amazon.com/sagemaker/latest/dg/blazingtext.html</p> <p>Let's install and import required modules.</p> <pre><code># please ignore warning messages during the installation\n!pip install --disable-pip-version-check -q sagemaker==2.35.0\n!pip install --disable-pip-version-check -q nltk==3.5\n</code></pre> <pre><code>shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\nsh: 0: getcwd() failed: No such file or directory\nThe folder you are executing pip from can no longer be found.\nshell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\nsh: 0: getcwd() failed: No such file or directory\nThe folder you are executing pip from can no longer be found.\n</code></pre> <pre><code>import boto3\nimport sagemaker\nimport pandas as pd\nimport numpy as np\nimport botocore\n\nconfig = botocore.config.Config(user_agent_extra='dlai-pds/c1/w4')\n\n# low-level service client of the boto3 session\nsm = boto3.client(service_name='sagemaker', \n                  config=config)\n\nsm_runtime = boto3.client('sagemaker-runtime',\n                          config=config)\n\nsess = sagemaker.Session(sagemaker_client=sm,\n                         sagemaker_runtime_client=sm_runtime)\n\nbucket = sess.default_bucket()\nrole = sagemaker.get_execution_role()\nregion = sess.boto_region_name\n</code></pre>                         Clean data in minutes                     Automatically visualize data, and improve data quality in a few clicks. Learn more Import Data Wrangler widget Remind me later Don't show again <pre><code>import matplotlib.pyplot as plt\n%matplotlib inline\n%config InlineBackend.figure_format='retina'\n</code></pre> <p></p>"},{"location":"datascience_on_aws/sagemaker_blazing_text_built_in_algos/#1-prepare-dataset","title":"1. Prepare dataset","text":"<p>Let's adapt the dataset into a format that BlazingText understands. The BlazingText format is as follows:</p> <pre><code>__label__&lt;label&gt; \"&lt;features&gt;\"\n</code></pre> <p>Here are some examples:</p> <pre><code>__label__-1 \"this is bad\"\n__label__0 \"this is ok\"\n__label__1 \"this is great\"\n</code></pre> <p>Sentiment is one of three classes: negative (-1), neutral (0), or positive (1).  BlazingText requires that <code>__label__</code> is prepended to each sentiment value.</p> <p>You will tokenize the <code>review_body</code> with the Natural Language Toolkit (<code>nltk</code>) for the model training. <code>nltk</code> documentation can be found here. You will also use <code>nltk</code> later in this lab to tokenize reviews to use as inputs to the deployed model.</p> <p></p>"},{"location":"datascience_on_aws/sagemaker_blazing_text_built_in_algos/#11-load-the-dataset","title":"1.1. Load the dataset","text":"<p>Upload the dataset into the Pandas dataframe:</p> <pre><code>!aws s3 cp 's3://dlai-practical-data-science/data/balanced/womens_clothing_ecommerce_reviews_balanced.csv' ./\n</code></pre> <pre><code>download: s3://dlai-practical-data-science/data/balanced/womens_clothing_ecommerce_reviews_balanced.csv to ./womens_clothing_ecommerce_reviews_balanced.csv\n</code></pre> <pre><code>path = './womens_clothing_ecommerce_reviews_balanced.csv'\n\ndf = pd.read_csv(path, delimiter=',')\ndf.head()\n</code></pre> sentiment review_body product_category 0 -1 This suit did nothing for me. the top has zero... Swim 1 -1 Like other reviewers  i saw this dress on the ... Dresses 2 -1 I wish i had read the reviews before purchasin... Knits 3 -1 I ordered these pants in my usual size (xl) an... Legwear 4 -1 I noticed this top on one of the sales associa... Knits <p></p>"},{"location":"datascience_on_aws/sagemaker_blazing_text_built_in_algos/#12-transform-the-dataset","title":"1.2. Transform the dataset","text":"<p>Now you will prepend <code>__label__</code> to each sentiment value and tokenize the review body using <code>nltk</code> module. Let's import the module and download the tokenizer:</p> <pre><code>import nltk\nnltk.download('punkt')\n</code></pre> <pre><code>[nltk_data] Downloading package punkt to /root/nltk_data...\n[nltk_data]   Unzipping tokenizers/punkt.zip.\n\n\n\n\n\nTrue\n</code></pre> <p>To split a sentence into tokens you can use <code>word_tokenize</code> method. It will separate words, punctuation, and apply some stemming. Have a look at the example:</p> <pre><code>sentence = \"I'm not a fan of this product!\"\n\ntokens = nltk.word_tokenize(sentence)\nprint(tokens)\n</code></pre> <pre><code>['I', \"'m\", 'not', 'a', 'fan', 'of', 'this', 'product', '!']\n</code></pre> <p>The output of word tokenization can be converted into a string separated by spaces and saved in the dataframe. The transformed sentences are prepared then for better text understending by the model. </p> <p>Let's define a <code>prepare_data</code> function which you will apply later to transform both training and validation datasets. </p> <p></p>"},{"location":"datascience_on_aws/sagemaker_blazing_text_built_in_algos/#exercise-1","title":"Exercise 1","text":"<p>Apply the tokenizer to each of the reviews in the <code>review_body</code> column of the dataframe <code>df</code>.</p> <pre><code>def tokenize(review):\n    # delete commas and quotation marks, apply tokenization and join back into a string separating by spaces\n    return ' '.join([str(token) for token in nltk.word_tokenize(str(review).replace(',', '').replace('\"', '').lower())])\n\ndef prepare_data(df):\n    df['sentiment'] = df['sentiment'].map(lambda sentiment : '__label__{}'.format(str(sentiment).replace('__label__', '')))\n    ### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n    df['review_body'] = df['review_body'].map(lambda review : tokenize(review)) # Replace all None\n    ### END SOLUTION - DO NOT delete this comment for grading purposes\n    return df\n</code></pre> <p>Test the prepared function and examine the result.</p> <pre><code># create a sample dataframe\ndf_example = pd.DataFrame({\n    'sentiment':[-1, 0, 1], \n    'review_body':[\n        \"I don't like this product!\", \n        \"this product is ok\", \n        \"I do like this product!\"]\n})\n\n# test the prepare_data function\nprint(prepare_data(df_example))\n\n# Expected output:\n#      sentiment                   review_body\n# 0  __label__-1  i do n't like this product !\n# 1   __label__0            this product is ok\n# 2   __label__1      i do like this product !\n</code></pre> <pre><code>     sentiment                   review_body\n0  __label__-1  i do n't like this product !\n1   __label__0            this product is ok\n2   __label__1      i do like this product !\n</code></pre> <p>Apply the <code>prepare_data</code> function to the dataset. </p> <pre><code>df_blazingtext = df[['sentiment', 'review_body']].reset_index(drop=True)\ndf_blazingtext = prepare_data(df_blazingtext)\ndf_blazingtext.head()\n</code></pre> sentiment review_body 0 __label__-1 this suit did nothing for me . the top has zer... 1 __label__-1 like other reviewers i saw this dress on the c... 2 __label__-1 i wish i had read the reviews before purchasin... 3 __label__-1 i ordered these pants in my usual size ( xl ) ... 4 __label__-1 i noticed this top on one of the sales associa... <p></p>"},{"location":"datascience_on_aws/sagemaker_blazing_text_built_in_algos/#13-split-the-dataset-into-train-and-validation-sets","title":"1.3. Split the dataset into train and validation sets","text":"<p>Split and visualize a pie chart of the train (90%) and validation (10%) sets. You can do the split using the <code>sklearn</code> model function.</p> <pre><code>from sklearn.model_selection import train_test_split\n\n# Split all data into 90% train and 10% holdout\ndf_train, df_validation = train_test_split(df_blazingtext, \n                                           test_size=0.10,\n                                           stratify=df_blazingtext['sentiment'])\n\nlabels = ['train', 'validation']\nsizes = [len(df_train.index), len(df_validation.index)]\nexplode = (0.1, 0)  \n\nfig1, ax1 = plt.subplots()\n\nax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%', startangle=90)\n\n# Equal aspect ratio ensures that pie is drawn as a circle.\nax1.axis('equal')  \n\nplt.show()\nprint(len(df_train))\n</code></pre> <p></p> <pre><code>6399\n</code></pre> <p>Save the results as CSV files.</p> <pre><code>blazingtext_train_path = './train.csv'\ndf_train[['sentiment', 'review_body']].to_csv(blazingtext_train_path, index=False, header=False, sep=' ')\n</code></pre> <pre><code>blazingtext_validation_path = './validation.csv'\ndf_validation[['sentiment', 'review_body']].to_csv(blazingtext_validation_path, index=False, header=False, sep=' ')\n</code></pre> <p></p>"},{"location":"datascience_on_aws/sagemaker_blazing_text_built_in_algos/#14-upload-the-train-and-validation-datasets-to-s3-bucket","title":"1.4. Upload the <code>train</code> and <code>validation</code> datasets to S3 bucket","text":"<p>You will use these to train and validate your model. Let's save them to S3 bucket.</p> <pre><code>train_s3_uri = sess.upload_data(bucket=bucket, key_prefix='blazingtext/data', path=blazingtext_train_path)\nvalidation_s3_uri = sess.upload_data(bucket=bucket, key_prefix='blazingtext/data', path=blazingtext_validation_path)\n</code></pre> <p></p>"},{"location":"datascience_on_aws/sagemaker_blazing_text_built_in_algos/#2-train-the-model","title":"2. Train the model","text":"<p>Setup the BlazingText estimator. For more information on Estimators, see the SageMaker Python SDK documentation here: https://sagemaker.readthedocs.io/.</p> <p></p>"},{"location":"datascience_on_aws/sagemaker_blazing_text_built_in_algos/#exercise-2","title":"Exercise 2","text":"<p>Setup the container image to use for training with the BlazingText algorithm.</p> <p>Instructions: Use the <code>sagemaker.image_uris.retrieve</code> function with the <code>blazingtext</code> algorithm. </p> <pre><code>image_uri = sagemaker.image_uris.retrieve(\n    region=region,\n    framework='...' # the name of framework or algorithm\n)\n</code></pre> <pre><code>image_uri = sagemaker.image_uris.retrieve(\n    region=region,\n    ### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n    framework='blazingtext' # Replace None\n    ### END SOLUTION - DO NOT delete this comment for grading purposes\n)\n</code></pre> <p></p>"},{"location":"datascience_on_aws/sagemaker_blazing_text_built_in_algos/#exercise-3","title":"Exercise 3","text":"<p>Create an estimator instance passing the container image and other instance parameters.</p> <p>Instructions: Pass the container image prepared above into the <code>sagemaker.estimator.Estimator</code> function.</p> <p>Note: For the purposes of this lab, you will use a relatively small instance type. Please refer to this link for additional instance types that may work for your use case outside of this lab.</p> <pre><code>estimator = sagemaker.estimator.Estimator(\n    ### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n    image_uri=image_uri, # Replace None\n    ### END SOLUTION - DO NOT delete this comment for grading purposes\n    role=role, \n    instance_count=1, \n    instance_type='ml.m5.large',\n    volume_size=30,\n    max_run=7200,\n    sagemaker_session=sess\n)\n</code></pre> <p>Configure the hyper-parameters for BlazingText. You are using BlazingText for a supervised classification task. For more information on the hyper-parameters, see the documentation here:  https://docs.aws.amazon.com/sagemaker/latest/dg/blazingtext-tuning.html</p> <p>The hyperparameters that have the greatest impact on word2vec objective metrics are: <code>learning_rate</code> and <code>vector_dim</code>.</p> <pre><code>estimator.set_hyperparameters(mode='supervised',   # supervised (text classification)\n                              epochs=10,           # number of complete passes through the dataset: 5 - 15\n                              learning_rate=0.01,  # step size for the  numerical optimizer: 0.005 - 0.01\n                              min_count=2,         # discard words that appear less than this number: 0 - 100                              \n                              vector_dim=300,      # number of dimensions in vector space: 32-300\n                              word_ngrams=3)       # number of words in a word n-gram: 1 - 3\n</code></pre> <p>To call the <code>fit</code> method for the created estimator instance you need to setup the input data channels. This can be organized as a dictionary</p> <pre><code>data_channels = {\n    'train': ..., # training data\n    'validation': ... # validation data\n}\n</code></pre> <p>where training and validation data are the Amazon SageMaker channels for S3 input data sources.</p> <p></p>"},{"location":"datascience_on_aws/sagemaker_blazing_text_built_in_algos/#exercise-4","title":"Exercise 4","text":"<p>Create a train data channel.</p> <p>Instructions: Pass the S3 input path for training data into the <code>sagemaker.inputs.TrainingInput</code> function.</p> <pre><code>train_data = sagemaker.inputs.TrainingInput(\n    ### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n    train_s3_uri, # Replace None\n    ### END SOLUTION - DO NOT delete this comment for grading purposes\n    distribution='FullyReplicated', \n    content_type='text/plain', \n    s3_data_type='S3Prefix'\n)\n</code></pre> <p></p>"},{"location":"datascience_on_aws/sagemaker_blazing_text_built_in_algos/#exercise-5","title":"Exercise 5","text":"<p>Create a validation data channel.</p> <p>Instructions: Pass the S3 input path for validation data into the <code>sagemaker.inputs.TrainingInput</code> function.</p> <pre><code>validation_data = sagemaker.inputs.TrainingInput(\n    ### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n    validation_s3_uri, # Replace None\n    ### END SOLUTION - DO NOT delete this comment for grading purposes\n    distribution='FullyReplicated', \n    content_type='text/plain', \n    s3_data_type='S3Prefix'\n)\n</code></pre> <p></p>"},{"location":"datascience_on_aws/sagemaker_blazing_text_built_in_algos/#exercise-6","title":"Exercise 6","text":"<p>Organize the data channels defined above as a dictionary.</p> <pre><code>data_channels = {\n    ### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n    'train': train_data, # Replace None\n    'validation': validation_data # Replace None\n    ### END SOLUTION - DO NOT delete this comment for grading purposes\n}\n</code></pre> <p></p>"},{"location":"datascience_on_aws/sagemaker_blazing_text_built_in_algos/#exercise-7","title":"Exercise 7","text":"<p>Start fitting the model to the dataset.</p> <p>Instructions: Call the <code>fit</code> method of the estimator passing the configured train and validation inputs (data channels).</p> <pre><code>estimator.fit(\n    inputs=..., # train and validation input\n    wait=False # do not wait for the job to complete before continuing\n)\n</code></pre> <pre><code>estimator.fit(\n    ### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n    inputs=data_channels, # Replace None\n    ### END SOLUTION - DO NOT delete this comment for grading purposes\n    wait=False\n)\n\ntraining_job_name = estimator.latest_training_job.name\nprint('Training Job Name:  {}'.format(training_job_name))\n</code></pre> <pre><code>INFO:sagemaker:Creating training-job with name: blazingtext-2023-06-11-02-42-40-507\n\n\nTraining Job Name:  blazingtext-2023-06-11-02-42-40-507\n</code></pre> <p>Review the training job in the console.</p> <p>Instructions:  - open the link - notice that you are in the section <code>Amazon SageMaker</code> -&gt; <code>Training jobs</code> - check the name of the training job, its status and other available information</p> <pre><code>from IPython.core.display import display, HTML\n\ndisplay(HTML('&lt;b&gt;Review &lt;a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={}#/jobs/{}\"&gt;Training job&lt;/a&gt;&lt;/b&gt;'.format(region, training_job_name)))\n</code></pre> <p>Review Training job</p> <p>Review the Cloud Watch logs (after about 5 minutes).</p> <p>Instructions:  - open the link - open the log stream with the name, which starts from the training job name - have a quick look at the log messages</p> <pre><code>from IPython.core.display import display, HTML\n\ndisplay(HTML('&lt;b&gt;Review &lt;a target=\"blank\" href=\"https://console.aws.amazon.com/cloudwatch/home?region={}#logStream:group=/aws/sagemaker/TrainingJobs;prefix={};streamFilter=typeLogStreamPrefix\"&gt;CloudWatch logs&lt;/a&gt; (after about 5 minutes)&lt;/b&gt;'.format(region, training_job_name)))\n</code></pre> <p>Review CloudWatch logs (after about 5 minutes)</p> <p>Wait for the training job to complete.</p>"},{"location":"datascience_on_aws/sagemaker_blazing_text_built_in_algos/#this-cell-will-take-approximately-5-10-minutes-to-run","title":"This cell will take approximately 5-10 minutes to run.","text":"<pre><code>%%time\n\nestimator.latest_training_job.wait(logs=False)\n</code></pre> <pre><code>2023-06-11 02:42:55 Starting - Preparing the instances for training...\n2023-06-11 02:43:52 Downloading - Downloading input data.......\n2023-06-11 02:44:32 Training - Downloading the training image..\n2023-06-11 02:44:48 Training - Training image download completed. Training in progress.......\n2023-06-11 02:45:23 Uploading - Uploading generated training model..............................................................\n2023-06-11 02:50:44 Completed - Training job completed\nCPU times: user 362 ms, sys: 61.2 ms, total: 423 ms\nWall time: 7min 16s\n</code></pre> <p>Review the train and validation accuracy.</p> <p>Ignore any warnings.</p> <pre><code>estimator.training_job_analytics.dataframe()\n</code></pre> <pre><code>WARNING:sagemaker.analytics:Warning: No metrics called train:mean_rho found\n</code></pre> timestamp metric_name value 0 0.0 train:accuracy 0.5407 1 0.0 validation:accuracy 0.5246 <p>Review the trained model in the S3 bucket.</p> <p>Instructions:  - open the link - notice that you are in the section <code>Amazon S3</code> -&gt; <code>[bucket name]</code> -&gt; <code>[training job name]</code> (Example: <code>Amazon S3</code> -&gt; <code>sagemaker-us-east-1-82XXXXXXXXXXX</code> -&gt; <code>blazingtext-20XX-XX-XX-XX-XX-XX-XXX</code>) - check the existence of the <code>model.tar.gz</code> file in the <code>output</code> folder</p> <pre><code>from IPython.core.display import display, HTML\n\ndisplay(HTML('&lt;b&gt;Review &lt;a target=\"blank\" href=\"https://s3.console.aws.amazon.com/s3/buckets/{}/{}/output/?region={}&amp;tab=overview\"&gt;Trained model&lt;/a&gt; in S3&lt;/b&gt;'.format(bucket, training_job_name, region)))\n\n</code></pre> <p>Review Trained model in S3</p> <p></p>"},{"location":"datascience_on_aws/sagemaker_blazing_text_built_in_algos/#3-deploy-the-model","title":"3. Deploy the model","text":"<p>Now deploy the trained model as an Endpoint.</p>"},{"location":"datascience_on_aws/sagemaker_blazing_text_built_in_algos/#this-cell-will-take-approximately-5-10-minutes-to-run_1","title":"This cell will take approximately 5-10 minutes to run.","text":"<pre><code>%%time\n\ntext_classifier = estimator.deploy(initial_instance_count=1,\n                                   instance_type='ml.m5.large',\n                                   serializer=sagemaker.serializers.JSONSerializer(),\n                                   deserializer=sagemaker.deserializers.JSONDeserializer())\n\nprint()\nprint('Endpoint name:  {}'.format(text_classifier.endpoint_name))\n</code></pre> <pre><code>INFO:sagemaker:Creating model with name: blazingtext-2023-06-11-02-52-59-769\nINFO:sagemaker:Creating endpoint-config with name blazingtext-2023-06-11-02-52-59-769\nINFO:sagemaker:Creating endpoint with name blazingtext-2023-06-11-02-52-59-769\n\n\n----\n</code></pre> <p>Review the endpoint in the AWS console.</p> <p>Instructions:  - open the link - notice that you are in the section <code>Amazon SageMaker</code> -&gt; <code>Endpoints</code> -&gt; <code>[Endpoint name]</code> (Example: <code>Amazon SageMaker</code> -&gt; <code>Endpoints</code> -&gt; <code>blazingtext-20XX-XX-XX-XX-XX-XX-XXX</code>) - check the status and other available information about the Endpoint</p> <pre><code>from IPython.core.display import display, HTML\n\ndisplay(HTML('&lt;b&gt;Review &lt;a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={}#/endpoints/{}\"&gt;SageMaker REST Endpoint&lt;/a&gt;&lt;/b&gt;'.format(region, text_classifier.endpoint_name)))\n\n</code></pre> <p></p>"},{"location":"datascience_on_aws/sagemaker_blazing_text_built_in_algos/#4-test-the-model","title":"4. Test the model","text":"<p>Import the <code>nltk</code> library to convert the raw reviews into tokens that BlazingText recognizes.</p> <pre><code>import nltk\nnltk.download('punkt')\n</code></pre> <p>Specify sample reviews to predict the sentiment.</p> <pre><code>reviews = ['This product is great!',\n           'OK, but not great',\n           'This is not the right product.'] \n</code></pre> <p>Tokenize the reviews and specify the payload to use when calling the REST API. </p> <pre><code>tokenized_reviews = [' '.join(nltk.word_tokenize(review)) for review in reviews]\n\npayload = {\"instances\" : tokenized_reviews}\nprint(payload)\n</code></pre> <p>Now you can predict the sentiment for each review. Call the <code>predict</code> method of the text classifier passing the tokenized sentence instances (<code>payload</code>) into the data argument.</p> <pre><code>predictions = text_classifier.predict(data=payload)\nfor prediction in predictions:\n    print('Predicted class: {}'.format(prediction['label'][0].lstrip('__label__')))\n</code></pre> <p>Upload the notebook into S3 bucket for grading purposes.</p> <p>Note: you may need to click on \"Save\" button before the upload.</p> <pre><code>!aws s3 cp ./C1_W4_Assignment.ipynb s3://$bucket/C1_W4_Assignment_Learner.ipynb\n</code></pre> <p>Please go to the main lab window and click on <code>Submit</code> button (see the <code>Finish the lab</code> section of the instructions).</p> <pre><code>\n</code></pre>"},{"location":"datascience_on_aws/sagemaker_feature_store/","title":"Feature transformation with Amazon SageMaker processing job and Feature Store","text":""},{"location":"datascience_on_aws/sagemaker_feature_store/#feature-transformation-with-amazon-sagemaker-processing-job-and-feature-store","title":"Feature transformation with Amazon SageMaker processing job and Feature Store","text":""},{"location":"datascience_on_aws/sagemaker_feature_store/#introduction","title":"Introduction","text":"<p>In this lab you will start with the raw Women's Clothing Reviews dataset and prepare it to train a BERT-based natural language processing (NLP) model. The model will be used to classify customer reviews into positive (1), neutral (0) and negative (-1) sentiment.</p> <p>You will convert the original review text into machine-readable features used by BERT. To perform the required feature transformation you will configure an Amazon SageMaker processing job, which will be running a custom Python script.</p> <pre><code># please ignore warning messages during the installation\n!pip install --disable-pip-version-check -q sagemaker==2.35.0\n!conda install -q -y pytorch==1.6.0 -c pytorch\n!pip install --disable-pip-version-check -q transformers==3.5.1\n</code></pre> <pre><code>\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting package metadata (current_repodata.json): ...working... done\nSolving environment: ...working... failed with initial frozen solve. Retrying with flexible solve.\nCollecting package metadata (repodata.json): ...working... done\nSolving environment: ...working... done\n\n## Package Plan ##\n\n  environment location: /opt/conda\n\n  added / updated specs:\n    - pytorch==1.6.0\n\n\nThe following packages will be downloaded:\n\n    package                    |            build\n    ---------------------------|-----------------\n    ca-certificates-2023.05.30 |       h06a4308_0         120 KB\n    certifi-2022.12.7          |   py37h06a4308_0         150 KB\n    cudatoolkit-10.2.89        |       hfd86e86_1       365.1 MB\n    ninja-1.10.2               |       h06a4308_5           8 KB\n    ninja-base-1.10.2          |       hd09550d_5         109 KB\n    pytorch-1.6.0              |py3.7_cuda10.2.89_cudnn7.6.5_0       537.7 MB  pytorch\n    ------------------------------------------------------------\n                                           Total:       903.1 MB\n\nThe following NEW packages will be INSTALLED:\n\n  cudatoolkit        pkgs/main/linux-64::cudatoolkit-10.2.89-hfd86e86_1 None\n  ninja              pkgs/main/linux-64::ninja-1.10.2-h06a4308_5 None\n  ninja-base         pkgs/main/linux-64::ninja-base-1.10.2-hd09550d_5 None\n  pytorch            pytorch/linux-64::pytorch-1.6.0-py3.7_cuda10.2.89_cudnn7.6.5_0 None\n\nThe following packages will be UPDATED:\n\n  ca-certificates    conda-forge::ca-certificates-2022.12.~ --&gt; pkgs/main::ca-certificates-2023.05.30-h06a4308_0 None\n\nThe following packages will be SUPERSEDED by a higher-priority channel:\n\n  certifi            conda-forge/noarch::certifi-2022.12.7~ --&gt; pkgs/main/linux-64::certifi-2022.12.7-py37h06a4308_0 None\n\n\nPreparing transaction: ...working... done\nVerifying transaction: ...working... done\nExecuting transaction: ...working... done\nRetrieving notices: ...working... done\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n</code></pre> <pre><code>import boto3\nimport sagemaker\nimport botocore\n\nconfig = botocore.config.Config(user_agent_extra='dlai-pds/c2/w1')\n\n# low-level service client of the boto3 session\nsm = boto3.client(service_name='sagemaker', \n                  config=config)\n\nfeaturestore_runtime = boto3.client(service_name='sagemaker-featurestore-runtime', \n                                    config=config)\n\nsess = sagemaker.Session(sagemaker_client=sm,\n                         sagemaker_featurestore_runtime_client=featurestore_runtime)\n\nbucket = sess.default_bucket()\nrole = sagemaker.get_execution_role()\nregion = sess.boto_region_name\n</code></pre> <p></p>"},{"location":"datascience_on_aws/sagemaker_feature_store/#1-configure-the-sagemaker-feature-store","title":"1. Configure the SageMaker Feature Store","text":""},{"location":"datascience_on_aws/sagemaker_feature_store/#11-configure-dataset","title":"1.1. Configure dataset","text":"<p>The raw dataset is in the public S3 bucket. Let's start by specifying the S3 location of it:</p> <pre><code>raw_input_data_s3_uri = 's3://dlai-practical-data-science/data/raw/'\nprint(raw_input_data_s3_uri)\n</code></pre> <pre><code>s3://dlai-practical-data-science/data/raw/\n</code></pre> <p>List the files in the S3 bucket (in this case it will be just one file):</p> <pre><code>!aws s3 ls $raw_input_data_s3_uri\n</code></pre> <pre><code>2021-04-30 02:21:06    8457214 womens_clothing_ecommerce_reviews.csv\n</code></pre> <p></p>"},{"location":"datascience_on_aws/sagemaker_feature_store/#12-configure-the-sagemaker-feature-store","title":"1.2. Configure the SageMaker feature store","text":"<p>As the result of the transformation, in addition to generating files in S3 bucket, you will also save the transformed data in the Amazon SageMaker Feature Store to be used by others in your organization, for example. </p> <p>To configure a Feature Store you need to setup a Feature Group. This is the main resource containing all of the metadata related to the data stored in the Feature Store. A Feature Group should contain a list of Feature Definitions. A Feature Definition consists of a name and the data type. The Feature Group also contains an online store configuration and an offline store configuration controlling where the data is stored. Enabling the online store allows quick access to the latest value for a record via the GetRecord API. The offline store allows storage of the data in your S3 bucket. You will be using the offline store in this lab.</p> <p>Let's setup the Feature Group name and the Feature Store offline prefix in S3 bucket (you will use those later in the lab):</p> <pre><code>import time\ntimestamp = int(time.time())\n\nfeature_group_name = 'reviews-feature-group-' + str(timestamp)\nfeature_store_offline_prefix = 'reviews-feature-store-' + str(timestamp)\n\nprint('Feature group name: {}'.format(feature_group_name))\nprint('Feature store offline prefix in S3: {}'.format(feature_store_offline_prefix))\n</code></pre> <pre><code>Feature group name: reviews-feature-group-1686463816\nFeature store offline prefix in S3: reviews-feature-store-1686463816\n</code></pre> <p>Taking two features from the original raw dataset (<code>Review Text</code> and <code>Rating</code>), you will transform it preparing to be used for the model training and then to be saved in the Feature Store. Here you will define the related features to be stored as a list of <code>FeatureDefinition</code>.</p> <pre><code>from sagemaker.feature_store.feature_definition import (\n    FeatureDefinition,\n    FeatureTypeEnum,\n)\n\nfeature_definitions= [\n    # unique ID of the review\n    FeatureDefinition(feature_name='review_id', feature_type=FeatureTypeEnum.STRING), \n    # ingestion timestamp\n    FeatureDefinition(feature_name='date', feature_type=FeatureTypeEnum.STRING),\n    # sentiment: -1 (negative), 0 (neutral) or 1 (positive). It will be found the Rating values (1, 2, 3, 4, 5)\n    FeatureDefinition(feature_name='sentiment', feature_type=FeatureTypeEnum.STRING), \n    # label ID of the target class (sentiment)\n    FeatureDefinition(feature_name='label_id', feature_type=FeatureTypeEnum.STRING),\n    # reviews encoded with the BERT tokenizer\n    FeatureDefinition(feature_name='input_ids', feature_type=FeatureTypeEnum.STRING),\n    # original Review Text\n    FeatureDefinition(feature_name='review_body', feature_type=FeatureTypeEnum.STRING),\n    # train/validation/test label\n    FeatureDefinition(feature_name='split_type', feature_type=FeatureTypeEnum.STRING)\n]\n</code></pre> <p></p>"},{"location":"datascience_on_aws/sagemaker_feature_store/#exercise-1","title":"Exercise 1","text":"<p>Create the feature group using the feature definitions defined above.</p> <p>Instructions: Use the <code>FeatureGroup</code> function passing the defined above feature group name and the feature definitions.</p> <pre><code>feature_group = FeatureGroup(\n    name=..., # Feature Group name\n    feature_definitions=..., # a list of Feature Definitions\n    sagemaker_session=sess # SageMaker session\n)\n</code></pre> <pre><code>from sagemaker.feature_store.feature_group import FeatureGroup\n\nfeature_group = FeatureGroup(\n    ### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n    name=feature_group_name, # Replace None\n    feature_definitions=feature_definitions, # Replace None\n    ### END SOLUTION - DO NOT delete this comment for grading purposes\n    sagemaker_session=sess\n)\n\nprint(feature_group)\n</code></pre> <pre><code>FeatureGroup(name='reviews-feature-group-1686463816', sagemaker_session=&lt;sagemaker.session.Session object at 0x7f0b3d12bd50&gt;, feature_definitions=[FeatureDefinition(feature_name='review_id', feature_type=&lt;FeatureTypeEnum.STRING: 'String'&gt;), FeatureDefinition(feature_name='date', feature_type=&lt;FeatureTypeEnum.STRING: 'String'&gt;), FeatureDefinition(feature_name='sentiment', feature_type=&lt;FeatureTypeEnum.STRING: 'String'&gt;), FeatureDefinition(feature_name='label_id', feature_type=&lt;FeatureTypeEnum.STRING: 'String'&gt;), FeatureDefinition(feature_name='input_ids', feature_type=&lt;FeatureTypeEnum.STRING: 'String'&gt;), FeatureDefinition(feature_name='review_body', feature_type=&lt;FeatureTypeEnum.STRING: 'String'&gt;), FeatureDefinition(feature_name='split_type', feature_type=&lt;FeatureTypeEnum.STRING: 'String'&gt;)])\n</code></pre> <p>You will use the defined Feature Group later in this lab, the actual creation of the Feature Group will take place in the processing job. Now let's move into the setup of the processing job to transform the dataset.</p> <p></p>"},{"location":"datascience_on_aws/sagemaker_feature_store/#2-transform-the-dataset","title":"2. Transform the dataset","text":"<p>You will configure a SageMaker processing job to run a custom Python script to balance and transform the raw data into a format used by BERT model.</p> <p>Set the transformation parameters including the instance type, instance count, and train/validation/test split percentages. For the purposes of this lab, you will use a relatively small instance type. Please refer to this link for additional instance types that may work for your use case outside of this lab.</p> <p>You can also choose whether you want to balance the dataset or not. In this case, you will balance the dataset to avoid class imbalance in the target variable, <code>sentiment</code>. </p> <p>Another important parameter of the model is the <code>max_seq_length</code>, which specifies the maximum length of the classified reviews for the RoBERTa model. If the sentence is shorter than the maximum length parameter, it will be padded. In another case, when the sentence is longer, it will be truncated from the right side.</p> <p>Since a smaller <code>max_seq_length</code> leads to faster training and lower resource utilization, you want to find the smallest power-of-2 that captures <code>100%</code> of our reviews.  For this dataset, the <code>100th</code> percentile is <code>115</code>.  However, it's best to stick with powers-of-2 when using BERT. So let's choose <code>128</code> as this is the smallest power-of-2 greater than <code>115</code>. You will see below how the shorter sentences will be padded to a maximum length.</p> <pre><code>mean        52.512374\nstd         31.387048\nmin          1.000000\n10%         10.000000\n20%         22.000000\n30%         32.000000\n40%         41.000000\n50%         51.000000\n60%         61.000000\n70%         73.000000\n80%         88.000000\n90%         97.000000\n100%       115.000000\nmax        115.000000\n</code></pre> <p></p> <pre><code>processing_instance_type='ml.c5.xlarge'\nprocessing_instance_count=1\ntrain_split_percentage=0.90\nvalidation_split_percentage=0.05\ntest_split_percentage=0.05\nbalance_dataset=True\nmax_seq_length=128\n</code></pre> <p>To balance and transform our data, you will use a scikit-learn-based processing job. This is essentially a generic Python processing job with scikit-learn pre-installed. You can specify the version of scikit-learn you wish to use. Also pass the SageMaker execution role, processing instance type and instance count.</p> <pre><code>from sagemaker.sklearn.processing import SKLearnProcessor\n\nprocessor = SKLearnProcessor(\n    framework_version='0.23-1',\n    role=role,\n    instance_type=processing_instance_type,\n    instance_count=processing_instance_count,\n    env={'AWS_DEFAULT_REGION': region},                             \n    max_runtime_in_seconds=7200\n)\n</code></pre> <p>The processing job will be running the Python code from the file <code>src/prepare_data.py</code>. In the following exercise you will review the contents of the file and familiarize yourself with main parts of it. </p> <p></p>"},{"location":"datascience_on_aws/sagemaker_feature_store/#exercise-2","title":"Exercise 2","text":"<ol> <li>Open the file src/prepare_data.py. Go through the comments to understand its content.</li> <li>Find and review the <code>convert_to_bert_input_ids()</code> function, which contains the RoBERTa <code>tokenizer</code> configuration.</li> <li>Complete method <code>encode_plus</code> of the RoBERTa <code>tokenizer</code>. Pass the <code>max_seq_length</code> as a value for the argument <code>max_length</code>. It defines a pad to a maximum length specified.</li> <li>Save the file src/prepare_data.py (with the menu command File -&gt; Save Python File).</li> </ol>"},{"location":"datascience_on_aws/sagemaker_feature_store/#this-cell-will-take-approximately-1-2-minutes-to-run","title":"This cell will take approximately 1-2 minutes to run.","text":"<pre><code>import sys, importlib\nsys.path.append('src/')\n\n# import the `prepare_data.py` module\nimport prepare_data\n\n# reload the module if it has been previously loaded \nif 'prepare_data' in sys.modules:\n    importlib.reload(prepare_data)\n\ninput_ids = prepare_data.convert_to_bert_input_ids(\"this product is great!\", max_seq_length)\n\nupdated_correctly = False\n\nif len(input_ids) != max_seq_length:\n    print('#######################################################################################################')\n    print('Please check that the function \\'convert_to_bert_input_ids\\' in the file src/prepare_data.py is complete.')\n    print('#######################################################################################################')\n    raise Exception('Please check that the function \\'convert_to_bert_input_ids\\' in the file src/prepare_data.py is complete.')\nelse:\n    print('##################')\n    print('Updated correctly!')\n    print('##################')\n\n    updated_correctly = True\n</code></pre> <pre><code>HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descripti\u2026\n\n\n\n\n\n\nHBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti\u2026\n\n\n\n##################\nUpdated correctly!\n##################\n</code></pre> <p>Review the results of tokenization for the given example (\\\"this product is great!\\\"):</p> <pre><code>input_ids = prepare_data.convert_to_bert_input_ids(\"this product is great!\", max_seq_length)\n\nprint(input_ids)\nprint('Length of the sequence: {}'.format(len(input_ids)))\n</code></pre> <pre><code>[0, 9226, 1152, 16, 372, 328, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\nLength of the sequence: 128\n</code></pre> <p>Launch the processing job with the custom script passing defined above parameters.</p> <pre><code>from sagemaker.processing import ProcessingInput, ProcessingOutput\n\nif (updated_correctly):\n\n    processor.run(code='src/prepare_data.py',\n              inputs=[\n                    ProcessingInput(source=raw_input_data_s3_uri,\n                                    destination='/opt/ml/processing/input/data/',\n                                    s3_data_distribution_type='ShardedByS3Key')\n              ],\n              outputs=[\n                    ProcessingOutput(output_name='sentiment-train',\n                                     source='/opt/ml/processing/output/sentiment/train',\n                                     s3_upload_mode='EndOfJob'),\n                    ProcessingOutput(output_name='sentiment-validation',\n                                     source='/opt/ml/processing/output/sentiment/validation',\n                                     s3_upload_mode='EndOfJob'),\n                    ProcessingOutput(output_name='sentiment-test',\n                                     source='/opt/ml/processing/output/sentiment/test',\n                                     s3_upload_mode='EndOfJob')\n              ],\n              arguments=['--train-split-percentage', str(train_split_percentage),\n                         '--validation-split-percentage', str(validation_split_percentage),\n                         '--test-split-percentage', str(test_split_percentage),\n                         '--balance-dataset', str(balance_dataset),\n                         '--max-seq-length', str(max_seq_length),                         \n                         '--feature-store-offline-prefix', str(feature_store_offline_prefix),\n                         '--feature-group-name', str(feature_group_name)                         \n              ],\n              logs=True,\n              wait=False)\n\nelse:\n    print('#######################################')\n    print('Please update the code correctly above.')\n    print('#######################################')    \n</code></pre> <pre><code>Job Name:  sagemaker-scikit-learn-2023-06-11-06-19-29-466\nInputs:  [{'InputName': 'input-1', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://dlai-practical-data-science/data/raw/', 'LocalPath': '/opt/ml/processing/input/data/', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'ShardedByS3Key', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-047418094836/sagemaker-scikit-learn-2023-06-11-06-19-29-466/input/code/prepare_data.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\nOutputs:  [{'OutputName': 'sentiment-train', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-047418094836/sagemaker-scikit-learn-2023-06-11-06-19-29-466/output/sentiment-train', 'LocalPath': '/opt/ml/processing/output/sentiment/train', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'sentiment-validation', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-047418094836/sagemaker-scikit-learn-2023-06-11-06-19-29-466/output/sentiment-validation', 'LocalPath': '/opt/ml/processing/output/sentiment/validation', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'sentiment-test', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-047418094836/sagemaker-scikit-learn-2023-06-11-06-19-29-466/output/sentiment-test', 'LocalPath': '/opt/ml/processing/output/sentiment/test', 'S3UploadMode': 'EndOfJob'}}]\n</code></pre> <p>You can see the information about the processing jobs using the <code>describe</code> function. The result is in dictionary format. Let's pull the processing job name:</p> <pre><code>scikit_processing_job_name = processor.jobs[-1].describe()['ProcessingJobName']\n\nprint('Processing job name: {}'.format(scikit_processing_job_name))\n</code></pre> <pre><code>Processing job name: sagemaker-scikit-learn-2023-06-11-06-19-29-466\n</code></pre> <p></p>"},{"location":"datascience_on_aws/sagemaker_feature_store/#exercise-3","title":"Exercise 3","text":"<p>Pull the processing job status from the processing job description.</p> <p>Instructions: Print the keys of the processing job description dictionary, choose the one related to the status of the processing job and print the value of it.</p> <pre><code>print(processor.jobs[-1].describe().keys())\n</code></pre> <pre><code>dict_keys(['ProcessingInputs', 'ProcessingOutputConfig', 'ProcessingJobName', 'ProcessingResources', 'StoppingCondition', 'AppSpecification', 'Environment', 'RoleArn', 'ProcessingJobArn', 'ProcessingJobStatus', 'LastModifiedTime', 'CreationTime', 'ResponseMetadata'])\n</code></pre> <pre><code>### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\nscikit_processing_job_status = processor.jobs[-1].describe()['ProcessingJobStatus'] # Replace None\n### END SOLUTION - DO NOT delete this comment for grading purposes\nprint('Processing job status: {}'.format(scikit_processing_job_status))\n</code></pre> <pre><code>Processing job status: InProgress\n</code></pre> <p>Review the created processing job in the AWS console.</p> <p>Instructions:  - open the link - notice that you are in the section <code>Amazon SageMaker</code> -&gt; <code>Processing jobs</code> - check the name of the processing job, its status and other available information</p> <pre><code>from IPython.core.display import display, HTML\n\ndisplay(HTML('&lt;b&gt;Review &lt;a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={}#/processing-jobs/{}\"&gt;processing job&lt;/a&gt;&lt;/b&gt;'.format(region, scikit_processing_job_name)))\n</code></pre> <p>Review processing job</p> <p>Wait for about 5 minutes to review the CloudWatch Logs. You may open the file src/prepare_data.py again and examine the outputs of the code in the CloudWatch logs.</p> <pre><code>from IPython.core.display import display, HTML\n\ndisplay(HTML('&lt;b&gt;Review &lt;a target=\"blank\" href=\"https://console.aws.amazon.com/cloudwatch/home?region={}#logStream:group=/aws/sagemaker/ProcessingJobs;prefix={};streamFilter=typeLogStreamPrefix\"&gt;CloudWatch logs&lt;/a&gt; after about 5 minutes&lt;/b&gt;'.format(region, scikit_processing_job_name)))\n</code></pre> <p>Review CloudWatch logs after about 5 minutes</p> <p>After the completion of the processing job you can also review the output in the S3 bucket.</p> <pre><code>from IPython.core.display import display, HTML\n\ndisplay(HTML('&lt;b&gt;Review &lt;a target=\"blank\" href=\"https://s3.console.aws.amazon.com/s3/buckets/{}/{}/?region={}&amp;tab=overview\"&gt;S3 output data&lt;/a&gt; after the processing job has completed&lt;/b&gt;'.format(bucket, scikit_processing_job_name, region)))\n\n</code></pre> <p>Review S3 output data after the processing job has completed</p> <p>Wait for the processing job to complete.</p>"},{"location":"datascience_on_aws/sagemaker_feature_store/#this-cell-will-take-approximately-15-minutes-to-run","title":"This cell will take approximately 15 minutes to run.","text":"<pre><code>%%time\n\nrunning_processor = sagemaker.processing.ProcessingJob.from_processing_name(\n    processing_job_name=scikit_processing_job_name,\n    sagemaker_session=sess\n)\n\nrunning_processor.wait(logs=False)\n</code></pre> <pre><code>................................................................................!CPU times: user 367 ms, sys: 20.1 ms, total: 387 ms\nWall time: 6min 45s\n</code></pre> <p>Please wait until ^^ Processing Job ^^ completes above</p> <p>Inspect the transformed and balanced data in the S3 bucket.</p> <pre><code>processing_job_description = running_processor.describe()\n\noutput_config = processing_job_description['ProcessingOutputConfig']\nfor output in output_config['Outputs']:\n    if output['OutputName'] == 'sentiment-train':\n        processed_train_data_s3_uri = output['S3Output']['S3Uri']\n    if output['OutputName'] == 'sentiment-validation':\n        processed_validation_data_s3_uri = output['S3Output']['S3Uri']\n    if output['OutputName'] == 'sentiment-test':\n        processed_test_data_s3_uri = output['S3Output']['S3Uri']\n\nprint(processed_train_data_s3_uri)\nprint(processed_validation_data_s3_uri)\nprint(processed_test_data_s3_uri)\n</code></pre> <pre><code>s3://sagemaker-us-east-1-047418094836/sagemaker-scikit-learn-2023-06-11-06-19-29-466/output/sentiment-train\ns3://sagemaker-us-east-1-047418094836/sagemaker-scikit-learn-2023-06-11-06-19-29-466/output/sentiment-validation\ns3://sagemaker-us-east-1-047418094836/sagemaker-scikit-learn-2023-06-11-06-19-29-466/output/sentiment-test\n</code></pre> <pre><code>!aws s3 ls $processed_train_data_s3_uri/\n</code></pre> <pre><code>2023-06-11 06:32:30    4898781 part-algo-1-womens_clothing_ecommerce_reviews.tsv\n</code></pre> <pre><code>!aws s3 ls $processed_validation_data_s3_uri/\n</code></pre> <pre><code>2023-06-11 06:32:30     270676 part-algo-1-womens_clothing_ecommerce_reviews.tsv\n</code></pre> <pre><code>!aws s3 ls $processed_test_data_s3_uri/\n</code></pre> <pre><code>2023-06-11 06:32:31     273383 part-algo-1-womens_clothing_ecommerce_reviews.tsv\n</code></pre> <p>Copy the data into the folder <code>balanced</code>.</p> <pre><code>!aws s3 cp $processed_train_data_s3_uri/part-algo-1-womens_clothing_ecommerce_reviews.tsv ./balanced/sentiment-train/\n!aws s3 cp $processed_validation_data_s3_uri/part-algo-1-womens_clothing_ecommerce_reviews.tsv ./balanced/sentiment-validation/\n!aws s3 cp $processed_test_data_s3_uri/part-algo-1-womens_clothing_ecommerce_reviews.tsv ./balanced/sentiment-test/\n</code></pre> <pre><code>download: s3://sagemaker-us-east-1-047418094836/sagemaker-scikit-learn-2023-06-11-06-19-29-466/output/sentiment-train/part-algo-1-womens_clothing_ecommerce_reviews.tsv to balanced/sentiment-train/part-algo-1-womens_clothing_ecommerce_reviews.tsv\ndownload: s3://sagemaker-us-east-1-047418094836/sagemaker-scikit-learn-2023-06-11-06-19-29-466/output/sentiment-validation/part-algo-1-womens_clothing_ecommerce_reviews.tsv to balanced/sentiment-validation/part-algo-1-womens_clothing_ecommerce_reviews.tsv\ndownload: s3://sagemaker-us-east-1-047418094836/sagemaker-scikit-learn-2023-06-11-06-19-29-466/output/sentiment-test/part-algo-1-womens_clothing_ecommerce_reviews.tsv to balanced/sentiment-test/part-algo-1-womens_clothing_ecommerce_reviews.tsv\n</code></pre> <p>Review the training, validation and test data outputs:</p> <pre><code>!head -n 5 ./balanced/sentiment-train/part-algo-1-womens_clothing_ecommerce_reviews.tsv\n</code></pre> <pre><code>review_id   sentiment   label_id    input_ids   review_body date\n12096   1   2   [0, 45065, 16, 372, 1437, 10698, 182, 157, 23, 3844, 1437, 939, 524, 195, 108, 306, 16157, 17243, 2162, 1836, 290, 642, 8, 24, 18, 205, 734, 939, 74, 2703, 3568, 8872, 25, 24, 11541, 8, 6476, 15, 5, 1929, 4, 51, 32, 55, 1136, 73, 36741, 73, 31421, 9304, 25, 1468, 1341, 7992, 4, 1374, 1437, 939, 524, 1372, 19, 106, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]   Quality is great  fits very well at waste  i am 5'4 135lb bought size 8p and it's good... i would require wear heels as it reaches and sits on the floor. they are more fall/spring/winter pants as material quite thick. overall  i am happy with them 2023-06-11T06:26:11Z\n10118   -1  0   [0, 713, 3588, 34, 1256, 8089, 4, 5, 299, 2564, 157, 53, 5, 2576, 1415, 101, 41, 7237, 159, 16676, 4, 24, 34, 615, 1468, 7, 146, 132, 31296, 8, 5, 380, 12189, 15, 5, 2380, 146, 5, 16576, 4757, 66, 29445, 4, 5, 1345, 9, 1421, 16, 31, 526, 1437, 45, 5, 760, 4, 182, 29747, 24203, 15, 162, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  This dress has pretty colors. the top fit well but the bottom looked like an upside down umbrella. it has enough material to make 2 skirts and the big pockets on the sides make the skirt stick out sideways. the photo of model is from side  not the front. very unflattering on me. 2023-06-11T06:26:11Z\n7852    -1  0   [0, 347, 4467, 11, 6680, 1437, 939, 657, 5, 4520, 8089, 1437, 5, 3016, 909, 19008, 579, 1671, 8, 5, 1510, 18, 16464, 1437, 959, 1437, 5, 10199, 16, 6162, 1437, 8, 5, 2373, 233, 11, 127, 1217, 16, 14, 5, 39336, 14, 422, 552, 5, 760, 1312, 9, 5, 6399, 109, 45, 12432, 5, 6184, 4, 2085, 42, 21, 18797, 1437, 53, 19, 5, 6399, 939, 829, 1437, 24, 1415, 11385, 4, 939, 1051, 24, 124, 4, 939, 3120, 11, 5, 2170, 14, 5, 909, 3405, 32, 19055, 2325, 81, 5, 1312, 760, 27595, 1437, 98, 24, 16, 10, 828, 34575, 9404, 4, 939, 1979, 75, 907, 42, 299, 23, 143, 425, 716, 15, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  Cute in theory  i love the bright colors  the tied black collar sash and the 70's vibe  however  the fabric is cheap  and the worst part in my view is that the seams that run along the front center of the shirt do not align the pattern. maybe this was intentional  but with the shirt i received  it looked horrible. i sent it back. i notice in the picture that the black ties are strategically placed over the center front seam  so it is a bit deceiving. i wouldn't buy this top at any price based on    2023-06-11T06:26:11Z\n8068    1   2   [0, 19065, 8089, 1437, 2496, 8, 2564, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]    Great colors  style and fit 2023-06-11T06:26:11Z\n</code></pre> <pre><code>!head -n 5 ./balanced/sentiment-validation/part-algo-1-womens_clothing_ecommerce_reviews.tsv\n</code></pre> <pre><code>review_id   sentiment   label_id    input_ids   review_body date\n12126   1   2   [0, 713, 16, 804, 5451, 98, 939, 2740, 258, 10070, 3023, 29, 8, 579, 4, 24, 1237, 1256, 739, 98, 939, 1682, 1836, 3023, 29, 4, 5, 1468, 64, 28, 13596, 4, 53, 939, 101, 5, 2157, 9, 24, 8, 182, 3473, 7, 110, 3024, 4, 939, 524, 98, 1372, 2806, 98, 171, 33391, 11263, 939, 213, 16506, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  This is online exclusive so i ordered both sizes xs and s. it runs pretty large so i kept size xs. the material can be stretched. but i like the feeling of it and very comfortable to your skin. i am so happy receiving so many compliments wherever i go!!!  2023-06-11T06:26:11Z\n2430    0   1   [0, 100, 2162, 155, 9, 209, 13657, 11, 430, 8089, 1437, 5, 2440, 65, 56, 65, 24150, 28840, 10941, 4, 1051, 24, 124, 4, 122, 540, 87, 158, 360, 423, 51, 32, 15, 1392, 4, 5, 2496, 16, 30213, 8, 120, 171, 14156, 2963, 15, 5, 80, 939, 33, 4, 856, 28831, 939, 437, 10, 2491, 417, 8325, 29882, 8, 5679, 2564, 372, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  I bought 3 of these tops in different colors  the blue one had one sleeve noticeably shorter. sent it back. now less than 10 days later they are on sale. the style is darling and get many complements on the two i have. fyi i'm a 36d 130lbs and med fit great   2023-06-11T06:26:11Z\n4395    -1  0   [0, 100, 794, 42, 15, 10, 313, 858, 18017, 11, 5, 1400, 8, 98, 770, 24, 7, 173, 53, 21, 95, 350, 24901, 8, 35156, 4, 182, 205, 1318, 8, 1468, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]    I saw this on a mannequin in the store and so wanted it to work but was just too oversized and bulky. very good quality and material.   2023-06-11T06:26:11Z\n2386    1   2   [0, 597, 20554, 833, 53, 45, 350, 856, 28102, 13454, 16, 10, 2579, 37919, 12, 3341, 1468, 4, 939, 300, 5, 1104, 65, 61, 40, 213, 19, 10, 319, 9, 127, 31296, 1437, 9304, 8, 13344, 4, 7328, 97, 34910, 1437, 939, 399, 75, 465, 24, 350, 765, 13, 162, 23, 70, 1437, 53, 939, 524, 239, 12, 2739, 15346, 4, 9881, 53, 19, 30109, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]   Feminine but not too fussy tee is a nice linen-like material. i got the white one which will go with a lot of my skirts  pants and shorts. unlike other reviewers  i didn't find it too short for me at all  but i am high-waisted. casual but with extras. 2023-06-11T06:26:11Z\n</code></pre> <pre><code>!head -n 5 ./balanced/sentiment-test/part-algo-1-womens_clothing_ecommerce_reviews.tsv\n</code></pre> <pre><code>review_id   sentiment   label_id    input_ids   review_body date\n14693   -1  0   [0, 100, 269, 770, 7, 657, 42, 6399, 328, 5, 8089, 32, 12058, 1437, 182, 11577, 8, 95, 25, 2343, 4, 5, 2564, 21, 70, 1593, 15, 162, 4, 939, 2740, 5, 4716, 1459, 37863, 29, 8, 24, 21, 202, 350, 2233, 219, 4, 8, 1437, 24, 1682, 9255, 98, 5, 760, 19008, 9, 5, 6399, 74, 3068, 62, 88, 127, 5397, 4, 24, 1415, 101, 10, 14072, 15, 162, 4, 13, 5135, 12, 939, 524, 195, 108, 176, 113, 1437, 12730, 29882, 734, 5632, 10, 650, 5120, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  \"I really wanted to love this shirt! the colors are gorgeous  very vibrant and just as shown. the fit was all wrong on me. i ordered the petite xxs and it was still too boxy. and  it kept shifting so the front collar of the shirt would ride up into my neck. it looked like a sack on me. for reference- i am 5'2\"\"  112lbs...with a small frame.\" 2023-06-11T06:26:11Z\n1209    1   2   [0, 100, 2638, 5, 3195, 8, 5, 2496, 9, 5, 21764, 4, 1437, 24, 21, 10, 828, 350, 765, 15, 162, 8, 939, 802, 24, 156, 162, 356, 2233, 219, 98, 939, 399, 75, 253, 62, 2396, 24, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1] I loved the color and the style of the sleeves.  it was a bit too short on me and i thought it made me look boxy so i didn't end up keeping it  2023-06-11T06:26:11Z\n17209   -1  0   [0, 133, 2564, 9, 5, 299, 16, 1528, 7, 1836, 1437, 53, 939, 269, 218, 75, 101, 5, 326, 1180, 2379, 8470, 1506, 41262, 12, 3341, 22861, 28517, 223, 5, 1104, 22990, 4, 5, 1104, 22990, 16, 4520, 1104, 8, 1302, 182, 28685, 1437, 53, 24, 817, 5, 22861, 28517, 12213, 356, 182, 11216, 8, 182, 28840, 326, 1180, 2379, 4, 24, 16, 6587, 11153, 561, 4, 939, 67, 399, 75, 101, 5, 619, 9, 5, 8470, 1506, 41262, 12, 3341, 10199, 136, 127, 3024, 4, 190, 600, 42, 16, 10, 205, 1318, 2125, 19, 10, 319, 9, 2679, 4617, 1437, 939, 437, 3668, 3981, 24, 124, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]   The fit of the top is true to size  but i really don't like the taupe terrycloth-like sweatshirt under the white lace. the white lace is bright white and seems very sturdy  but it makes the sweatshirt underneath look very dirty and very noticeably taupe. it is terrible paired together. i also didn't like the feel of the terrycloth-like fabric against my skin. even though this is a good quality piece with a lot of interesting detail  i'm absolutely sending it back.    2023-06-11T06:26:11Z\n14582   -1  0   [0, 100, 269, 770, 7, 657, 42, 1437, 53, 24, 21, 95, 350, 13103, 18140, 1827, 7, 28, 34203, 4, 939, 524, 3700, 10, 1836, 158, 50, 316, 11, 14442, 8, 13855, 27734, 1437, 8, 5, 4761, 21, 1087, 6932, 198, 162, 4, 67, 5, 33827, 13977, 478, 162, 614, 8, 15713, 3804, 11, 41, 29747, 24203, 169, 4, 24, 56, 7, 213, 124, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]    I really wanted to love this  but it was just too voluminous to be flattering. i am typically a size 10 or 12 in dresses and jumpsuits  and the medium was billowing around me. also the elastic waist hit me low and bunched in an unflattering way. it had to go back.    2023-06-11T06:26:11Z\n</code></pre> <p></p>"},{"location":"datascience_on_aws/sagemaker_feature_store/#3-query-the-feature-store","title":"3. Query the Feature Store","text":"<p>In addition to transforming the data and saving in S3 bucket, the processing job populates the feature store with the transformed and balanced data.  Let's query this data using Amazon Athena.</p> <p></p>"},{"location":"datascience_on_aws/sagemaker_feature_store/#31-export-training-validation-and-test-datasets-from-the-feature-store","title":"3.1. Export training, validation, and test datasets from the Feature Store","text":"<p>Here you will do the export only for the training dataset, as an example. </p> <p>Use <code>athena_query()</code> function to create an Athena query for the defined above Feature Group. Then you can pull the table name of the Amazon Glue Data Catalog table which is auto-generated by Feature Store.</p> <pre><code>feature_store_query = feature_group.athena_query()\n\nfeature_store_table = feature_store_query.table_name\n\nquery_string = \"\"\"\n    SELECT date,\n        review_id,\n        sentiment, \n        label_id,\n        input_ids,\n        review_body\n    FROM \"{}\" \n    WHERE split_type='train' \n    LIMIT 5\n\"\"\".format(feature_store_table)\n\nprint('Glue Catalog table name: {}'.format(feature_store_table))\nprint('Running query: {}'.format(query_string))\n</code></pre> <pre><code>Glue Catalog table name: reviews_feature_group_1686463816_1686464741\nRunning query: \n    SELECT date,\n        review_id,\n        sentiment, \n        label_id,\n        input_ids,\n        review_body\n    FROM \"reviews_feature_group_1686463816_1686464741\" \n    WHERE split_type='train' \n    LIMIT 5\n</code></pre> <p>Configure the S3 location for the query results.  This allows us to re-use the query results for future queries if the data has not changed.  We can even share this S3 location between team members to improve query performance for common queries on data that does not change often.</p> <pre><code>output_s3_uri = 's3://{}/query_results/{}/'.format(bucket, feature_store_offline_prefix)\nprint(output_s3_uri)\n</code></pre> <pre><code>s3://sagemaker-us-east-1-047418094836/query_results/reviews-feature-store-1686463816/\n</code></pre> <p></p>"},{"location":"datascience_on_aws/sagemaker_feature_store/#exercise-4","title":"Exercise 4","text":"<p>Query the feature store.</p> <p>Instructions: Use <code>feature_store_query.run</code> function passing the constructed above query string and the location of the output S3 bucket.</p> <pre><code>feature_store_query.run(\n    query_string=..., # query string\n    output_location=... # location of the output S3 bucket\n)\n</code></pre> <pre><code>feature_store_query.run(\n    ### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n    query_string=query_string, # Replace None\n    output_location=output_s3_uri # Replace None\n    ### END SOLUTION - DO NOT delete this comment for grading purposes\n)\n\nfeature_store_query.wait()\n</code></pre> <pre><code>import pandas as pd\npd.set_option(\"max_colwidth\", 100)\n\ndf_feature_store = feature_store_query.as_dataframe()\ndf_feature_store\n</code></pre> date review_id sentiment label_id input_ids review_body 0 2023-06-11T06:26:11Z 18569 1 2 [0, 16587, 1437, 657, 42, 299, 4, 10199, 16, 2579, 8, 3793, 1437, 1326, 372, 19, 2084, 6149, 103... Love  love this top. fabric is nice and soft  looks great with leggings. love the way it falls i... 1 2023-06-11T06:26:11Z 11103 0 1 [0, 713, 16, 10, 7992, 23204, 4, 24, 16, 1256, 1437, 53, 34, 10, 765, 5933, 4, 2, 1, 1, 1, 1, 1,... This is a thick sweater. it is pretty  but has a short length. 2 2023-06-11T06:26:11Z 1038 -1 0 [0, 20328, 282, 75, 173, 15, 42, 5350, 11454, 22101, 4, 1437, 39328, 62, 74, 33, 1147, 19, 5, 61... Didn't work on this curvy gal.  sizing up would have helped with the button gaps  but the flowy ... 3 2023-06-11T06:26:11Z 7946 0 1 [0, 28965, 1437, 10, 269, 2579, 299, 14, 16, 3793, 8, 3473, 4, 5, 3124, 5933, 2323, 15481, 15, 5... Overall  a really nice top that is soft and comfortable. the arm length hits nicely on the forea... 4 2023-06-11T06:26:11Z 3267 -1 0 [0, 100, 269, 6640, 42, 6399, 5, 65, 86, 939, 300, 7, 3568, 24, 734, 4297, 77, 939, 15158, 24, 1... I really liked this shirt the one time i got to wear it...but when i washed it  according to the... <p>Review the Feature Store in SageMaker Studio</p> <p></p> <p></p>"},{"location":"datascience_on_aws/sagemaker_feature_store/#32-export-tsv-from-feature-store","title":"3.2. Export TSV from Feature Store","text":"<p>Save the output as a TSV file:</p> <pre><code>df_feature_store.to_csv('./feature_store_export.tsv',\n                        sep='\\t',\n                        index=False,\n                        header=True)\n</code></pre> <pre><code>!head -n 5 ./feature_store_export.tsv\n</code></pre> <pre><code>date    review_id   sentiment   label_id    input_ids   review_body\n2023-06-11T06:26:11Z    18569   1   2   [0, 16587, 1437, 657, 42, 299, 4, 10199, 16, 2579, 8, 3793, 1437, 1326, 372, 19, 2084, 6149, 1033, 4, 657, 5, 169, 24, 5712, 11, 5, 760, 41, 251, 615, 11, 5, 124, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]    Love  love this top. fabric is nice and soft  looks great with leggings. love the way it falls in the front an long enough in the back.\n2023-06-11T06:26:11Z    11103   0   1   [0, 713, 16, 10, 7992, 23204, 4, 24, 16, 1256, 1437, 53, 34, 10, 765, 5933, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1] This is a thick sweater. it is pretty  but has a short length.\n2023-06-11T06:26:11Z    1038    -1  0   [0, 20328, 282, 75, 173, 15, 42, 5350, 11454, 22101, 4, 1437, 39328, 62, 74, 33, 1147, 19, 5, 6148, 10778, 1437, 53, 5, 3041, 219, 3989, 9, 5, 3089, 11556, 74, 33, 1415, 350, 21592, 15, 10, 2514, 1836, 4, 1437, 538, 1323, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]   Didn't work on this curvy gal.  sizing up would have helped with the button gaps  but the flowy shape of the blouse would have looked too maternity on a larger size.  major pass.\n2023-06-11T06:26:11Z    7946    0   1   [0, 28965, 1437, 10, 269, 2579, 299, 14, 16, 3793, 8, 3473, 4, 5, 3124, 5933, 2323, 15481, 15, 5, 30357, 8, 5, 29815, 4617, 23, 299, 16, 157, 12, 3865, 28354, 4, 399, 75, 489, 42, 187, 5, 299, 156, 162, 356, 1341, 380, 11, 127, 11044, 1437, 7, 5, 477, 9, 45, 145, 34203, 4, 299, 16, 67, 10, 828, 2233, 219, 1437, 98, 939, 1017, 1095, 409, 114, 47, 32, 4716, 1459, 1437, 19, 10, 2514, 11044, 3867, 47, 32, 8578, 19, 14, 9723, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1] Overall  a really nice top that is soft and comfortable. the arm length hits nicely on the forearm and the decorative detail at top is well-constructed. didn't keep this since the top made me look quite big in my bust  to the point of not being flattering. top is also a bit boxy  so i'd stay away if you are petite  with a larger bust unless you are okay with that emphasis.\n</code></pre> <p>Upload TSV to the S3 bucket:</p> <pre><code>!aws s3 cp ./feature_store_export.tsv s3://$bucket/feature_store/feature_store_export.tsv\n</code></pre> <pre><code>upload: ./feature_store_export.tsv to s3://sagemaker-us-east-1-047418094836/feature_store/feature_store_export.tsv\n</code></pre> <p>Check the file in the S3 bucket:</p> <pre><code>!aws s3 ls --recursive s3://$bucket/feature_store/feature_store_export.tsv\n</code></pre> <pre><code>2023-06-11 06:37:31       3622 feature_store/feature_store_export.tsv\n</code></pre> <p></p>"},{"location":"datascience_on_aws/sagemaker_feature_store/#33-check-that-the-dataset-in-the-feature-store-is-balanced-by-sentiment","title":"3.3. Check that the dataset in the Feature Store is balanced by sentiment","text":"<p>Now you can setup an Athena query to check that the stored dataset is balanced by the target class <code>sentiment</code>.</p> <p></p>"},{"location":"datascience_on_aws/sagemaker_feature_store/#exercise-5","title":"Exercise 5","text":"<p>Write an SQL query to count the total number of the reviews per <code>sentiment</code> stored in the Feature Group.</p> <p>Instructions: Pass the SQL statement of the form </p> <pre><code>SELECT category_column, COUNT(*) AS new_column_name\nFROM table_name\nGROUP BY category_column\n</code></pre> <p>into the variable <code>query_string_count_by_sentiment</code>. Here you would need to use the column <code>sentiment</code> and give a name <code>count_reviews</code> to the new column with the counts.</p> <pre><code>feature_store_query_2 = feature_group.athena_query()\n\n# Replace all None\n### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\nquery_string_count_by_sentiment = \"\"\"\nSELECT sentiment, COUNT(*) AS count_reviews\nFROM \"{}\"\nGROUP BY sentiment\n\"\"\".format(feature_store_table)\n### END SOLUTION - DO NOT delete this comment for grading purposes\n</code></pre> <p></p>"},{"location":"datascience_on_aws/sagemaker_feature_store/#exercise-6","title":"Exercise 6","text":"<p>Query the feature store.</p> <p>Instructions: Use <code>run</code> function of the Feature Store query, passing the new query string <code>query_string_count_by_sentiment</code>. The output S3 bucket will remain unchanged. You can follow the example above.</p> <pre><code>feature_store_query_2.run(\n    ### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n    query_string=query_string_count_by_sentiment, # Replace None\n    output_location=output_s3_uri # Replace None\n    ### END SOLUTION - DO NOT delete this comment for grading purposes\n)\n\nfeature_store_query_2.wait()\n\ndf_count_by_sentiment = feature_store_query_2.as_dataframe()\ndf_count_by_sentiment\n</code></pre> sentiment count_reviews 0 -1 2051 1 0 2051 2 1 2051 <p></p>"},{"location":"datascience_on_aws/sagemaker_feature_store/#exercise-7","title":"Exercise 7","text":"<p>Visualize the result of the query in the bar plot, showing the count of the reviews by sentiment value.</p> <p>Instructions: Pass the resulting data frame <code>df_count_by_sentiment</code> into the <code>barplot</code> function of the <code>seaborn</code> library.</p> <pre><code>sns.barplot(\n    data=..., \n    x='...', \n    y='...',\n    color=\"blue\"\n)\n</code></pre> <pre><code>%matplotlib inline\nimport seaborn as sns\n\nsns.barplot(\n    ### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n    data=df_count_by_sentiment, # Replace None\n    x='sentiment', # Replace None\n    y='count_reviews', # Replace None\n    ### END SOLUTION - DO NOT delete this comment for grading purposes\n    color=\"blue\"\n)\n</code></pre> <pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f0ad1ecddd0&gt;\n</code></pre> <p></p> <p>Upload the notebook and <code>prepare_data.py</code> file into S3 bucket for grading purposes.</p> <p>Note: you may need to save the file before the upload.</p> <pre><code>!aws s3 cp ./C2_W1_Assignment.ipynb s3://$bucket/C2_W1_Assignment_Learner.ipynb\n!aws s3 cp ./src/prepare_data.py s3://$bucket/src/C2_W1_prepare_data_Learner.py\n</code></pre> <p>Please go to the main lab window and click on <code>Submit</code> button (see the <code>Finish the lab</code> section of the instructions).</p> <pre><code>\n</code></pre>"},{"location":"datascience_on_aws/viz_and_analyze_data/","title":"Register, Analyze and Visualize Data","text":""},{"location":"datascience_on_aws/viz_and_analyze_data/#register-and-visualize-dataset","title":"Register and visualize dataset","text":""},{"location":"datascience_on_aws/viz_and_analyze_data/#introduction","title":"Introduction","text":"<p>In this lab you will ingest and transform the customer product reviews dataset. Then you will use AWS data stack services such as AWS Glue and Amazon Athena for ingesting and querying the dataset. Finally you will use AWS Data Wrangler to analyze the dataset and plot some visuals extracting insights.</p> <p>Let's install the required modules first.</p> <pre><code># please ignore warning messages during the installation\n!pip install --disable-pip-version-check -q sagemaker==2.35.0\n!pip install --disable-pip-version-check -q pandas==1.1.4\n!pip install --disable-pip-version-check -q awswrangler==2.7.0\n!pip install --disable-pip-version-check -q numpy==1.18.5\n!pip install --disable-pip-version-check -q seaborn==0.11.0\n!pip install --disable-pip-version-check -q matplotlib===3.3.3\n</code></pre> <pre><code>\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nsparkmagic 0.20.4 requires nest-asyncio==1.5.5, but you have nest-asyncio 1.5.6 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nsparkmagic 0.20.4 requires nest-asyncio==1.5.5, but you have nest-asyncio 1.5.6 which is incompatible.\nsagemaker-data-insights 0.3.3 requires numpy&gt;=1.21.6, but you have numpy 1.20.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nsparkmagic 0.20.4 requires nest-asyncio==1.5.5, but you have nest-asyncio 1.5.6 which is incompatible.\nsagemaker-data-insights 0.3.3 requires numpy&gt;=1.21.6, but you have numpy 1.18.5 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n</code></pre> <p></p>"},{"location":"datascience_on_aws/viz_and_analyze_data/#1-ingest-and-transform-the-public-dataset","title":"1. Ingest and transform the public dataset","text":"<p>The dataset Women's Clothing Reviews has been chosen as the main dataset.</p> <p>It is shared in a public Amazon S3 bucket, and is available as a comma-separated value (CSV) text format:</p> <p><code>s3://dlai-practical-data-science/data/raw/womens_clothing_ecommerce_reviews.csv</code></p> <p></p>"},{"location":"datascience_on_aws/viz_and_analyze_data/#11-list-the-dataset-files-in-the-public-s3-bucket","title":"1.1. List the dataset files in the public S3 bucket","text":"<p>The AWS Command Line Interface (CLI) is a unified tool to manage your AWS services. With just one tool, you can control multiple AWS services from the command line and automate them through scripts. You will use it to list the dataset files.</p> <p>View dataset files in CSV format</p> <p><code>aws s3 ls [bucket_name]</code> function lists all objects in the S3 bucket. Let's use it to view the reviews data files in CSV format:</p> <p></p>"},{"location":"datascience_on_aws/viz_and_analyze_data/#exercise-1","title":"Exercise 1","text":"<p>View the list of the files available in the public bucket <code>s3://dlai-practical-data-science/data/raw/</code>.</p> <p>Instructions: Use <code>aws s3 ls [bucket_name]</code> function. To run the AWS CLI command from the notebook you will need to put an exclamation mark in front of it: <code>!aws</code>. You should see the data file <code>womens_clothing_ecommerce_reviews.csv</code> in the list.</p> <pre><code>### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n!aws s3 ls s3://dlai-practical-data-science/data/raw/ # Replace None\n### END SOLUTION - DO NOT delete this comment for grading purposes\n\n# EXPECTED OUTPUT\n# ... womens_clothing_ecommerce_reviews.csv\n</code></pre> <pre><code>2021-04-30 02:21:06    8457214 womens_clothing_ecommerce_reviews.csv\n</code></pre> <p></p>"},{"location":"datascience_on_aws/viz_and_analyze_data/#12-copy-the-data-locally-to-the-notebook","title":"1.2. Copy the data locally to the notebook","text":"<p><code>aws s3 cp [bucket_name/file_name] [file_name]</code> function copies the file from the S3 bucket into the local environment or into another S3 bucket. Let's use it to copy the file with the dataset locally.</p> <pre><code>!aws s3 cp s3://dlai-practical-data-science/data/raw/womens_clothing_ecommerce_reviews.csv ./womens_clothing_ecommerce_reviews.csv\n</code></pre> <pre><code>download: s3://dlai-practical-data-science/data/raw/womens_clothing_ecommerce_reviews.csv to ./womens_clothing_ecommerce_reviews.csv\n</code></pre> <p>Now use the Pandas dataframe to load and preview the data.</p> <pre><code>import pandas as pd\nimport csv\n\ndf = pd.read_csv('./womens_clothing_ecommerce_reviews.csv',\n                 index_col=0)\n\ndf.shape\n</code></pre>                         Clean data in minutes                     Automatically visualize data, and improve data quality in a few clicks. Learn more Import Data Wrangler widget Remind me later Don't show again <pre><code>(23486, 10)\n</code></pre> <pre><code>df\n</code></pre> Clothing ID Age Title Review Text Rating Recommended IND Positive Feedback Count Division Name Department Name Class Name 0 847 33 Cute, crisp shirt If this product was in petite  i would get the... 4 1 2 General Tops Blouses 1 1080 34 NaN Love this dress!  it's sooo pretty.  i happene... 5 1 4 General Dresses Dresses 2 1077 60 Some major design flaws I had such high hopes for this dress and reall... 3 0 0 General Dresses Dresses 3 1049 50 My favorite buy! I love  love  love this jumpsuit. it's fun  fl... 5 1 0 General Petite Bottoms Pants 4 847 47 Flattering shirt This shirt is very flattering to all due to th... 5 1 6 General Tops Blouses ... ... ... ... ... ... ... ... ... ... ... 23481 1104 34 Great dress for many occasions I was very happy to snag this dress at such a ... 5 1 0 General Petite Dresses Dresses 23482 862 48 Wish it was made of cotton It reminds me of maternity clothes. soft  stre... 3 1 0 General Petite Tops Knits 23483 1104 31 Cute, but see through This fit well  but the top was very see throug... 3 0 1 General Petite Dresses Dresses 23484 1084 28 Very cute dress, perfect for summer parties an... I bought this dress for a wedding i have this ... 3 1 2 General Dresses Dresses 23485 1104 52 Please make more like this one! This dress in a lovely platinum is feminine an... 5 1 22 General Petite Dresses Dresses <p>23486 rows \u00d7 10 columns</p> <p></p>"},{"location":"datascience_on_aws/viz_and_analyze_data/#13-transform-the-data","title":"1.3. Transform the data","text":"<p>To simplify the task, you will transform the data into a comma-separated value (CSV) file that contains only a <code>review_body</code>, <code>product_category</code>, and <code>sentiment</code> derived from the original data.</p> <pre><code>df_transformed = df.rename(columns={'Review Text': 'review_body',\n                                    'Rating': 'star_rating',\n                                    'Class Name': 'product_category'})\ndf_transformed.drop(columns=['Clothing ID', 'Age', 'Title', 'Recommended IND', 'Positive Feedback Count', 'Division Name', 'Department Name'],\n                    inplace=True)\n\ndf_transformed.dropna(inplace=True)\n\ndf_transformed.shape\n</code></pre> <pre><code>(22628, 3)\n</code></pre> <p>Now convert the <code>star_rating</code> into the <code>sentiment</code> (positive, neutral, negative), which later on will be for the prediction.</p> <pre><code>def to_sentiment(star_rating):\n    if star_rating in {1, 2}: # negative\n        return -1 \n    if star_rating == 3:      # neutral\n        return 0\n    if star_rating in {4, 5}: # positive\n        return 1\n\n# transform star_rating into the sentiment\ndf_transformed['sentiment'] = df_transformed['star_rating'].apply(lambda star_rating: \n    to_sentiment(star_rating=star_rating) \n)\n\n# drop the star rating column\ndf_transformed.drop(columns=['star_rating'],\n                    inplace=True)\n\n# remove reviews for product_categories with &lt; 10 reviews\ndf_transformed = df_transformed.groupby('product_category').filter(lambda reviews : len(reviews) &gt; 10)[['sentiment', 'review_body', 'product_category']]\n\ndf_transformed.shape\n</code></pre> <pre><code>(22626, 3)\n</code></pre> <pre><code># preview the results\ndf_transformed\n</code></pre> sentiment review_body product_category 0 1 If this product was in petite  i would get the... Blouses 1 1 Love this dress!  it's sooo pretty.  i happene... Dresses 2 0 I had such high hopes for this dress and reall... Dresses 3 1 I love  love  love this jumpsuit. it's fun  fl... Pants 4 1 This shirt is very flattering to all due to th... Blouses ... ... ... ... 23481 1 I was very happy to snag this dress at such a ... Dresses 23482 0 It reminds me of maternity clothes. soft  stre... Knits 23483 0 This fit well  but the top was very see throug... Dresses 23484 0 I bought this dress for a wedding i have this ... Dresses 23485 1 This dress in a lovely platinum is feminine an... Dresses <p>22626 rows \u00d7 3 columns</p> <p></p>"},{"location":"datascience_on_aws/viz_and_analyze_data/#14-write-the-data-to-a-csv-file","title":"1.4 Write the data to a CSV file","text":"<pre><code>df_transformed.to_csv('./womens_clothing_ecommerce_reviews_transformed.csv', \n                      index=False)\n</code></pre> <pre><code>!head -n 5 ./womens_clothing_ecommerce_reviews_transformed.csv\n</code></pre> <pre><code>sentiment,review_body,product_category\n1,If this product was in petite  i would get the petite. the regular is a little long on me but a tailor can do a simple fix on that.     fits nicely! i'm 5'4  130lb and pregnant so i bough t medium to grow into.     the tie can be front or back so provides for some nice flexibility on form fitting.,Blouses\n1,\"Love this dress!  it's sooo pretty.  i happened to find it in a store  and i'm glad i did bc i never would have ordered it online bc it's petite.  i bought a petite and am 5'8\"\".  i love the length on me- hits just a little below the knee.  would definitely be a true midi on someone who is truly petite.\",Dresses\n0,I had such high hopes for this dress and really wanted it to work for me. i initially ordered the petite small (my usual size) but i found this to be outrageously small. so small in fact that i could not zip it up! i reordered it in petite medium  which was just ok. overall  the top half was comfortable and fit nicely  but the bottom half had a very tight under layer and several somewhat cheap (net) over layers. imo  a major design flaw was the net over layer sewn directly into the zipper - it c,Dresses\n1,I love  love  love this jumpsuit. it's fun  flirty  and fabulous! every time i wear it  i get nothing but great compliments!,Pants\n</code></pre>"},{"location":"datascience_on_aws/viz_and_analyze_data/#2-register-the-public-dataset-for-querying-and-visualizing","title":"2. Register the public dataset for querying and visualizing","text":"<p>You will register the public dataset into an S3-backed database table so you can query and visualize our dataset at scale. </p> <p></p>"},{"location":"datascience_on_aws/viz_and_analyze_data/#21-register-s3-dataset-files-as-a-table-for-querying","title":"2.1. Register S3 dataset files as a table for querying","text":"<p>Let's import required modules.</p> <p><code>boto3</code> is the AWS SDK for Python to create, configure, and manage AWS services, such as Amazon Elastic Compute Cloud (Amazon EC2) and Amazon Simple Storage Service (Amazon S3). The SDK provides an object-oriented API as well as low-level access to AWS services. </p> <p><code>sagemaker</code> is the SageMaker Python SDK which provides several high-level abstractions for working with the Amazon SageMaker.</p> <pre><code>import boto3\nimport sagemaker\nimport pandas as pd\nimport numpy as np\nimport botocore\n\nconfig = botocore.config.Config(user_agent_extra='dlai-pds/c1/w1')\n\n# low-level service client of the boto3 session\nsm = boto3.client(service_name='sagemaker', \n                  config=config)\n\nsess = sagemaker.Session(sagemaker_client=sm)                         \n\nbucket = sess.default_bucket()\nrole = sagemaker.get_execution_role()\nregion = sess.boto_region_name\naccount_id = sess.account_id\n\nprint('S3 Bucket: {}'.format(bucket))\nprint('Region: {}'.format(region))\nprint('Account ID: {}'.format(account_id))\n</code></pre> <pre><code>S3 Bucket: sagemaker-us-east-1-404789036642\nRegion: us-east-1\nAccount ID: &lt;bound method Session.account_id of &lt;sagemaker.session.Session object at 0x7f94c60c5f10&gt;&gt;\n</code></pre> <p>Review the empty bucket which was created automatically for this account.</p> <p>Instructions:  - open the link - click on the S3 bucket name <code>sagemaker-us-east-1-ACCOUNT</code> - check that it is empty at this stage</p> <pre><code>from IPython.core.display import display, HTML\n\ndisplay(HTML('&lt;b&gt;Review &lt;a target=\"top\" href=\"https://s3.console.aws.amazon.com/s3/home?region={}#\"&gt;Amazon S3 buckets&lt;/a&gt;&lt;/b&gt;'.format(region)))\n</code></pre> <p>Review Amazon S3 buckets</p> <p>Copy the file into the S3 bucket.</p> <pre><code>!aws s3 cp ./womens_clothing_ecommerce_reviews_transformed.csv s3://$bucket/data/transformed/womens_clothing_ecommerce_reviews_transformed.csv\n</code></pre> <pre><code>upload: ./womens_clothing_ecommerce_reviews_transformed.csv to s3://sagemaker-us-east-1-404789036642/data/transformed/womens_clothing_ecommerce_reviews_transformed.csv\n</code></pre> <p>Review the bucket with the file we uploaded above.</p> <p>Instructions:  - open the link - check that the CSV file is located in the S3 bucket - check the location directory structure is the same as in the CLI command above - click on the file name and see the available information about the file (region, size, S3 URI, Amazon Resource Name (ARN))</p> <pre><code>from IPython.core.display import display, HTML\n\ndisplay(HTML('&lt;b&gt;Review &lt;a target=\"top\" href=\"https://s3.console.aws.amazon.com/s3/buckets/{}?region={}&amp;prefix=data/transformed/#\"&gt;Amazon S3 buckets&lt;/a&gt;&lt;/b&gt;'.format(bucket, region)))\n</code></pre> <p>Review Amazon S3 buckets</p> <p>Import AWS Data Wrangler</p> <p>AWS Data Wrangler is an AWS Professional Service open source python initiative that extends the power of Pandas library to AWS connecting dataframes and AWS data related services (Amazon Redshift, AWS Glue, Amazon Athena, Amazon EMR, Amazon QuickSight, etc).</p> <p>Built on top of other open-source projects like Pandas, Apache Arrow, Boto3, SQLAlchemy, Psycopg2 and PyMySQL, it offers abstracted functions to execute usual ETL tasks like load/unload data from data lakes, data warehouses and databases.</p> <p>Review the AWS Data Wrangler documentation: https://aws-data-wrangler.readthedocs.io/en/stable/</p> <pre><code>import awswrangler as wr\n</code></pre> <p>Create AWS Glue Catalog database</p> <p>The data catalog features of AWS Glue and the inbuilt integration to Amazon S3 simplify the process of identifying data and deriving the schema definition out of the discovered data. Using AWS Glue crawlers within your data catalog, you can traverse your data stored in Amazon S3 and build out the metadata tables that are defined in your data catalog.</p> <p>Here you will use <code>wr.catalog.create_database</code> function to create a database with the name <code>dsoaws_deep_learning</code> (\"dsoaws\" stands for \"Data Science on AWS\").</p> <pre><code>wr.catalog.create_database(\n    name='dsoaws_deep_learning',\n    exist_ok=True\n)\n</code></pre> <pre><code>dbs = wr.catalog.get_databases()\n\nfor db in dbs:\n    print(\"Database name: \" + db['Name'])\n</code></pre> <pre><code>Database name: dsoaws_deep_learning\n</code></pre> <p>Review the created database in the AWS Glue Catalog.</p> <p>Instructions: - open the link - on the left side panel notice that you are in the AWS Glue -&gt; Data Catalog -&gt; Databases - check that the database <code>dsoaws_deep_learning</code> has been created - click on the name of the database - click on the <code>Tables in dsoaws_deep_learning</code> link to see that there are no tables</p> <pre><code>from IPython.core.display import display, HTML\n\ndisplay(HTML('&lt;b&gt;Review &lt;a target=\"top\" href=\"https://console.aws.amazon.com/glue/home?region={}#catalog:tab=databases\"&gt;AWS Glue Databases&lt;/a&gt;&lt;/b&gt;'.format(region)))\n</code></pre> <p>Review AWS Glue Databases</p> <p>Register CSV data with AWS Glue Catalog</p> <p></p>"},{"location":"datascience_on_aws/viz_and_analyze_data/#exercise-2","title":"Exercise 2","text":"<p>Register CSV data with AWS Glue Catalog.</p> <p>Instructions: Use <code>wr.catalog.create_csv_table</code> function with the following parameters</p> <pre><code>res = wr.catalog.create_csv_table(\n    database='dsoaws_deep_learning', # AWS Glue Catalog database name\n    path='s3://{}/data/transformed/'.format(bucket), # S3 object path for the data\n    table='reviews', # registered table name\n    columns_types={\n        'sentiment': 'int',        \n        'review_body': 'string',\n        'product_category': 'string'      \n    },\n    mode='overwrite',\n    skip_header_line_count=1,\n    sep=','    \n)\n</code></pre> <pre><code>wr.catalog.create_csv_table(\n    ### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n    database='dsoaws_deep_learning', # Replace None\n    ### END SOLUTION - DO NOT delete this comment for grading purposes\n    path='s3://{}/data/transformed/'.format(bucket), \n    table=\"reviews\",    \n    columns_types={\n        'sentiment': 'int',        \n        'review_body': 'string',\n        'product_category': 'string'      \n    },\n    mode='overwrite',\n    skip_header_line_count=1,\n    sep=','\n)\n</code></pre> <p>Review the registered table in the AWS Glue Catalog.</p> <p>Instructions: - open the link - on the left side panel notice that you are in the AWS Glue -&gt; Data Catalog -&gt; Databases -&gt; Tables - check that you can see the table <code>reviews</code> from the database <code>dsoaws_deep_learning</code> in the list - click on the name of the table - explore the available information about the table (name, database, classification, location, schema etc.)</p> <pre><code>from IPython.core.display import display, HTML\n\ndisplay(HTML('&lt;b&gt;Review &lt;a target=\"top\" href=\"https://console.aws.amazon.com/glue/home?region={}#\"&gt;AWS Glue Catalog&lt;/a&gt;&lt;/b&gt;'.format(region)))\n</code></pre> <p>Review AWS Glue Catalog</p> <p>Review the table shape:</p> <pre><code>table = wr.catalog.table(database='dsoaws_deep_learning',\n                         table='reviews')\ntable\n</code></pre> Column Name Type Partition Comment 0 sentiment int False 1 review_body string False 2 product_category string False <p></p>"},{"location":"datascience_on_aws/viz_and_analyze_data/#22-create-default-s3-bucket-for-amazon-athena","title":"2.2. Create default S3 bucket for Amazon Athena","text":"<p>Amazon Athena requires this S3 bucket to store temporary query results and improve performance of subsequent queries.</p> <p>The contents of this bucket are mostly binary and human-unreadable. </p> <pre><code># S3 bucket name\nwr.athena.create_athena_bucket()\n\n# EXPECTED OUTPUT\n# 's3://aws-athena-query-results-ACCOUNT-REGION/'\n</code></pre> <pre><code>'s3://aws-athena-query-results-404789036642-us-east-1/'\n</code></pre> <p></p>"},{"location":"datascience_on_aws/viz_and_analyze_data/#3-visualize-data","title":"3. Visualize data","text":"<p>Reviews dataset - column descriptions</p> <ul> <li><code>sentiment</code>: The review's sentiment (-1, 0, 1).</li> <li><code>product_category</code>: Broad product category that can be used to group reviews (in this case digital videos).</li> <li><code>review_body</code>: The text of the review.</li> </ul> <p></p>"},{"location":"datascience_on_aws/viz_and_analyze_data/#31-preparation-for-data-visualization","title":"3.1. Preparation for data visualization","text":"<p>Imports</p> <pre><code>import numpy as np\nimport seaborn as sns\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n%config InlineBackend.figure_format='retina'\n</code></pre> <p>Settings</p> <p>Set AWS Glue database and table name.</p> <pre><code># Do not change the database and table names - they are used for grading purposes!\ndatabase_name = 'dsoaws_deep_learning'\ntable_name = 'reviews'\n</code></pre> <p>Set seaborn parameters. You can review seaborn documentation following the link.</p> <pre><code>sns.set_style = 'seaborn-whitegrid'\n\nsns.set(rc={\"font.style\":\"normal\",\n            \"axes.facecolor\":\"white\",\n            'grid.color': '.8',\n            'grid.linestyle': '-',\n            \"figure.facecolor\":\"white\",\n            \"figure.titlesize\":20,\n            \"text.color\":\"black\",\n            \"xtick.color\":\"black\",\n            \"ytick.color\":\"black\",\n            \"axes.labelcolor\":\"black\",\n            \"axes.grid\":True,\n            'axes.labelsize':10,\n            'xtick.labelsize':10,\n            'font.size':10,\n            'ytick.labelsize':10})\n</code></pre> <p>Helper code to display values on barplots:</p> <p>Run SQL queries using Amazon Athena</p> <p>Amazon Athena lets you query data in Amazon S3 using a standard SQL interface. It reflects the databases and tables in the AWS Glue Catalog. You can create interactive queries and perform any data manipulations required for further downstream processing.</p> <p>Standard SQL query can be saved as a string and then passed as a parameter into the Athena query. Run the following cells as an example to count the total number of reviews by sentiment. The SQL query here will take the following form:</p> <pre><code>SELECT column_name, COUNT(column_name) as new_column_name\nFROM table_name\nGROUP BY column_name\nORDER BY column_name\n</code></pre> <p>If you are not familiar with the SQL query statements, you can review some tutorials following the link.</p> <p></p>"},{"location":"datascience_on_aws/viz_and_analyze_data/#32-how-many-reviews-per-sentiment","title":"3.2. How many reviews per sentiment?","text":"<p>Set the SQL statement to find the count of sentiments:</p> <pre><code>statement_count_by_sentiment = \"\"\"\nSELECT sentiment, COUNT(sentiment) AS count_sentiment\nFROM reviews\nGROUP BY sentiment\nORDER BY sentiment\n\"\"\"\n\nprint(statement_count_by_sentiment)\n</code></pre> <pre><code>SELECT sentiment, COUNT(sentiment) AS count_sentiment\nFROM reviews\nGROUP BY sentiment\nORDER BY sentiment\n</code></pre> <p>Query data in Amazon Athena database cluster using the prepared SQL statement:</p> <pre><code>df_count_by_sentiment = wr.athena.read_sql_query(\n    sql=statement_count_by_sentiment,\n    database=database_name\n)\n\nprint(df_count_by_sentiment)\n</code></pre> <pre><code>   sentiment  count_sentiment\n0         -1             2370\n1          0             2823\n2          1            17433\n</code></pre> <p>Preview the results of the query:</p> <pre><code>df_count_by_sentiment.plot(kind='bar', x='sentiment', y='count_sentiment', rot=0)\n</code></pre> <pre><code>&lt;AxesSubplot:xlabel='sentiment'&gt;\n</code></pre> <p></p> <p></p>"},{"location":"datascience_on_aws/viz_and_analyze_data/#exercise-3","title":"Exercise 3","text":"<p>Use Amazon Athena query with the standard SQL statement passed as a parameter, to calculate the total number of reviews per <code>product_category</code> in the table <code>reviews</code>.</p> <p>Instructions: Pass the SQL statement of the form</p> <pre><code>SELECT category_column, COUNT(column_name) AS new_column_name\nFROM table_name\nGROUP BY category_column\nORDER BY new_column_name DESC\n</code></pre> <p>as a triple quote string into the variable <code>statement_count_by_category</code>. Please use the column <code>sentiment</code> in the <code>COUNT</code> function and give it a new name <code>count_sentiment</code>.</p> <pre><code># Replace all None\n### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\nstatement_count_by_category = \"\"\"\nSELECT product_category, COUNT(review_body) AS number_of_reviews\nFROM reviews\nGROUP BY product_category \nORDER BY number_of_reviews DESC\n\"\"\"\n### END SOLUTION - DO NOT delete this comment for grading purposes\nprint(statement_count_by_category)\n</code></pre> <pre><code>SELECT product_category, COUNT(review_body) AS number_of_reviews\nFROM reviews\nGROUP BY product_category \nORDER BY number_of_reviews DESC\n</code></pre> <p>Query data in Amazon Athena database passing the prepared SQL statement:</p> <pre><code>%%time\ndf_count_by_category = wr.athena.read_sql_query(\n    sql=statement_count_by_category,\n    database=database_name\n)\n\ndf_count_by_category\n\n# EXPECTED OUTPUT\n# Dresses: 6145\n# Knits: 4626\n# Blouses: 2983\n# Sweaters: 1380\n# Pants: 1350\n# ...\n</code></pre> <pre><code>CPU times: user 498 ms, sys: 15.3 ms, total: 513 ms\nWall time: 3.82 s\n</code></pre> product_category number_of_reviews 0 Dresses 6145 1 Knits 4626 2 Blouses 2983 3 Sweaters 1380 4 Pants 1350 5 Jeans 1104 6 Fine gauge 1059 7 Skirts 903 8 Jackets 683 9 Lounge 669 10 Swim 332 11 Outerwear 319 12 Shorts 304 13 Sleep 214 14 Legwear 158 15 Intimates 147 16 Layering 132 17 Trend 118 <p></p>"},{"location":"datascience_on_aws/viz_and_analyze_data/#33-which-product-categories-are-highest-rated-by-average-sentiment","title":"3.3. Which product categories are highest rated by average sentiment?","text":"<p>Set the SQL statement to find the average sentiment per product category, showing the results in the descending order:</p> <pre><code>statement_avg_by_category = \"\"\"\nSELECT product_category, AVG(sentiment) AS avg_sentiment\nFROM {} \nGROUP BY product_category \nORDER BY avg_sentiment DESC\n\"\"\".format(table_name)\n\nprint(statement_avg_by_category)\n</code></pre> <pre><code>SELECT product_category, AVG(sentiment) AS avg_sentiment\nFROM reviews \nGROUP BY product_category \nORDER BY avg_sentiment DESC\n</code></pre> <p>Query data in Amazon Athena database passing the prepared SQL statement:</p> <pre><code>%%time\ndf_avg_by_category = wr.athena.read_sql_query(\n    sql=statement_avg_by_category,\n    database=database_name\n)\n</code></pre> <pre><code>CPU times: user 310 ms, sys: 39.2 ms, total: 349 ms\nWall time: 3.19 s\n</code></pre> <p>Preview the query results in the temporary S3 bucket:  <code>s3://aws-athena-query-results-ACCOUNT-REGION/</code></p> <p>Instructions:  - open the link - check the name of the S3 bucket - briefly check the content of it</p> <pre><code>from IPython.core.display import display, HTML\n\ndisplay(HTML('&lt;b&gt;Review &lt;a target=\"top\" href=\"https://s3.console.aws.amazon.com/s3/buckets/aws-athena-query-results-{}-{}?region={}\"&gt;Amazon S3 buckets&lt;/a&gt;&lt;/b&gt;'.format(account_id, region, region)))\n</code></pre> <p>Review Amazon S3 buckets</p> <p>Preview the results of the query:</p> <pre><code>df_avg_by_category\n</code></pre> product_category avg_sentiment 0 Layering 0.780303 1 Jeans 0.746377 2 Lounge 0.745889 3 Sleep 0.710280 4 Shorts 0.707237 5 Pants 0.705185 6 Intimates 0.700680 7 Jackets 0.699854 8 Skirts 0.696567 9 Legwear 0.696203 10 Fine gauge 0.692162 11 Outerwear 0.683386 12 Knits 0.653913 13 Swim 0.644578 14 Dresses 0.643287 15 Sweaters 0.641304 16 Blouses 0.641301 17 Trend 0.483051 <p>Visualization</p> <pre><code>def show_values_barplot(axs, space):\n    def _show_on_plot(ax):\n        for p in ax.patches:\n            _x = p.get_x() + p.get_width() + float(space)\n            _y = p.get_y() + p.get_height()\n            value = round(float(p.get_width()),2)\n            ax.text(_x, _y, value, ha=\"left\")\n\n    if isinstance(axs, np.ndarray):\n        for idx, ax in np.ndenumerate(axs):\n            _show_on_plot(ax)\n    else:\n        _show_on_plot(axs)\n</code></pre> <pre><code># Create plot\nbarplot = sns.barplot(\n    data = df_avg_by_category, \n    y='product_category',\n    x='avg_sentiment', \n    color=\"b\", \n    saturation=1\n)\n\n# Set the size of the figure\nsns.set(rc={'figure.figsize':(15.0, 10.0)})\n\n# Set title and x-axis ticks \nplt.title('Average sentiment by product category')\n#plt.xticks([-1, 0, 1], ['Negative', 'Neutral', 'Positive'])\n\n# Helper code to show actual values afters bars \nshow_values_barplot(barplot, 0.1)\n\nplt.xlabel(\"Average sentiment\")\nplt.ylabel(\"Product category\")\n\nplt.tight_layout()\n# Do not change the figure name - it is used for grading purposes!\nplt.savefig('avg_sentiment_per_category.png', dpi=300)\n\n# Show graphic\nplt.show(barplot)\n</code></pre> <p></p> <pre><code># Upload image to S3 bucket\nsess.upload_data(path='avg_sentiment_per_category.png', bucket=bucket, key_prefix=\"images\")\n</code></pre> <pre><code>'s3://sagemaker-us-east-1-404789036642/images/avg_sentiment_per_category.png'\n</code></pre> <p>Review the bucket on the account.</p> <p>Instructions:  - open the link - click on the S3 bucket name <code>sagemaker-us-east-1-ACCOUNT</code> - open the images folder - check the existence of the image <code>avg_sentiment_per_category.png</code> - if you click on the image name, you can see the information about the image file. You can also download the file with the command on the top right Object Actions -&gt; Download / Download as </p> <pre><code>from IPython.core.display import display, HTML\n\ndisplay(HTML('&lt;b&gt;Review &lt;a target=\"top\" href=\"https://s3.console.aws.amazon.com/s3/home?region={}\"&gt;Amazon S3 buckets&lt;/a&gt;&lt;/b&gt;'.format(region)))\n</code></pre> <p>Review Amazon S3 buckets</p> <p></p>"},{"location":"datascience_on_aws/viz_and_analyze_data/#34-which-product-categories-have-the-most-reviews","title":"3.4. Which product categories have the most reviews?","text":"<p>Set the SQL statement to find the count of sentiment per product category, showing the results in the descending order:</p> <pre><code>statement_count_by_category_desc = \"\"\"\nSELECT product_category, COUNT(*) AS count_reviews \nFROM {}\nGROUP BY product_category \nORDER BY count_reviews DESC\n\"\"\".format(table_name)\n\nprint(statement_count_by_category_desc)\n</code></pre> <pre><code>SELECT product_category, COUNT(*) AS count_reviews \nFROM reviews\nGROUP BY product_category \nORDER BY count_reviews DESC\n</code></pre> <p>Query data in Amazon Athena database passing the prepared SQL statement:</p> <pre><code>%%time\ndf_count_by_category_desc = wr.athena.read_sql_query(\n    sql=statement_count_by_category_desc,\n    database=database_name\n)\n</code></pre> <pre><code>CPU times: user 444 ms, sys: 22.6 ms, total: 466 ms\nWall time: 2.95 s\n</code></pre> <p>Store maximum number of sentiment for the visualization plot:</p> <pre><code>max_sentiment = df_count_by_category_desc['count_reviews'].max()\nprint('Highest number of reviews (in a single category): {}'.format(max_sentiment))\n</code></pre> <pre><code>Highest number of reviews (in a single category): 6145\n</code></pre> <p>Visualization</p> <p></p>"},{"location":"datascience_on_aws/viz_and_analyze_data/#exercise-4","title":"Exercise 4","text":"<p>Use <code>barplot</code> function to plot number of reviews per product category.</p> <p>Instructions: Use the <code>barplot</code> chart example in the previous section, passing the newly defined dataframe <code>df_count_by_category_desc</code> with the count of reviews. Here, please put the <code>product_category</code> column into the <code>y</code> argument.</p> <pre><code># Create seaborn barplot\nbarplot = sns.barplot(\n    ### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n    data=df_count_by_category_desc, # Replace None\n    y='product_category', # Replace None\n    x='count_reviews', # Replace None\n    ### END SOLUTION - DO NOT delete this comment for grading purposes\n    color=\"b\",\n    saturation=1\n)\n\n# Set the size of the figure\nsns.set(rc={'figure.figsize':(15.0, 10.0)})\n\n# Set title\nplt.title(\"Number of reviews per product category\")\nplt.xlabel(\"Number of reviews\")\nplt.ylabel(\"Product category\")\n\nplt.tight_layout()\n\n# Do not change the figure name - it is used for grading purposes!\nplt.savefig('num_reviews_per_category.png', dpi=300)\n\n# Show the barplot\nplt.show(barplot)\n</code></pre> <p></p> <pre><code># Upload image to S3 bucket\nsess.upload_data(path='num_reviews_per_category.png', bucket=bucket, key_prefix=\"images\")\n</code></pre> <pre><code>'s3://sagemaker-us-east-1-404789036642/images/num_reviews_per_category.png'\n</code></pre> <p></p>"},{"location":"datascience_on_aws/viz_and_analyze_data/#35-what-is-the-breakdown-of-sentiments-per-product-category","title":"3.5. What is the breakdown of sentiments per product category?","text":"<p>Set the SQL statement to find the count of sentiment per product category and sentiment:</p> <pre><code>statement_count_by_category_and_sentiment = \"\"\"\nSELECT product_category,\n         sentiment,\n         COUNT(*) AS count_reviews\nFROM {}\nGROUP BY  product_category, sentiment\nORDER BY  product_category ASC, sentiment DESC, count_reviews\n\"\"\".format(table_name)\n\nprint(statement_count_by_category_and_sentiment)\n</code></pre> <pre><code>SELECT product_category,\n         sentiment,\n         COUNT(*) AS count_reviews\nFROM reviews\nGROUP BY  product_category, sentiment\nORDER BY  product_category ASC, sentiment DESC, count_reviews\n</code></pre> <p>Query data in Amazon Athena database passing the prepared SQL statement:</p> <pre><code>%%time\ndf_count_by_category_and_sentiment = wr.athena.read_sql_query(\n    sql=statement_count_by_category_and_sentiment,\n    database=database_name\n)\n</code></pre> <pre><code>CPU times: user 326 ms, sys: 14.7 ms, total: 341 ms\nWall time: 3.01 s\n</code></pre> <p>Prepare for stacked percentage horizontal bar plot showing proportion of sentiments per product category.</p> <pre><code># Create grouped dataframes by category and by sentiment\ngrouped_category = df_count_by_category_and_sentiment.groupby('product_category')\ngrouped_star = df_count_by_category_and_sentiment.groupby('sentiment')\n\n# Create sum of sentiments per star sentiment\ndf_sum = df_count_by_category_and_sentiment.groupby(['sentiment']).sum()\n\n# Calculate total number of sentiments\ntotal = df_sum['count_reviews'].sum()\nprint('Total number of reviews: {}'.format(total))\n</code></pre> <pre><code>Total number of reviews: 22626\n</code></pre> <p>Create dictionary of product categories and array of star rating distribution per category.</p> <pre><code>distribution = {}\ncount_reviews_per_star = []\ni=0\n\nfor category, sentiments in grouped_category:\n    count_reviews_per_star = []\n    for star in sentiments['sentiment']:\n        count_reviews_per_star.append(sentiments.at[i, 'count_reviews'])\n        i=i+1;\n    distribution[category] = count_reviews_per_star\n</code></pre> <p>Build array per star across all categories.</p> <pre><code>distribution\n</code></pre> <pre><code>{'Blouses': [2256, 384, 343],\n 'Dresses': [4634, 830, 681],\n 'Fine gauge': [837, 118, 104],\n 'Intimates': [117, 16, 14],\n 'Jackets': [550, 61, 72],\n 'Jeans': [909, 110, 85],\n 'Knits': [3523, 605, 498],\n 'Layering': [113, 9, 10],\n 'Legwear': [126, 16, 16],\n 'Lounge': [545, 78, 46],\n 'Outerwear': [254, 29, 36],\n 'Pants': [1074, 154, 122],\n 'Shorts': [240, 39, 25],\n 'Skirts': [714, 104, 85],\n 'Sleep': [175, 16, 23],\n 'Sweaters': [1036, 193, 151],\n 'Swim': [252, 42, 38],\n 'Trend': [78, 19, 21]}\n</code></pre> <pre><code>df_distribution_pct = pd.DataFrame(distribution).transpose().apply(\n    lambda num_sentiments: num_sentiments/sum(num_sentiments)*100, axis=1\n)\ndf_distribution_pct.columns=['1', '0', '-1']\ndf_distribution_pct\n</code></pre> 1 0 -1 Blouses 75.628562 12.872947 11.498491 Dresses 75.410903 13.506916 11.082181 Fine gauge 79.036827 11.142587 9.820585 Intimates 79.591837 10.884354 9.523810 Jackets 80.527086 8.931186 10.541728 Jeans 82.336957 9.963768 7.699275 Knits 76.156507 13.078253 10.765240 Layering 85.606061 6.818182 7.575758 Legwear 79.746835 10.126582 10.126582 Lounge 81.464873 11.659193 6.875934 Outerwear 79.623824 9.090909 11.285266 Pants 79.555556 11.407407 9.037037 Shorts 78.947368 12.828947 8.223684 Skirts 79.069767 11.517165 9.413068 Sleep 81.775701 7.476636 10.747664 Sweaters 75.072464 13.985507 10.942029 Swim 75.903614 12.650602 11.445783 Trend 66.101695 16.101695 17.796610 <p>Visualization</p> <p>Plot the distributions of sentiments per product category.</p> <pre><code>categories = df_distribution_pct.index\n\n# Plot bars\nplt.figure(figsize=(10,5))\n\ndf_distribution_pct.plot(kind=\"barh\", \n                         stacked=True, \n                         edgecolor='white',\n                         width=1.0,\n                         color=['green', \n                                'orange', \n                                'blue'])\n\nplt.title(\"Distribution of reviews per sentiment per category\", \n          fontsize='16')\n\nplt.legend(bbox_to_anchor=(1.04,1), \n           loc=\"upper left\",\n           labels=['Positive', \n                   'Neutral', \n                   'Negative'])\n\nplt.xlabel(\"% Breakdown of sentiments\", fontsize='14')\nplt.gca().invert_yaxis()\nplt.tight_layout()\n\n# Do not change the figure name - it is used for grading purposes!\nplt.savefig('distribution_sentiment_per_category.png', dpi=300)\nplt.show()\n</code></pre> <pre><code>&lt;Figure size 1000x500 with 0 Axes&gt;\n</code></pre> <p></p> <pre><code># Upload image to S3 bucket\nsess.upload_data(path='distribution_sentiment_per_category.png', bucket=bucket, key_prefix=\"images\")\n</code></pre> <pre><code>'s3://sagemaker-us-east-1-404789036642/images/distribution_sentiment_per_category.png'\n</code></pre> <p></p>"},{"location":"datascience_on_aws/viz_and_analyze_data/#36-analyze-the-distribution-of-review-word-counts","title":"3.6. Analyze the distribution of review word counts","text":"<p>Set the SQL statement to count the number of the words in each of the reviews:</p> <pre><code>statement_num_words = \"\"\"\n    SELECT CARDINALITY(SPLIT(review_body, ' ')) as num_words\n    FROM {}\n\"\"\".format(table_name)\n\nprint(statement_num_words)\n</code></pre> <pre><code>    SELECT CARDINALITY(SPLIT(review_body, ' ')) as num_words\n    FROM reviews\n</code></pre> <p>Query data in Amazon Athena database passing the SQL statement:</p> <pre><code>%%time\ndf_num_words = wr.athena.read_sql_query(\n    sql=statement_num_words,\n    database=database_name\n)\n</code></pre> <pre><code>CPU times: user 479 ms, sys: 35.9 ms, total: 515 ms\nWall time: 3.53 s\n</code></pre> <p>Print out and analyse some descriptive statistics: </p> <pre><code>summary = df_num_words[\"num_words\"].describe(percentiles=[0.10, 0.20, 0.30, 0.40, 0.50, 0.60, 0.70, 0.80, 0.90, 1.00])\nsummary\n</code></pre> <pre><code>count    22626.000000\nmean        62.709847\nstd         29.993735\nmin          2.000000\n10%         22.000000\n20%         33.000000\n30%         42.000000\n40%         51.000000\n50%         61.000000\n60%         72.000000\n70%         86.000000\n80%         97.000000\n90%        103.000000\n100%       122.000000\nmax        122.000000\nName: num_words, dtype: float64\n</code></pre> <p>Plot the distribution of the words number per review:</p> <pre><code>df_num_words[\"num_words\"].plot.hist(xticks=[0, 16, 32, 64, 128, 256], bins=100, range=[0, 256]).axvline(\n    x=summary[\"100%\"], c=\"red\"\n)\n\nplt.xlabel(\"Words number\", fontsize='14')\nplt.ylabel(\"Frequency\", fontsize='14')\nplt.savefig('distribution_num_words_per_review.png', dpi=300)\nplt.show()\n</code></pre> <p></p> <pre><code># Upload image to S3 bucket\nsess.upload_data(path='distribution_num_words_per_review.png', bucket=bucket, key_prefix=\"images\")\n</code></pre> <pre><code>'s3://sagemaker-us-east-1-404789036642/images/distribution_num_words_per_review.png'\n</code></pre> <p>Upload the notebook into S3 bucket for grading purposes.</p> <p>Note: you may need to click on \"Save\" button before the upload.</p> <pre><code>!aws s3 cp ./C1_W1_Assignment.ipynb s3://$bucket/C1_W1_Assignment_Learner.ipynb\n</code></pre> <pre><code>upload: ./C1_W1_Assignment.ipynb to s3://sagemaker-us-east-1-404789036642/C1_W1_Assignment_Learner.ipynb\n</code></pre> <p>Please go to the main lab window and click on <code>Submit</code> button (see the <code>Finish the lab</code> section of the instructions).</p> <pre><code>\n</code></pre>"},{"location":"blog/page/2/","title":"Blog Home","text":""}]}